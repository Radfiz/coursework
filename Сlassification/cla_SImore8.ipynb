{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddde29b9-e3eb-4c5c-8dd4-d127058ba0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Data (actual logged targets):\n",
      "         SI\n",
      "0  3.371597\n",
      "1  2.079442\n",
      "2  0.542324\n",
      "3  4.162553\n",
      "4  0.832909\n",
      "\n",
      "Manual Data (actual logged targets):\n",
      "         SI\n",
      "0  3.371597\n",
      "1  2.079442\n",
      "2  0.542324\n",
      "3  4.162553\n",
      "4  0.832909\n",
      "\n",
      "Созданные бинарные целевые переменные:\n",
      "PCA - is_SI_above_8 value counts:\n",
      " is_SI_above_8\n",
      "0    643\n",
      "1    358\n",
      "Name: count, dtype: int64\n",
      "Manual - is_SI_above_8 value counts:\n",
      " is_SI_above_8\n",
      "0    643\n",
      "1    358\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import uniform, randint\n",
    "import optuna\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Загрузка данных ---\n",
    "file_url_pca = 'https://drive.google.com/uc?export=download&id=1SuUhkpfj-3uJQnxwmUCyDUogfa2TixTe'\n",
    "file_url_manual = 'https://drive.google.com/uc?export=download&id=1p8VYp23oOylSFrfJztQVheNLop-bX40o'\n",
    "\n",
    "df_pca = pd.read_csv(file_url_pca, encoding='utf-8')\n",
    "df_manual = pd.read_csv(file_url_manual, encoding='utf-8')\n",
    "\n",
    "# --- Определяем фактические целевые переменные, которые уже логарифмированы ---\n",
    "# Поскольку вы подтвердили, что 'IC50, mM', 'CC50, mM', 'SI' уже логарифмированы,\n",
    "# мы будем использовать их напрямую как наши \"лог-цели\".\n",
    "TARGETS_ACTUAL_LOGGED = ['SI']\n",
    "\n",
    "print(\"PCA Data (actual logged targets):\")\n",
    "print(df_pca[TARGETS_ACTUAL_LOGGED].head())\n",
    "print(\"\\nManual Data (actual logged targets):\")\n",
    "print(df_manual[TARGETS_ACTUAL_LOGGED].head())\n",
    "\n",
    "# --- Создание бинарных целевых переменных для классификации ---\n",
    "\n",
    "classification_targets = {}\n",
    "\n",
    "\n",
    "# 4. SI > 8 (поскольку SI уже логарифмировано, порог 8 должен быть логарифмирован)\n",
    "# Если SI было получено как np.log1p(SI_original), то порог тоже должен быть np.log1p(8)\n",
    "log_8_threshold = np.log1p(8) # Предполагаем, что исходное SI было логарифмировано с log1p\n",
    "df_pca['is_SI_above_8'] = (df_pca['SI'] > log_8_threshold).astype(int)\n",
    "df_manual['is_SI_above_8'] = (df_manual['SI'] > log_8_threshold).astype(int)\n",
    "classification_targets['is_SI_above_8'] = 'SI'\n",
    "\n",
    "print(\"\\nСозданные бинарные целевые переменные:\")\n",
    "print(\"PCA - is_SI_above_8 value counts:\\n\", df_pca['is_SI_above_8'].value_counts())\n",
    "\n",
    "print(\"Manual - is_SI_above_8 value counts:\\n\", df_manual['is_SI_above_8'].value_counts())\n",
    "\n",
    "# --- Вспомогательная функция для расчета метрик классификации ---\n",
    "def calculate_classification_metrics(y_true, y_pred, y_pred_proba):\n",
    "    \"\"\"Вычисляет метрики классификации: Accuracy, Precision, Recall, F1, ROC-AUC.\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0) # Добавлено zero_division\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# --- Функции для каждого метода оптимизации (адаптированные для классификации) ---\n",
    "\n",
    "def run_randomized_search_classifier(model_instance, param_distributions, X_train_scaled, y_train, n_iter_search=20):\n",
    "    \"\"\"Выполняет RandomizedSearchCV для подбора гиперпараметров для классификации.\"\"\"\n",
    "    if not param_distributions:\n",
    "        model_instance.fit(X_train_scaled, y_train)\n",
    "        return model_instance, {}\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    random_search = RandomizedSearchCV(model_instance, param_distributions, n_iter=n_iter_search,\n",
    "                                       cv=cv, scoring='roc_auc',\n",
    "                                       n_jobs=-1, verbose=0, random_state=42)\n",
    "    random_search.fit(X_train_scaled, y_train)\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "def run_grid_search_classifier(model_instance, param_grid, X_train_scaled, y_train):\n",
    "    \"\"\"Выполняет GridSearchCV для подбора гиперпараметров для классификации.\"\"\"\n",
    "    if not param_grid:\n",
    "        model_instance.fit(X_train_scaled, y_train)\n",
    "        return model_instance, {}\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(model_instance, param_grid, cv=cv, scoring='roc_auc',\n",
    "                               n_jobs=-1, verbose=0)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def run_optuna_search_classifier(model_class, optuna_search_space, X_train_scaled, y_train, n_trials=20):\n",
    "    \"\"\"Выполняет оптимизацию гиперпараметров с помощью Optuna для классификации.\"\"\"\n",
    "    def objective(trial):\n",
    "        params = optuna_search_space(trial)\n",
    "\n",
    "        # Обработка random_state/random_seed для Optuna\n",
    "        # Random_state может быть не поддерживаем для всех моделей или определенных solvers\n",
    "        # Здесь мы исходим из того, что Optuna space уже определяет правильный параметр ('random_state' или 'random_seed')\n",
    "        if model_class in [LogisticRegression, MLPClassifier] and 'random_state' in params:\n",
    "            model = model_class(**{k: v for k, v in params.items() if k != 'random_state'})\n",
    "        else:\n",
    "            model = model_class(**params)\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = []\n",
    "        for train_idx, val_idx in kf.split(X_train_scaled, y_train):\n",
    "            X_train_fold, X_val_fold = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            try:\n",
    "                if isinstance(model, CatBoostClassifier):\n",
    "                    train_pool = Pool(X_train_fold, y_train_fold)\n",
    "                    val_pool = Pool(X_val_fold, y_val_fold)\n",
    "                    model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=10, verbose=False)\n",
    "                    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "                else:\n",
    "                    model.fit(X_train_fold, y_train_fold)\n",
    "                    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "                roc_auc_fold = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
    "                cv_scores.append(roc_auc_fold)\n",
    "            except Exception as e:\n",
    "                # print(f\"Ошибка при обучении/предсказании в Optuna (фолд): {e}\") # Для дебага\n",
    "                return -float('inf')\n",
    "\n",
    "        return -np.mean(cv_scores)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False, catch=(ValueError, Exception))\n",
    "\n",
    "    best_params = study.best_params\n",
    "    \n",
    "    # Final model instance with best parameters\n",
    "    if model_class in [LogisticRegression, MLPClassifier] and 'random_state' in best_params:\n",
    "        best_model_instance = model_class(**{k: v for k, v in best_params.items() if k != 'random_state'})\n",
    "    else:\n",
    "        best_model_instance = model_class(**best_params)\n",
    "\n",
    "    try:\n",
    "        if isinstance(best_model_instance, CatBoostClassifier):\n",
    "            train_pool_final = Pool(X_train_scaled, y_train)\n",
    "            best_model_instance.fit(train_pool_final, verbose=False)\n",
    "        else:\n",
    "            best_model_instance.fit(X_train_scaled, y_train)\n",
    "    except Exception as e:\n",
    "        # print(f\"Ошибка при окончательном обучении CatBoost: {e}\") # Для дебага\n",
    "        return None, {}\n",
    "\n",
    "    return best_model_instance, best_params\n",
    "\n",
    "# --- Общая функция для оценки моделей с различными оптимизаторами (адаптированная) ---\n",
    "def evaluate_model_with_optimizer_classifier(model_name, model_class, params_config, X, y, target_name, optimizer_type):\n",
    "    \"\"\"Оценивает производительность модели классификации, используя указанный метод оптимизации.\"\"\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    best_model = None\n",
    "    best_params = {}\n",
    "\n",
    "    # Инициализация параметров для воспроизводимости:\n",
    "    model_init_params = {}\n",
    "    if model_name == \"CatBoostClassifier\":\n",
    "        model_init_params['random_seed'] = 42\n",
    "    elif model_name in [\"LogisticRegression\", \"RandomForestClassifier\", \"XGBClassifier\", \"MLPClassifier\"]:\n",
    "        # Эти модели обычно принимают random_state для воспроизводимости\n",
    "        model_init_params['random_state'] = 42\n",
    "\n",
    "    if optimizer_type == 'RandomizedSearchCV':\n",
    "        param_distributions = params_config.get('random_dist', {})\n",
    "        # Для LogisticRegression, если нет dist, используем дефолтный инстанс\n",
    "        if model_name == \"LogisticRegression\" and not param_distributions:\n",
    "             model_instance = model_class(**model_init_params)\n",
    "             model_instance.fit(X_train_scaled, y_train)\n",
    "             best_model, best_params = model_instance, {}\n",
    "        else:\n",
    "            best_model, best_params = run_randomized_search_classifier(model_class(**model_init_params), param_distributions, X_train_scaled, y_train, n_iter_search=20)\n",
    "\n",
    "    elif optimizer_type == 'GridSearchCV':\n",
    "        param_grid = params_config.get('grid_params', {})\n",
    "        if not param_grid:\n",
    "            model_instance = model_class(**model_init_params)\n",
    "            model_instance.fit(X_train_scaled, y_train)\n",
    "            best_model, best_params = model_instance, {}\n",
    "        else:\n",
    "            best_model, best_params = run_grid_search_classifier(model_class(**model_init_params), param_grid, X_train_scaled, y_train)\n",
    "\n",
    "    elif optimizer_type == 'Optuna':\n",
    "        optuna_space = params_config.get('optuna_space')\n",
    "        if optuna_space is None:\n",
    "            model_instance = model_class(**model_init_params)\n",
    "            model_instance.fit(X_train_scaled, y_train)\n",
    "            best_model, best_params = model_instance, {}\n",
    "        else:\n",
    "            # Optuna уже обрабатывает random_state/random_seed в своей objective функции\n",
    "            best_model, best_params = run_optuna_search_classifier(model_class, optuna_space, X_train_scaled, y_train, n_trials=20)\n",
    "    else:\n",
    "        raise ValueError(f\"Неизвестный тип оптимизатора: {optimizer_type}\")\n",
    "\n",
    "    if best_model is None:\n",
    "        return None\n",
    "\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    # predict_proba может отсутствовать для некоторых моделей (например, SVM с probability=False)\n",
    "    # или если модель не была обучена с этой функциональностью.\n",
    "    # Проверяем наличие predict_proba\n",
    "    if hasattr(best_model, \"predict_proba\") and len(best_model.predict_proba(X_test_scaled).shape) > 1:\n",
    "        y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        # Для моделей без predict_proba, ROC-AUC не может быть рассчитан.\n",
    "        # В таком случае, можно либо пропустить ROC-AUC, либо вернуть NaN.\n",
    "        # Для SVM, если probability=True не установлен при инициализации, его не будет.\n",
    "        # Для LogisticRegression и Tree-based моделей predict_proba всегда есть.\n",
    "        print(f\"Warning: Model {model_name} does not have predict_proba or it's not applicable. ROC-AUC will be NaN.\")\n",
    "        y_pred_proba = np.full_like(y_pred, np.nan, dtype=float) # Заполняем NaN для ROC-AUC\n",
    "\n",
    "    accuracy, precision, recall, f1, roc_auc = calculate_classification_metrics(y_test, y_pred, y_pred_proba)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'optimizer': optimizer_type,\n",
    "        'target': target_name,\n",
    "        'best_params': best_params,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "\n",
    "# --- Определение моделей и их гиперпараметров для разных оптимизаторов (адаптированные для классификации) ---\n",
    "models_config_classifier = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"class\": LogisticRegression,\n",
    "        \"random_dist\": {\n",
    "            'C': uniform(loc=0.1, scale=10),\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear']\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear']\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'C': trial.suggest_float('C', 0.1, 10.0, log=True),\n",
    "            'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
    "            'solver': 'liblinear',\n",
    "            'random_state': 42 # Добавлен random_state здесь, чтобы управлять им\n",
    "        }\n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"class\": RandomForestClassifier,\n",
    "        \"random_dist\": {\n",
    "            'n_estimators': randint(50, 200),\n",
    "            'max_depth': [5, 10, None],\n",
    "            'min_samples_split': randint(2, 8)\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'n_estimators': [100, 150],\n",
    "            'max_depth': [5, 10],\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [5, 10, 15, None]),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 8),\n",
    "            'random_state': 42\n",
    "        }\n",
    "    },\n",
    "    \"XGBClassifier\": {\n",
    "        \"class\": XGBClassifier,\n",
    "        \"random_dist\": {\n",
    "            'n_estimators': randint(50, 200),\n",
    "            'learning_rate': uniform(0.01, 0.15),\n",
    "            'max_depth': randint(3, 8),\n",
    "            'subsample': uniform(0.7, 0.3),\n",
    "            'use_label_encoder': [False]\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'n_estimators': [100, 150],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'max_depth': [3, 5],\n",
    "            'use_label_encoder': [False]\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'eval_metric': 'logloss',\n",
    "            'n_jobs': -1,\n",
    "            'random_state': 42,\n",
    "            'use_label_encoder': False\n",
    "        }\n",
    "    },\n",
    "    \"CatBoostClassifier\": {\n",
    "        \"class\": CatBoostClassifier,\n",
    "        \"random_dist\": {\n",
    "            'iterations': randint(50, 200),\n",
    "            'learning_rate': uniform(0.01, 0.15),\n",
    "            'depth': randint(3, 8),\n",
    "            'l2_leaf_reg': uniform(1, 7)\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'iterations': [100, 150],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'depth': [3, 5]\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'iterations': trial.suggest_int('iterations', 50, 200),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15, log=True),\n",
    "            'depth': trial.suggest_int('depth', 3, 8),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 10, log=True),\n",
    "            'verbose': False,\n",
    "            'random_seed': 42, # CatBoost uses random_seed\n",
    "            'thread_count': -1,\n",
    "            'objective': 'Logloss'\n",
    "        }\n",
    "    },\n",
    "    \"MLPClassifier\": {\n",
    "        \"class\": MLPClassifier,\n",
    "        \"random_dist\": {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "            'alpha': uniform(0.0001, 0.005),\n",
    "            'learning_rate_init': uniform(0.0001, 0.005)\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'hidden_layer_sizes': [(50,), (100,)],\n",
    "            'alpha': [0.0001, 0.001]\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50)]),\n",
    "            'alpha': trial.suggest_float('alpha', 1e-5, 1e-2, log=True),\n",
    "            'learning_rate_init': trial.suggest_float('learning_rate_init', 1e-4, 1e-2, log=True),\n",
    "            'max_iter': 2000,\n",
    "            'random_state': 42,\n",
    "            'solver': 'adam'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65441089-d139-4982-9de4-11c9d5367183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем процесс обучения и оценки моделей классификации...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fee2e68af954389a373970e121cb650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Прогнозирование задач классификации:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Оптимизация для is_SI_above_8 (PCA Aggregated):   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:04:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6398639\ttotal: 149ms\tremaining: 26.9s\n",
      "1:\tlearn: 0.5829765\ttotal: 153ms\tremaining: 13.7s\n",
      "2:\tlearn: 0.5437484\ttotal: 159ms\tremaining: 9.43s\n",
      "3:\tlearn: 0.4918354\ttotal: 163ms\tremaining: 7.2s\n",
      "4:\tlearn: 0.4495544\ttotal: 168ms\tremaining: 5.91s\n",
      "5:\tlearn: 0.4124100\ttotal: 174ms\tremaining: 5.06s\n",
      "6:\tlearn: 0.3901831\ttotal: 179ms\tremaining: 4.45s\n",
      "7:\tlearn: 0.3674915\ttotal: 184ms\tremaining: 3.98s\n",
      "8:\tlearn: 0.3518825\ttotal: 188ms\tremaining: 3.6s\n",
      "9:\tlearn: 0.3460591\ttotal: 193ms\tremaining: 3.3s\n",
      "10:\tlearn: 0.3311690\ttotal: 198ms\tremaining: 3.06s\n",
      "11:\tlearn: 0.3142591\ttotal: 202ms\tremaining: 2.85s\n",
      "12:\tlearn: 0.2990650\ttotal: 207ms\tremaining: 2.67s\n",
      "13:\tlearn: 0.2848858\ttotal: 211ms\tremaining: 2.52s\n",
      "14:\tlearn: 0.2748331\ttotal: 216ms\tremaining: 2.4s\n",
      "15:\tlearn: 0.2583442\ttotal: 221ms\tremaining: 2.28s\n",
      "16:\tlearn: 0.2528650\ttotal: 226ms\tremaining: 2.18s\n",
      "17:\tlearn: 0.2457677\ttotal: 232ms\tremaining: 2.1s\n",
      "18:\tlearn: 0.2289919\ttotal: 237ms\tremaining: 2.02s\n",
      "19:\tlearn: 0.2218692\ttotal: 241ms\tremaining: 1.94s\n",
      "20:\tlearn: 0.2167431\ttotal: 247ms\tremaining: 1.88s\n",
      "21:\tlearn: 0.2043118\ttotal: 252ms\tremaining: 1.82s\n",
      "22:\tlearn: 0.2024585\ttotal: 257ms\tremaining: 1.76s\n",
      "23:\tlearn: 0.1930136\ttotal: 262ms\tremaining: 1.71s\n",
      "24:\tlearn: 0.1906242\ttotal: 266ms\tremaining: 1.66s\n",
      "25:\tlearn: 0.1869461\ttotal: 271ms\tremaining: 1.62s\n",
      "26:\tlearn: 0.1855320\ttotal: 277ms\tremaining: 1.58s\n",
      "27:\tlearn: 0.1840988\ttotal: 281ms\tremaining: 1.54s\n",
      "28:\tlearn: 0.1808405\ttotal: 286ms\tremaining: 1.5s\n",
      "29:\tlearn: 0.1740837\ttotal: 290ms\tremaining: 1.46s\n",
      "30:\tlearn: 0.1678493\ttotal: 296ms\tremaining: 1.43s\n",
      "31:\tlearn: 0.1639445\ttotal: 301ms\tremaining: 1.4s\n",
      "32:\tlearn: 0.1616953\ttotal: 307ms\tremaining: 1.38s\n",
      "33:\tlearn: 0.1605642\ttotal: 313ms\tremaining: 1.35s\n",
      "34:\tlearn: 0.1583078\ttotal: 317ms\tremaining: 1.32s\n",
      "35:\tlearn: 0.1545744\ttotal: 321ms\tremaining: 1.29s\n",
      "36:\tlearn: 0.1514131\ttotal: 328ms\tremaining: 1.27s\n",
      "37:\tlearn: 0.1497020\ttotal: 334ms\tremaining: 1.26s\n",
      "38:\tlearn: 0.1491722\ttotal: 338ms\tremaining: 1.23s\n",
      "39:\tlearn: 0.1485172\ttotal: 344ms\tremaining: 1.21s\n",
      "40:\tlearn: 0.1454749\ttotal: 348ms\tremaining: 1.19s\n",
      "41:\tlearn: 0.1448488\ttotal: 353ms\tremaining: 1.17s\n",
      "42:\tlearn: 0.1445667\ttotal: 361ms\tremaining: 1.16s\n",
      "43:\tlearn: 0.1428094\ttotal: 365ms\tremaining: 1.14s\n",
      "44:\tlearn: 0.1387262\ttotal: 369ms\tremaining: 1.12s\n",
      "45:\tlearn: 0.1375234\ttotal: 375ms\tremaining: 1.1s\n",
      "46:\tlearn: 0.1347523\ttotal: 380ms\tremaining: 1.08s\n",
      "47:\tlearn: 0.1339467\ttotal: 386ms\tremaining: 1.07s\n",
      "48:\tlearn: 0.1313776\ttotal: 392ms\tremaining: 1.05s\n",
      "49:\tlearn: 0.1280544\ttotal: 396ms\tremaining: 1.04s\n",
      "50:\tlearn: 0.1271065\ttotal: 401ms\tremaining: 1.02s\n",
      "51:\tlearn: 0.1214013\ttotal: 407ms\tremaining: 1.01s\n",
      "52:\tlearn: 0.1184638\ttotal: 413ms\tremaining: 996ms\n",
      "53:\tlearn: 0.1167985\ttotal: 419ms\tremaining: 985ms\n",
      "54:\tlearn: 0.1158018\ttotal: 425ms\tremaining: 973ms\n",
      "55:\tlearn: 0.1155874\ttotal: 431ms\tremaining: 961ms\n",
      "56:\tlearn: 0.1148928\ttotal: 436ms\tremaining: 948ms\n",
      "57:\tlearn: 0.1139438\ttotal: 441ms\tremaining: 934ms\n",
      "58:\tlearn: 0.1136739\ttotal: 448ms\tremaining: 926ms\n",
      "59:\tlearn: 0.1126494\ttotal: 453ms\tremaining: 913ms\n",
      "60:\tlearn: 0.1108304\ttotal: 458ms\tremaining: 901ms\n",
      "61:\tlearn: 0.1095904\ttotal: 463ms\tremaining: 889ms\n",
      "62:\tlearn: 0.1088163\ttotal: 469ms\tremaining: 878ms\n",
      "63:\tlearn: 0.1084001\ttotal: 474ms\tremaining: 867ms\n",
      "64:\tlearn: 0.1060514\ttotal: 479ms\tremaining: 855ms\n",
      "65:\tlearn: 0.1041372\ttotal: 485ms\tremaining: 845ms\n",
      "66:\tlearn: 0.1013812\ttotal: 489ms\tremaining: 833ms\n",
      "67:\tlearn: 0.1007641\ttotal: 496ms\tremaining: 824ms\n",
      "68:\tlearn: 0.0986014\ttotal: 501ms\tremaining: 813ms\n",
      "69:\tlearn: 0.0984965\ttotal: 505ms\tremaining: 801ms\n",
      "70:\tlearn: 0.0954840\ttotal: 511ms\tremaining: 791ms\n",
      "71:\tlearn: 0.0944649\ttotal: 516ms\tremaining: 781ms\n",
      "72:\tlearn: 0.0930985\ttotal: 521ms\tremaining: 771ms\n",
      "73:\tlearn: 0.0924018\ttotal: 526ms\tremaining: 761ms\n",
      "74:\tlearn: 0.0919168\ttotal: 531ms\tremaining: 751ms\n",
      "75:\tlearn: 0.0917664\ttotal: 537ms\tremaining: 742ms\n",
      "76:\tlearn: 0.0892892\ttotal: 542ms\tremaining: 732ms\n",
      "77:\tlearn: 0.0878116\ttotal: 547ms\tremaining: 723ms\n",
      "78:\tlearn: 0.0869641\ttotal: 554ms\tremaining: 715ms\n",
      "79:\tlearn: 0.0868885\ttotal: 557ms\tremaining: 704ms\n",
      "80:\tlearn: 0.0865918\ttotal: 563ms\tremaining: 695ms\n",
      "81:\tlearn: 0.0860262\ttotal: 569ms\tremaining: 687ms\n",
      "82:\tlearn: 0.0853487\ttotal: 574ms\tremaining: 678ms\n",
      "83:\tlearn: 0.0836895\ttotal: 578ms\tremaining: 668ms\n",
      "84:\tlearn: 0.0836252\ttotal: 584ms\tremaining: 660ms\n",
      "85:\tlearn: 0.0821255\ttotal: 590ms\tremaining: 651ms\n",
      "86:\tlearn: 0.0798746\ttotal: 595ms\tremaining: 642ms\n",
      "87:\tlearn: 0.0770372\ttotal: 600ms\tremaining: 634ms\n",
      "88:\tlearn: 0.0741804\ttotal: 606ms\tremaining: 627ms\n",
      "89:\tlearn: 0.0731011\ttotal: 611ms\tremaining: 617ms\n",
      "90:\tlearn: 0.0721639\ttotal: 616ms\tremaining: 609ms\n",
      "91:\tlearn: 0.0720956\ttotal: 622ms\tremaining: 602ms\n",
      "92:\tlearn: 0.0720473\ttotal: 627ms\tremaining: 593ms\n",
      "93:\tlearn: 0.0719652\ttotal: 631ms\tremaining: 584ms\n",
      "94:\tlearn: 0.0698590\ttotal: 634ms\tremaining: 574ms\n",
      "95:\tlearn: 0.0679370\ttotal: 640ms\tremaining: 567ms\n",
      "96:\tlearn: 0.0653717\ttotal: 645ms\tremaining: 559ms\n",
      "97:\tlearn: 0.0648709\ttotal: 652ms\tremaining: 552ms\n",
      "98:\tlearn: 0.0631726\ttotal: 658ms\tremaining: 545ms\n",
      "99:\tlearn: 0.0622494\ttotal: 663ms\tremaining: 537ms\n",
      "100:\tlearn: 0.0616185\ttotal: 669ms\tremaining: 530ms\n",
      "101:\tlearn: 0.0614843\ttotal: 673ms\tremaining: 521ms\n",
      "102:\tlearn: 0.0614400\ttotal: 678ms\tremaining: 514ms\n",
      "103:\tlearn: 0.0602896\ttotal: 683ms\tremaining: 506ms\n",
      "104:\tlearn: 0.0584953\ttotal: 688ms\tremaining: 498ms\n",
      "105:\tlearn: 0.0583281\ttotal: 694ms\tremaining: 491ms\n",
      "106:\tlearn: 0.0581068\ttotal: 700ms\tremaining: 484ms\n",
      "107:\tlearn: 0.0568834\ttotal: 705ms\tremaining: 476ms\n",
      "108:\tlearn: 0.0567491\ttotal: 711ms\tremaining: 470ms\n",
      "109:\tlearn: 0.0561997\ttotal: 717ms\tremaining: 463ms\n",
      "110:\tlearn: 0.0560209\ttotal: 721ms\tremaining: 455ms\n",
      "111:\tlearn: 0.0559647\ttotal: 728ms\tremaining: 448ms\n",
      "112:\tlearn: 0.0547406\ttotal: 732ms\tremaining: 441ms\n",
      "113:\tlearn: 0.0547129\ttotal: 736ms\tremaining: 433ms\n",
      "114:\tlearn: 0.0544695\ttotal: 742ms\tremaining: 426ms\n",
      "115:\tlearn: 0.0534454\ttotal: 747ms\tremaining: 419ms\n",
      "116:\tlearn: 0.0520333\ttotal: 751ms\tremaining: 411ms\n",
      "117:\tlearn: 0.0519027\ttotal: 757ms\tremaining: 404ms\n",
      "118:\tlearn: 0.0518694\ttotal: 763ms\tremaining: 397ms\n",
      "119:\tlearn: 0.0508544\ttotal: 769ms\tremaining: 391ms\n",
      "120:\tlearn: 0.0504914\ttotal: 774ms\tremaining: 384ms\n",
      "121:\tlearn: 0.0502822\ttotal: 779ms\tremaining: 377ms\n",
      "122:\tlearn: 0.0502152\ttotal: 784ms\tremaining: 370ms\n",
      "123:\tlearn: 0.0497809\ttotal: 789ms\tremaining: 363ms\n",
      "124:\tlearn: 0.0497243\ttotal: 793ms\tremaining: 355ms\n",
      "125:\tlearn: 0.0488892\ttotal: 798ms\tremaining: 348ms\n",
      "126:\tlearn: 0.0488665\ttotal: 804ms\tremaining: 342ms\n",
      "127:\tlearn: 0.0481181\ttotal: 809ms\tremaining: 335ms\n",
      "128:\tlearn: 0.0478475\ttotal: 814ms\tremaining: 328ms\n",
      "129:\tlearn: 0.0468694\ttotal: 818ms\tremaining: 321ms\n",
      "130:\tlearn: 0.0464966\ttotal: 822ms\tremaining: 314ms\n",
      "131:\tlearn: 0.0464167\ttotal: 827ms\tremaining: 307ms\n",
      "132:\tlearn: 0.0460153\ttotal: 831ms\tremaining: 300ms\n",
      "133:\tlearn: 0.0450546\ttotal: 835ms\tremaining: 293ms\n",
      "134:\tlearn: 0.0446805\ttotal: 840ms\tremaining: 286ms\n",
      "135:\tlearn: 0.0446621\ttotal: 844ms\tremaining: 279ms\n",
      "136:\tlearn: 0.0446444\ttotal: 849ms\tremaining: 273ms\n",
      "137:\tlearn: 0.0445096\ttotal: 853ms\tremaining: 266ms\n",
      "138:\tlearn: 0.0438037\ttotal: 858ms\tremaining: 259ms\n",
      "139:\tlearn: 0.0437650\ttotal: 863ms\tremaining: 253ms\n",
      "140:\tlearn: 0.0437177\ttotal: 867ms\tremaining: 246ms\n",
      "141:\tlearn: 0.0436864\ttotal: 872ms\tremaining: 239ms\n",
      "142:\tlearn: 0.0428890\ttotal: 877ms\tremaining: 233ms\n",
      "143:\tlearn: 0.0428404\ttotal: 881ms\tremaining: 226ms\n",
      "144:\tlearn: 0.0427804\ttotal: 887ms\tremaining: 220ms\n",
      "145:\tlearn: 0.0427522\ttotal: 891ms\tremaining: 214ms\n",
      "146:\tlearn: 0.0427208\ttotal: 896ms\tremaining: 207ms\n",
      "147:\tlearn: 0.0426854\ttotal: 901ms\tremaining: 201ms\n",
      "148:\tlearn: 0.0423554\ttotal: 905ms\tremaining: 194ms\n",
      "149:\tlearn: 0.0419461\ttotal: 910ms\tremaining: 188ms\n",
      "150:\tlearn: 0.0418535\ttotal: 916ms\tremaining: 182ms\n",
      "151:\tlearn: 0.0416637\ttotal: 921ms\tremaining: 176ms\n",
      "152:\tlearn: 0.0416146\ttotal: 925ms\tremaining: 169ms\n",
      "153:\tlearn: 0.0415876\ttotal: 930ms\tremaining: 163ms\n",
      "154:\tlearn: 0.0410733\ttotal: 935ms\tremaining: 157ms\n",
      "155:\tlearn: 0.0405413\ttotal: 939ms\tremaining: 151ms\n",
      "156:\tlearn: 0.0404912\ttotal: 945ms\tremaining: 144ms\n",
      "157:\tlearn: 0.0402956\ttotal: 950ms\tremaining: 138ms\n",
      "158:\tlearn: 0.0402475\ttotal: 955ms\tremaining: 132ms\n",
      "159:\tlearn: 0.0393544\ttotal: 960ms\tremaining: 126ms\n",
      "160:\tlearn: 0.0392704\ttotal: 965ms\tremaining: 120ms\n",
      "161:\tlearn: 0.0388266\ttotal: 969ms\tremaining: 114ms\n",
      "162:\tlearn: 0.0385444\ttotal: 974ms\tremaining: 108ms\n",
      "163:\tlearn: 0.0385199\ttotal: 978ms\tremaining: 101ms\n",
      "164:\tlearn: 0.0375724\ttotal: 983ms\tremaining: 95.3ms\n",
      "165:\tlearn: 0.0372049\ttotal: 988ms\tremaining: 89.3ms\n",
      "166:\tlearn: 0.0371632\ttotal: 993ms\tremaining: 83.3ms\n",
      "167:\tlearn: 0.0369582\ttotal: 997ms\tremaining: 77.1ms\n",
      "168:\tlearn: 0.0367721\ttotal: 1s\tremaining: 71.1ms\n",
      "169:\tlearn: 0.0367375\ttotal: 1s\tremaining: 65ms\n",
      "170:\tlearn: 0.0365664\ttotal: 1.01s\tremaining: 59ms\n",
      "171:\tlearn: 0.0361709\ttotal: 1.01s\tremaining: 53ms\n",
      "172:\tlearn: 0.0361271\ttotal: 1.01s\tremaining: 47ms\n",
      "173:\tlearn: 0.0360661\ttotal: 1.02s\tremaining: 41ms\n",
      "174:\tlearn: 0.0357193\ttotal: 1.02s\tremaining: 35.1ms\n",
      "175:\tlearn: 0.0356886\ttotal: 1.03s\tremaining: 29.2ms\n",
      "176:\tlearn: 0.0356581\ttotal: 1.03s\tremaining: 23.3ms\n",
      "177:\tlearn: 0.0353642\ttotal: 1.03s\tremaining: 17.4ms\n",
      "178:\tlearn: 0.0353555\ttotal: 1.04s\tremaining: 11.6ms\n",
      "179:\tlearn: 0.0352442\ttotal: 1.04s\tremaining: 5.81ms\n",
      "180:\tlearn: 0.0350257\ttotal: 1.05s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6357742\ttotal: 7.47ms\tremaining: 1.11s\n",
      "1:\tlearn: 0.5621494\ttotal: 14ms\tremaining: 1.03s\n",
      "2:\tlearn: 0.4912701\ttotal: 19.9ms\tremaining: 976ms\n",
      "3:\tlearn: 0.4284259\ttotal: 25.9ms\tremaining: 946ms\n",
      "4:\tlearn: 0.3980988\ttotal: 32.5ms\tremaining: 943ms\n",
      "5:\tlearn: 0.3668693\ttotal: 39.4ms\tremaining: 944ms\n",
      "6:\tlearn: 0.3380212\ttotal: 45.7ms\tremaining: 934ms\n",
      "7:\tlearn: 0.3137681\ttotal: 52.6ms\tremaining: 935ms\n",
      "8:\tlearn: 0.2960931\ttotal: 58.9ms\tremaining: 923ms\n",
      "9:\tlearn: 0.2819997\ttotal: 65.9ms\tremaining: 922ms\n",
      "10:\tlearn: 0.2751172\ttotal: 74.1ms\tremaining: 936ms\n",
      "11:\tlearn: 0.2692007\ttotal: 81ms\tremaining: 931ms\n",
      "12:\tlearn: 0.2529399\ttotal: 87.4ms\tremaining: 921ms\n",
      "13:\tlearn: 0.2438624\ttotal: 93.7ms\tremaining: 911ms\n",
      "14:\tlearn: 0.2262857\ttotal: 102ms\tremaining: 917ms\n",
      "15:\tlearn: 0.2222916\ttotal: 107ms\tremaining: 899ms\n",
      "16:\tlearn: 0.2055444\ttotal: 113ms\tremaining: 888ms\n",
      "17:\tlearn: 0.1988989\ttotal: 121ms\tremaining: 888ms\n",
      "18:\tlearn: 0.1959917\ttotal: 128ms\tremaining: 884ms\n",
      "19:\tlearn: 0.1875349\ttotal: 135ms\tremaining: 877ms\n",
      "20:\tlearn: 0.1774019\ttotal: 141ms\tremaining: 867ms\n",
      "21:\tlearn: 0.1729071\ttotal: 149ms\tremaining: 865ms\n",
      "22:\tlearn: 0.1687671\ttotal: 154ms\tremaining: 852ms\n",
      "23:\tlearn: 0.1622931\ttotal: 162ms\tremaining: 851ms\n",
      "24:\tlearn: 0.1579448\ttotal: 169ms\tremaining: 844ms\n",
      "25:\tlearn: 0.1536490\ttotal: 177ms\tremaining: 843ms\n",
      "26:\tlearn: 0.1480384\ttotal: 184ms\tremaining: 839ms\n",
      "27:\tlearn: 0.1452357\ttotal: 192ms\tremaining: 836ms\n",
      "28:\tlearn: 0.1428374\ttotal: 199ms\tremaining: 829ms\n",
      "29:\tlearn: 0.1412627\ttotal: 206ms\tremaining: 824ms\n",
      "30:\tlearn: 0.1389480\ttotal: 212ms\tremaining: 815ms\n",
      "31:\tlearn: 0.1345700\ttotal: 219ms\tremaining: 807ms\n",
      "32:\tlearn: 0.1291777\ttotal: 225ms\tremaining: 796ms\n",
      "33:\tlearn: 0.1255404\ttotal: 231ms\tremaining: 789ms\n",
      "34:\tlearn: 0.1251989\ttotal: 238ms\tremaining: 782ms\n",
      "35:\tlearn: 0.1239225\ttotal: 243ms\tremaining: 770ms\n",
      "36:\tlearn: 0.1229543\ttotal: 249ms\tremaining: 760ms\n",
      "37:\tlearn: 0.1194406\ttotal: 255ms\tremaining: 752ms\n",
      "38:\tlearn: 0.1159931\ttotal: 263ms\tremaining: 748ms\n",
      "39:\tlearn: 0.1122374\ttotal: 269ms\tremaining: 739ms\n",
      "40:\tlearn: 0.1111490\ttotal: 273ms\tremaining: 726ms\n",
      "41:\tlearn: 0.1097797\ttotal: 279ms\tremaining: 717ms\n",
      "42:\tlearn: 0.1090095\ttotal: 285ms\tremaining: 709ms\n",
      "43:\tlearn: 0.1079938\ttotal: 291ms\tremaining: 702ms\n",
      "44:\tlearn: 0.1053945\ttotal: 298ms\tremaining: 695ms\n",
      "45:\tlearn: 0.1047204\ttotal: 304ms\tremaining: 686ms\n",
      "46:\tlearn: 0.1034913\ttotal: 309ms\tremaining: 677ms\n",
      "47:\tlearn: 0.0999725\ttotal: 315ms\tremaining: 670ms\n",
      "48:\tlearn: 0.0984980\ttotal: 323ms\tremaining: 665ms\n",
      "49:\tlearn: 0.0964353\ttotal: 328ms\tremaining: 657ms\n",
      "50:\tlearn: 0.0953592\ttotal: 335ms\tremaining: 650ms\n",
      "51:\tlearn: 0.0933632\ttotal: 341ms\tremaining: 642ms\n",
      "52:\tlearn: 0.0924090\ttotal: 346ms\tremaining: 632ms\n",
      "53:\tlearn: 0.0920268\ttotal: 352ms\tremaining: 626ms\n",
      "54:\tlearn: 0.0881287\ttotal: 359ms\tremaining: 619ms\n",
      "55:\tlearn: 0.0878995\ttotal: 364ms\tremaining: 611ms\n",
      "56:\tlearn: 0.0875263\ttotal: 372ms\tremaining: 606ms\n",
      "57:\tlearn: 0.0867089\ttotal: 378ms\tremaining: 600ms\n",
      "58:\tlearn: 0.0853791\ttotal: 386ms\tremaining: 595ms\n",
      "59:\tlearn: 0.0816495\ttotal: 391ms\tremaining: 587ms\n",
      "60:\tlearn: 0.0794918\ttotal: 399ms\tremaining: 582ms\n",
      "61:\tlearn: 0.0785564\ttotal: 405ms\tremaining: 575ms\n",
      "62:\tlearn: 0.0757200\ttotal: 411ms\tremaining: 568ms\n",
      "63:\tlearn: 0.0747612\ttotal: 418ms\tremaining: 562ms\n",
      "64:\tlearn: 0.0742268\ttotal: 426ms\tremaining: 557ms\n",
      "65:\tlearn: 0.0709553\ttotal: 433ms\tremaining: 551ms\n",
      "66:\tlearn: 0.0707234\ttotal: 441ms\tremaining: 547ms\n",
      "67:\tlearn: 0.0693829\ttotal: 448ms\tremaining: 540ms\n",
      "68:\tlearn: 0.0692129\ttotal: 455ms\tremaining: 534ms\n",
      "69:\tlearn: 0.0667629\ttotal: 461ms\tremaining: 527ms\n",
      "70:\tlearn: 0.0661724\ttotal: 468ms\tremaining: 520ms\n",
      "71:\tlearn: 0.0653638\ttotal: 475ms\tremaining: 515ms\n",
      "72:\tlearn: 0.0644819\ttotal: 481ms\tremaining: 507ms\n",
      "73:\tlearn: 0.0643281\ttotal: 489ms\tremaining: 502ms\n",
      "74:\tlearn: 0.0642095\ttotal: 495ms\tremaining: 495ms\n",
      "75:\tlearn: 0.0603852\ttotal: 501ms\tremaining: 487ms\n",
      "76:\tlearn: 0.0599601\ttotal: 507ms\tremaining: 481ms\n",
      "77:\tlearn: 0.0586738\ttotal: 514ms\tremaining: 474ms\n",
      "78:\tlearn: 0.0560830\ttotal: 521ms\tremaining: 468ms\n",
      "79:\tlearn: 0.0547744\ttotal: 527ms\tremaining: 461ms\n",
      "80:\tlearn: 0.0518913\ttotal: 535ms\tremaining: 455ms\n",
      "81:\tlearn: 0.0511563\ttotal: 540ms\tremaining: 448ms\n",
      "82:\tlearn: 0.0509867\ttotal: 548ms\tremaining: 442ms\n",
      "83:\tlearn: 0.0508747\ttotal: 554ms\tremaining: 435ms\n",
      "84:\tlearn: 0.0490119\ttotal: 560ms\tremaining: 428ms\n",
      "85:\tlearn: 0.0485394\ttotal: 567ms\tremaining: 422ms\n",
      "86:\tlearn: 0.0484245\ttotal: 573ms\tremaining: 415ms\n",
      "87:\tlearn: 0.0483473\ttotal: 580ms\tremaining: 408ms\n",
      "88:\tlearn: 0.0482423\ttotal: 586ms\tremaining: 402ms\n",
      "89:\tlearn: 0.0470330\ttotal: 594ms\tremaining: 396ms\n",
      "90:\tlearn: 0.0467302\ttotal: 600ms\tremaining: 389ms\n",
      "91:\tlearn: 0.0466353\ttotal: 607ms\tremaining: 383ms\n",
      "92:\tlearn: 0.0450178\ttotal: 613ms\tremaining: 376ms\n",
      "93:\tlearn: 0.0437533\ttotal: 619ms\tremaining: 369ms\n",
      "94:\tlearn: 0.0436952\ttotal: 626ms\tremaining: 362ms\n",
      "95:\tlearn: 0.0435980\ttotal: 632ms\tremaining: 355ms\n",
      "96:\tlearn: 0.0425899\ttotal: 638ms\tremaining: 349ms\n",
      "97:\tlearn: 0.0408339\ttotal: 645ms\tremaining: 342ms\n",
      "98:\tlearn: 0.0404056\ttotal: 650ms\tremaining: 335ms\n",
      "99:\tlearn: 0.0390298\ttotal: 656ms\tremaining: 328ms\n",
      "100:\tlearn: 0.0380625\ttotal: 663ms\tremaining: 322ms\n",
      "101:\tlearn: 0.0374260\ttotal: 670ms\tremaining: 315ms\n",
      "102:\tlearn: 0.0372927\ttotal: 675ms\tremaining: 308ms\n",
      "103:\tlearn: 0.0372550\ttotal: 682ms\tremaining: 302ms\n",
      "104:\tlearn: 0.0372187\ttotal: 689ms\tremaining: 295ms\n",
      "105:\tlearn: 0.0369744\ttotal: 697ms\tremaining: 289ms\n",
      "106:\tlearn: 0.0360198\ttotal: 703ms\tremaining: 282ms\n",
      "107:\tlearn: 0.0359562\ttotal: 710ms\tremaining: 276ms\n",
      "108:\tlearn: 0.0358618\ttotal: 716ms\tremaining: 269ms\n",
      "109:\tlearn: 0.0357895\ttotal: 722ms\tremaining: 263ms\n",
      "110:\tlearn: 0.0347372\ttotal: 730ms\tremaining: 256ms\n",
      "111:\tlearn: 0.0342192\ttotal: 736ms\tremaining: 250ms\n",
      "112:\tlearn: 0.0340260\ttotal: 743ms\tremaining: 243ms\n",
      "113:\tlearn: 0.0338587\ttotal: 748ms\tremaining: 236ms\n",
      "114:\tlearn: 0.0338309\ttotal: 755ms\tremaining: 230ms\n",
      "115:\tlearn: 0.0327069\ttotal: 761ms\tremaining: 223ms\n",
      "116:\tlearn: 0.0326530\ttotal: 766ms\tremaining: 216ms\n",
      "117:\tlearn: 0.0326285\ttotal: 774ms\tremaining: 210ms\n",
      "118:\tlearn: 0.0323556\ttotal: 780ms\tremaining: 203ms\n",
      "119:\tlearn: 0.0314791\ttotal: 786ms\tremaining: 197ms\n",
      "120:\tlearn: 0.0314569\ttotal: 793ms\tremaining: 190ms\n",
      "121:\tlearn: 0.0313637\ttotal: 799ms\tremaining: 183ms\n",
      "122:\tlearn: 0.0310528\ttotal: 806ms\tremaining: 177ms\n",
      "123:\tlearn: 0.0309762\ttotal: 812ms\tremaining: 170ms\n",
      "124:\tlearn: 0.0302520\ttotal: 819ms\tremaining: 164ms\n",
      "125:\tlearn: 0.0294726\ttotal: 824ms\tremaining: 157ms\n",
      "126:\tlearn: 0.0289052\ttotal: 832ms\tremaining: 151ms\n",
      "127:\tlearn: 0.0281390\ttotal: 839ms\tremaining: 144ms\n",
      "128:\tlearn: 0.0275177\ttotal: 846ms\tremaining: 138ms\n",
      "129:\tlearn: 0.0274622\ttotal: 854ms\tremaining: 131ms\n",
      "130:\tlearn: 0.0274129\ttotal: 860ms\tremaining: 125ms\n",
      "131:\tlearn: 0.0270548\ttotal: 866ms\tremaining: 118ms\n",
      "132:\tlearn: 0.0269519\ttotal: 872ms\tremaining: 111ms\n",
      "133:\tlearn: 0.0261523\ttotal: 879ms\tremaining: 105ms\n",
      "134:\tlearn: 0.0251710\ttotal: 886ms\tremaining: 98.4ms\n",
      "135:\tlearn: 0.0251412\ttotal: 892ms\tremaining: 91.9ms\n",
      "136:\tlearn: 0.0250952\ttotal: 899ms\tremaining: 85.3ms\n",
      "137:\tlearn: 0.0243541\ttotal: 905ms\tremaining: 78.7ms\n",
      "138:\tlearn: 0.0240049\ttotal: 912ms\tremaining: 72.2ms\n",
      "139:\tlearn: 0.0237092\ttotal: 918ms\tremaining: 65.6ms\n",
      "140:\tlearn: 0.0236662\ttotal: 924ms\tremaining: 59ms\n",
      "141:\tlearn: 0.0236261\ttotal: 930ms\tremaining: 52.4ms\n",
      "142:\tlearn: 0.0233902\ttotal: 936ms\tremaining: 45.8ms\n",
      "143:\tlearn: 0.0231378\ttotal: 942ms\tremaining: 39.3ms\n",
      "144:\tlearn: 0.0227560\ttotal: 950ms\tremaining: 32.8ms\n",
      "145:\tlearn: 0.0226510\ttotal: 958ms\tremaining: 26.2ms\n",
      "146:\tlearn: 0.0222627\ttotal: 966ms\tremaining: 19.7ms\n",
      "147:\tlearn: 0.0222307\ttotal: 972ms\tremaining: 13.1ms\n",
      "148:\tlearn: 0.0220335\ttotal: 979ms\tremaining: 6.57ms\n",
      "149:\tlearn: 0.0214960\ttotal: 984ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-06-18 20:05:35,831] A new study created in memory with name: no-name-9c1722e5-3ee6-4c1a-bfcf-8ebb6081253e\n",
      "[I 2025-06-18 20:05:35,967] Trial 0 finished with value: -0.9964607900143829 and parameters: {'C': 0.5611516415334505, 'penalty': 'l1'}. Best is trial 0 with value: -0.9964607900143829.\n",
      "[I 2025-06-18 20:05:36,227] Trial 1 finished with value: -0.9934661137374443 and parameters: {'C': 1.5751320499779735, 'penalty': 'l1'}. Best is trial 0 with value: -0.9964607900143829.\n",
      "[I 2025-06-18 20:05:36,312] Trial 2 finished with value: -0.9984337530053693 and parameters: {'C': 0.13066739238053282, 'penalty': 'l1'}. Best is trial 2 with value: -0.9984337530053693.\n",
      "[I 2025-06-18 20:05:36,604] Trial 3 finished with value: -0.9803895311053783 and parameters: {'C': 2.607024758370768, 'penalty': 'l2'}. Best is trial 2 with value: -0.9984337530053693.\n",
      "[I 2025-06-18 20:05:37,129] Trial 4 finished with value: -0.9908794490608253 and parameters: {'C': 4.622589001020832, 'penalty': 'l1'}. Best is trial 2 with value: -0.9984337530053693.\n",
      "[I 2025-06-18 20:05:37,315] Trial 5 finished with value: -0.9750804570061599 and parameters: {'C': 0.2327067708383781, 'penalty': 'l2'}. Best is trial 2 with value: -0.9984337530053693.\n",
      "[I 2025-06-18 20:05:37,569] Trial 6 finished with value: -0.9781094581507828 and parameters: {'C': 0.7309539835912913, 'penalty': 'l2'}. Best is trial 2 with value: -0.9984337530053693.\n",
      "[I 2025-06-18 20:05:37,753] Trial 7 finished with value: -0.9741970796741158 and parameters: {'C': 0.19010245319870356, 'penalty': 'l2'}. Best is trial 2 with value: -0.9984337530053693.\n",
      "[I 2025-06-18 20:05:37,925] Trial 8 finished with value: -0.9957454093296615 and parameters: {'C': 0.8168455894760165, 'penalty': 'l1'}. Best is trial 2 with value: -0.9984337530053693.\n",
      "[I 2025-06-18 20:05:38,114] Trial 9 finished with value: -0.9948264115259693 and parameters: {'C': 1.0677482709481354, 'penalty': 'l1'}. Best is trial 2 with value: -0.9984337530053693.\n",
      "[I 2025-06-18 20:05:38,208] Trial 10 finished with value: -0.9985018844991524 and parameters: {'C': 0.10991587445851024, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:05:38,306] Trial 11 finished with value: -0.9984678187522608 and parameters: {'C': 0.10353677627159782, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:05:38,399] Trial 12 finished with value: -0.9984678187522608 and parameters: {'C': 0.1069139322389136, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:05:38,516] Trial 13 finished with value: -0.9975157916848483 and parameters: {'C': 0.324255176142218, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:05:38,637] Trial 14 finished with value: -0.9975839231786313 and parameters: {'C': 0.31385189050357676, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:05:39,413] Trial 15 finished with value: -0.9905731164595946 and parameters: {'C': 8.611382274356343, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:05:39,510] Trial 16 finished with value: -0.9984678187522608 and parameters: {'C': 0.11141231165883378, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:05:39,645] Trial 17 finished with value: -0.9971072618429432 and parameters: {'C': 0.394134405489134, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:05:39,828] Trial 18 finished with value: -0.9737206774592204 and parameters: {'C': 0.1736216698299393, 'penalty': 'l2'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:05:39,944] Trial 19 finished with value: -0.9978567082745562 and parameters: {'C': 0.21086760429111312, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:05:39,971] A new study created in memory with name: no-name-53aaeba0-32bb-4af8-a179-30dc0efb05be\n",
      "[I 2025-06-18 20:05:42,738] Trial 0 finished with value: -0.845891415259036 and parameters: {'n_estimators': 106, 'max_depth': 5, 'min_samples_split': 3}. Best is trial 0 with value: -0.845891415259036.\n",
      "[I 2025-06-18 20:05:44,283] Trial 1 finished with value: -0.8419132373757213 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 0 with value: -0.845891415259036.\n",
      "[I 2025-06-18 20:05:50,311] Trial 2 finished with value: -0.8868683455621073 and parameters: {'n_estimators': 175, 'max_depth': None, 'min_samples_split': 5}. Best is trial 2 with value: -0.8868683455621073.\n",
      "[I 2025-06-18 20:05:53,844] Trial 3 finished with value: -0.8716934200247858 and parameters: {'n_estimators': 115, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 2 with value: -0.8868683455621073.\n",
      "[I 2025-06-18 20:05:56,711] Trial 4 finished with value: -0.8496012130999034 and parameters: {'n_estimators': 118, 'max_depth': 5, 'min_samples_split': 2}. Best is trial 2 with value: -0.8868683455621073.\n",
      "[I 2025-06-18 20:06:01,374] Trial 5 finished with value: -0.8797246444258107 and parameters: {'n_estimators': 141, 'max_depth': None, 'min_samples_split': 7}. Best is trial 2 with value: -0.8868683455621073.\n",
      "[I 2025-06-18 20:06:04,599] Trial 6 finished with value: -0.8696110044109269 and parameters: {'n_estimators': 95, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 2 with value: -0.8868683455621073.\n",
      "[I 2025-06-18 20:06:06,011] Trial 7 finished with value: -0.8467662416049182 and parameters: {'n_estimators': 55, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 2 with value: -0.8868683455621073.\n",
      "[I 2025-06-18 20:06:10,160] Trial 8 finished with value: -0.8802026013654629 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 2 with value: -0.8868683455621073.\n",
      "[I 2025-06-18 20:06:13,727] Trial 9 finished with value: -0.8537210955074327 and parameters: {'n_estimators': 140, 'max_depth': 5, 'min_samples_split': 4}. Best is trial 2 with value: -0.8868683455621073.\n",
      "[I 2025-06-18 20:06:20,114] Trial 10 finished with value: -0.8886126949149789 and parameters: {'n_estimators': 197, 'max_depth': None, 'min_samples_split': 6}. Best is trial 10 with value: -0.8886126949149789.\n",
      "[I 2025-06-18 20:06:26,400] Trial 11 finished with value: -0.8888844435277325 and parameters: {'n_estimators': 193, 'max_depth': None, 'min_samples_split': 6}. Best is trial 11 with value: -0.8888844435277325.\n",
      "[I 2025-06-18 20:06:32,672] Trial 12 finished with value: -0.887490339113109 and parameters: {'n_estimators': 198, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 11 with value: -0.8888844435277325.\n",
      "[I 2025-06-18 20:06:39,210] Trial 13 finished with value: -0.8883739755659457 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 6}. Best is trial 11 with value: -0.8888844435277325.\n",
      "[I 2025-06-18 20:06:44,847] Trial 14 finished with value: -0.8886756439929064 and parameters: {'n_estimators': 170, 'max_depth': None, 'min_samples_split': 6}. Best is trial 11 with value: -0.8888844435277325.\n",
      "[I 2025-06-18 20:06:50,162] Trial 15 finished with value: -0.8872815395782826 and parameters: {'n_estimators': 166, 'max_depth': None, 'min_samples_split': 6}. Best is trial 11 with value: -0.8888844435277325.\n",
      "[I 2025-06-18 20:06:55,769] Trial 16 finished with value: -0.8855844711327345 and parameters: {'n_estimators': 167, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 11 with value: -0.8888844435277325.\n",
      "[I 2025-06-18 20:07:01,437] Trial 17 finished with value: -0.8890529584166407 and parameters: {'n_estimators': 179, 'max_depth': None, 'min_samples_split': 4}. Best is trial 17 with value: -0.8890529584166407.\n",
      "[I 2025-06-18 20:07:06,837] Trial 18 finished with value: -0.8848458386755403 and parameters: {'n_estimators': 155, 'max_depth': None, 'min_samples_split': 3}. Best is trial 17 with value: -0.8890529584166407.\n",
      "[I 2025-06-18 20:07:12,732] Trial 19 finished with value: -0.8877254307710434 and parameters: {'n_estimators': 182, 'max_depth': None, 'min_samples_split': 4}. Best is trial 17 with value: -0.8890529584166407.\n",
      "[I 2025-06-18 20:07:14,146] A new study created in memory with name: no-name-babaa65d-6ba3-47bd-828a-9ab9f81cff7c\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:15,551] Trial 0 finished with value: -0.9948261524051762 and parameters: {'n_estimators': 106, 'learning_rate': 0.13125830316209655, 'max_depth': 7, 'subsample': 0.8795975452591109}. Best is trial 0 with value: -0.9948261524051762.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:16,306] Trial 1 finished with value: -0.9784969473843137 and parameters: {'n_estimators': 73, 'learning_rate': 0.015256811898068502, 'max_depth': 3, 'subsample': 0.9598528437324805}. Best is trial 0 with value: -0.9948261524051762.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:17,544] Trial 2 finished with value: -0.9924831303726537 and parameters: {'n_estimators': 140, 'learning_rate': 0.06803900745073706, 'max_depth': 3, 'subsample': 0.9909729556485982}. Best is trial 0 with value: -0.9948261524051762.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:19,682] Trial 3 finished with value: -0.9940158298619786 and parameters: {'n_estimators': 175, 'learning_rate': 0.01777174904859463, 'max_depth': 4, 'subsample': 0.7550213529560301}. Best is trial 0 with value: -0.9948261524051762.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:21,244] Trial 4 finished with value: -0.9939435524355108 and parameters: {'n_estimators': 95, 'learning_rate': 0.04141536110538596, 'max_depth': 5, 'subsample': 0.7873687420594125}. Best is trial 0 with value: -0.9948261524051762.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:23,450] Trial 5 finished with value: -0.9917401619608602 and parameters: {'n_estimators': 142, 'learning_rate': 0.01459007452373112, 'max_depth': 4, 'subsample': 0.8099085529881075}. Best is trial 0 with value: -0.9948261524051762.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:24,808] Trial 6 finished with value: -0.9948277071299332 and parameters: {'n_estimators': 118, 'learning_rate': 0.0838375512850209, 'max_depth': 4, 'subsample': 0.8542703315240835}. Best is trial 6 with value: -0.9948277071299332.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:27,679] Trial 7 finished with value: -0.991188113749191 and parameters: {'n_estimators': 139, 'learning_rate': 0.011340440501807348, 'max_depth': 6, 'subsample': 0.7511572371061874}. Best is trial 6 with value: -0.9948277071299332.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:28,844] Trial 8 finished with value: -0.9946904076591961 and parameters: {'n_estimators': 59, 'learning_rate': 0.13060986669773664, 'max_depth': 8, 'subsample': 0.9425192044349383}. Best is trial 6 with value: -0.9948277071299332.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:31,235] Trial 9 finished with value: -0.9875685331310118 and parameters: {'n_estimators': 95, 'learning_rate': 0.01302780710309028, 'max_depth': 7, 'subsample': 0.8320457481218804}. Best is trial 6 with value: -0.9948277071299332.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:33,634] Trial 10 finished with value: -0.9944516883101627 and parameters: {'n_estimators': 192, 'learning_rate': 0.06768269073143275, 'max_depth': 5, 'subsample': 0.8919394579380205}. Best is trial 6 with value: -0.9948277071299332.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:35,277] Trial 11 finished with value: -0.9949291270082293 and parameters: {'n_estimators': 109, 'learning_rate': 0.11681446704286463, 'max_depth': 7, 'subsample': 0.8833252799515279}. Best is trial 11 with value: -0.9949291270082293.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:37,795] Trial 12 finished with value: -0.9948953203821306 and parameters: {'n_estimators': 124, 'learning_rate': 0.07652586248387556, 'max_depth': 8, 'subsample': 0.88472111241213}. Best is trial 11 with value: -0.9949291270082293.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:41,335] Trial 13 finished with value: -0.994317498288939 and parameters: {'n_estimators': 170, 'learning_rate': 0.042061971002568886, 'max_depth': 8, 'subsample': 0.9239393389677505}. Best is trial 11 with value: -0.9949291270082293.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:43,524] Trial 14 finished with value: -0.9946560827915117 and parameters: {'n_estimators': 125, 'learning_rate': 0.09578882570706004, 'max_depth': 7, 'subsample': 0.8960663373785396}. Best is trial 11 with value: -0.9949291270082293.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:07:45,516] Trial 15 finished with value: -0.9916286363716456 and parameters: {'n_estimators': 75, 'learning_rate': 0.02550159780786631, 'max_depth': 8, 'subsample': 0.8488123936509142}. Best is trial 11 with value: -0.9949291270082293.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:07:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:08:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:08:20,332] Trial 16 finished with value: -0.9947595756361503 and parameters: {'n_estimators': 155, 'learning_rate': 0.05576395338221608, 'max_depth': 6, 'subsample': 0.9135933406640235}. Best is trial 11 with value: -0.9949291270082293.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:08:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:08:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:08:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:08:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:08:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:08:22,763] Trial 17 finished with value: -0.9942480711911921 and parameters: {'n_estimators': 111, 'learning_rate': 0.14768167654797504, 'max_depth': 7, 'subsample': 0.7197788901674507}. Best is trial 11 with value: -0.9949291270082293.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:08:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:08:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:08:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:08:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:09:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:09:52,701] Trial 18 finished with value: -0.9943848524203437 and parameters: {'n_estimators': 90, 'learning_rate': 0.10300946039412257, 'max_depth': 8, 'subsample': 0.8688227543000983}. Best is trial 11 with value: -0.9949291270082293.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:10:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:10:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:10:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:11:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:11:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:11:20,558] Trial 19 finished with value: -0.9935534806314117 and parameters: {'n_estimators': 51, 'learning_rate': 0.061360740094958566, 'max_depth': 6, 'subsample': 0.9988050968083642}. Best is trial 11 with value: -0.9949291270082293.\n",
      "[I 2025-06-18 20:12:07,061] A new study created in memory with name: no-name-48eb71c4-b1c2-4b3f-8d12-8aace1f07f55\n",
      "[I 2025-06-18 20:15:58,075] Trial 0 finished with value: -0.9919981771715964 and parameters: {'iterations': 106, 'learning_rate': 0.13125830316209655, 'depth': 7, 'l2_leaf_reg': 0.6251373574521749}. Best is trial 0 with value: -0.9919981771715964.\n",
      "[I 2025-06-18 20:16:04,096] Trial 1 finished with value: -0.9740820645915583 and parameters: {'iterations': 73, 'learning_rate': 0.015256811898068502, 'depth': 3, 'l2_leaf_reg': 3.9676050770529883}. Best is trial 0 with value: -0.9919981771715964.\n",
      "[I 2025-06-18 20:16:08,907] Trial 2 finished with value: -0.9943518231566232 and parameters: {'iterations': 140, 'learning_rate': 0.06803900745073706, 'depth': 3, 'l2_leaf_reg': 8.123245085588687}. Best is trial 2 with value: -0.9943518231566232.\n",
      "[I 2025-06-18 20:16:17,024] Trial 3 finished with value: -0.9908175364660693 and parameters: {'iterations': 175, 'learning_rate': 0.01777174904859463, 'depth': 4, 'l2_leaf_reg': 0.03549878832196503}. Best is trial 2 with value: -0.9943518231566232.\n",
      "[I 2025-06-18 20:16:25,427] Trial 4 finished with value: -0.9900639441017717 and parameters: {'iterations': 95, 'learning_rate': 0.04141536110538596, 'depth': 5, 'l2_leaf_reg': 0.07476312062252301}. Best is trial 2 with value: -0.9943518231566232.\n",
      "[I 2025-06-18 20:16:29,810] Trial 5 finished with value: -0.9898033376831077 and parameters: {'iterations': 142, 'learning_rate': 0.01459007452373112, 'depth': 4, 'l2_leaf_reg': 0.1256277350380703}. Best is trial 2 with value: -0.9943518231566232.\n",
      "[I 2025-06-18 20:16:33,360] Trial 6 finished with value: -0.9922753673209985 and parameters: {'iterations': 118, 'learning_rate': 0.0838375512850209, 'depth': 4, 'l2_leaf_reg': 0.34890188454913873}. Best is trial 2 with value: -0.9943518231566232.\n",
      "[I 2025-06-18 20:16:39,850] Trial 7 finished with value: -0.9896548960182807 and parameters: {'iterations': 139, 'learning_rate': 0.011340440501807348, 'depth': 6, 'l2_leaf_reg': 0.03247673570627449}. Best is trial 2 with value: -0.9943518231566232.\n",
      "[I 2025-06-18 20:16:45,102] Trial 8 finished with value: -0.9893472678130861 and parameters: {'iterations': 59, 'learning_rate': 0.13060986669773664, 'depth': 8, 'l2_leaf_reg': 2.6619018884890564}. Best is trial 2 with value: -0.9943518231566232.\n",
      "[I 2025-06-18 20:16:49,917] Trial 9 finished with value: -0.9882306126686574 and parameters: {'iterations': 95, 'learning_rate': 0.01302780710309028, 'depth': 7, 'l2_leaf_reg': 0.2091498132903561}. Best is trial 2 with value: -0.9943518231566232.\n",
      "[I 2025-06-18 20:16:52,514] Trial 10 finished with value: -0.9941492425208238 and parameters: {'iterations': 194, 'learning_rate': 0.04542131010106151, 'depth': 3, 'l2_leaf_reg': 7.332884431753993}. Best is trial 2 with value: -0.9943518231566232.\n",
      "[I 2025-06-18 20:16:55,036] Trial 11 finished with value: -0.994591319868035 and parameters: {'iterations': 195, 'learning_rate': 0.047583949325428546, 'depth': 3, 'l2_leaf_reg': 9.116925308189677}. Best is trial 11 with value: -0.994591319868035.\n",
      "[I 2025-06-18 20:16:57,208] Trial 12 finished with value: -0.9943536370021727 and parameters: {'iterations': 164, 'learning_rate': 0.0696130364836842, 'depth': 3, 'l2_leaf_reg': 1.234433488463974}. Best is trial 11 with value: -0.994591319868035.\n",
      "[I 2025-06-18 20:17:01,238] Trial 13 finished with value: -0.9906451347652693 and parameters: {'iterations': 172, 'learning_rate': 0.026053366721511713, 'depth': 5, 'l2_leaf_reg': 1.3943500096523647}. Best is trial 11 with value: -0.994591319868035.\n",
      "[I 2025-06-18 20:17:03,561] Trial 14 finished with value: -0.9941471695544817 and parameters: {'iterations': 199, 'learning_rate': 0.06481997376425686, 'depth': 3, 'l2_leaf_reg': 1.0732820811474333}. Best is trial 11 with value: -0.994591319868035.\n",
      "[I 2025-06-18 20:17:06,321] Trial 15 finished with value: -0.991804924884337 and parameters: {'iterations': 169, 'learning_rate': 0.028715946422439177, 'depth': 4, 'l2_leaf_reg': 2.335776038676432}. Best is trial 11 with value: -0.994591319868035.\n",
      "[I 2025-06-18 20:17:09,769] Trial 16 finished with value: -0.9947587982737718 and parameters: {'iterations': 159, 'learning_rate': 0.09004786160906032, 'depth': 5, 'l2_leaf_reg': 9.728583151931058}. Best is trial 16 with value: -0.9947587982737718.\n",
      "[I 2025-06-18 20:17:15,460] Trial 17 finished with value: -0.9945879512977287 and parameters: {'iterations': 185, 'learning_rate': 0.08931859345890258, 'depth': 6, 'l2_leaf_reg': 9.07100562688584}. Best is trial 16 with value: -0.9947587982737718.\n",
      "[I 2025-06-18 20:17:19,320] Trial 18 finished with value: -0.9928199010296769 and parameters: {'iterations': 149, 'learning_rate': 0.05107665164572381, 'depth': 5, 'l2_leaf_reg': 4.4328493941111455}. Best is trial 16 with value: -0.9947587982737718.\n",
      "[I 2025-06-18 20:17:24,938] Trial 19 finished with value: -0.9892442932100332 and parameters: {'iterations': 160, 'learning_rate': 0.03084203125084717, 'depth': 6, 'l2_leaf_reg': 0.4278418532330561}. Best is trial 16 with value: -0.9947587982737718.\n",
      "[I 2025-06-18 20:17:25,707] A new study created in memory with name: no-name-24bc6680-4381-4c0d-ad75-6ffd041c60a0\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:17:49,392] Trial 0 finished with value: -0.9372638675402147 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 2.9380279387035334e-05, 'learning_rate_init': 0.00020511104188433984}. Best is trial 0 with value: -0.9372638675402147.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:17:51,470] Trial 1 finished with value: -0.9514690248731776 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.1527987128232396e-05, 'learning_rate_init': 0.008706020878304856}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:18:00,193] Trial 2 finished with value: -0.9438573343103915 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 8.17949947521167e-05, 'learning_rate_init': 0.0011207606211860567}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:18:11,218] Trial 3 finished with value: -0.9311666170882216 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 7.52374288453485e-05, 'learning_rate_init': 0.0005404103854647331}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:19:00,424] Trial 4 finished with value: -0.9243252408182275 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0005987474910461401, 'learning_rate_init': 0.0001238513729886094}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:19:04,954] Trial 5 finished with value: -0.9455962421266146 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00788671412999049, 'learning_rate_init': 0.004138040112561018}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:19:19,036] Trial 6 finished with value: -0.9274364869024805 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 2.32335035153901e-05, 'learning_rate_init': 0.0009780337016659412}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:19:47,786] Trial 7 finished with value: -0.9403235658614228 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 8.612579192594876e-05, 'learning_rate_init': 0.001096821720752952}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:19:52,519] Trial 8 finished with value: -0.9359996862910936 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.006584106160121612, 'learning_rate_init': 0.006161049539380964}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:20:26,519] Trial 9 finished with value: -0.9419781557716738 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.3667272915456215e-05, 'learning_rate_init': 0.0004473636174621269}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:20:32,054] Trial 10 finished with value: -0.9420131198039803 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0006446437100534851, 'learning_rate_init': 0.008691089486124973}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:20:38,741] Trial 11 finished with value: -0.9449167410343342 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.006410986086138413, 'learning_rate_init': 0.0038079765727675992}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:20:43,707] Trial 12 finished with value: -0.9233851333072831 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00265810630166612, 'learning_rate_init': 0.003085473344630515}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:20:46,999] Trial 13 finished with value: -0.938058521912809 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.00178831453901513, 'learning_rate_init': 0.003124556445157581}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:20:48,824] Trial 14 finished with value: -0.936162362324804 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00024466282558992545, 'learning_rate_init': 0.009841513366747656}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:20:53,315] Trial 15 finished with value: -0.946182615205968 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.00028674015157718663, 'learning_rate_init': 0.0019593582632936456}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:20:57,238] Trial 16 finished with value: -0.9456089390454612 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.00032855253153484296, 'learning_rate_init': 0.002023048619894486}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:21:02,113] Trial 17 finished with value: -0.9459782207246192 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.00018734294128464328, 'learning_rate_init': 0.0017440757348872338}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:21:03,905] Trial 18 finished with value: -0.946046611339195 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.261123605460073e-05, 'learning_rate_init': 0.005321569090909447}. Best is trial 1 with value: -0.9514690248731776.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:21:16,063] Trial 19 finished with value: -0.9416118453442731 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 3.8070266561518165e-05, 'learning_rate_init': 0.0005364384697609554}. Best is trial 1 with value: -0.9514690248731776.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Оптимизация для is_SI_above_8 (Manual Aggregated):   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:21:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5608192\ttotal: 7.43ms\tremaining: 1.05s\n",
      "1:\tlearn: 0.4495586\ttotal: 14.2ms\tremaining: 991ms\n",
      "2:\tlearn: 0.3815707\ttotal: 20.6ms\tremaining: 956ms\n",
      "3:\tlearn: 0.3267213\ttotal: 27.2ms\tremaining: 939ms\n",
      "4:\tlearn: 0.2829439\ttotal: 33.6ms\tremaining: 920ms\n",
      "5:\tlearn: 0.2657916\ttotal: 39.6ms\tremaining: 899ms\n",
      "6:\tlearn: 0.2474791\ttotal: 46.2ms\tremaining: 892ms\n",
      "7:\tlearn: 0.2266729\ttotal: 52.2ms\tremaining: 874ms\n",
      "8:\tlearn: 0.2064248\ttotal: 58.2ms\tremaining: 860ms\n",
      "9:\tlearn: 0.1929453\ttotal: 65ms\tremaining: 858ms\n",
      "10:\tlearn: 0.1883593\ttotal: 71.4ms\tremaining: 850ms\n",
      "11:\tlearn: 0.1826473\ttotal: 77.8ms\tremaining: 842ms\n",
      "12:\tlearn: 0.1755195\ttotal: 84.1ms\tremaining: 834ms\n",
      "13:\tlearn: 0.1606422\ttotal: 90.5ms\tremaining: 828ms\n",
      "14:\tlearn: 0.1513761\ttotal: 97.1ms\tremaining: 822ms\n",
      "15:\tlearn: 0.1478078\ttotal: 103ms\tremaining: 812ms\n",
      "16:\tlearn: 0.1420116\ttotal: 110ms\tremaining: 806ms\n",
      "17:\tlearn: 0.1393357\ttotal: 116ms\tremaining: 797ms\n",
      "18:\tlearn: 0.1346607\ttotal: 122ms\tremaining: 793ms\n",
      "19:\tlearn: 0.1284436\ttotal: 129ms\tremaining: 786ms\n",
      "20:\tlearn: 0.1267123\ttotal: 135ms\tremaining: 776ms\n",
      "21:\tlearn: 0.1248556\ttotal: 142ms\tremaining: 772ms\n",
      "22:\tlearn: 0.1207250\ttotal: 148ms\tremaining: 766ms\n",
      "23:\tlearn: 0.1149851\ttotal: 155ms\tremaining: 762ms\n",
      "24:\tlearn: 0.1098904\ttotal: 162ms\tremaining: 757ms\n",
      "25:\tlearn: 0.1081536\ttotal: 169ms\tremaining: 752ms\n",
      "26:\tlearn: 0.1034455\ttotal: 176ms\tremaining: 748ms\n",
      "27:\tlearn: 0.1011700\ttotal: 182ms\tremaining: 741ms\n",
      "28:\tlearn: 0.0967610\ttotal: 189ms\tremaining: 735ms\n",
      "29:\tlearn: 0.0950551\ttotal: 195ms\tremaining: 728ms\n",
      "30:\tlearn: 0.0931302\ttotal: 201ms\tremaining: 721ms\n",
      "31:\tlearn: 0.0916176\ttotal: 208ms\tremaining: 715ms\n",
      "32:\tlearn: 0.0880718\ttotal: 215ms\tremaining: 710ms\n",
      "33:\tlearn: 0.0876698\ttotal: 222ms\tremaining: 704ms\n",
      "34:\tlearn: 0.0869418\ttotal: 228ms\tremaining: 698ms\n",
      "35:\tlearn: 0.0851098\ttotal: 235ms\tremaining: 692ms\n",
      "36:\tlearn: 0.0819018\ttotal: 242ms\tremaining: 686ms\n",
      "37:\tlearn: 0.0805915\ttotal: 249ms\tremaining: 680ms\n",
      "38:\tlearn: 0.0782863\ttotal: 255ms\tremaining: 674ms\n",
      "39:\tlearn: 0.0751797\ttotal: 262ms\tremaining: 667ms\n",
      "40:\tlearn: 0.0723523\ttotal: 268ms\tremaining: 661ms\n",
      "41:\tlearn: 0.0707993\ttotal: 275ms\tremaining: 655ms\n",
      "42:\tlearn: 0.0701024\ttotal: 281ms\tremaining: 648ms\n",
      "43:\tlearn: 0.0646194\ttotal: 288ms\tremaining: 641ms\n",
      "44:\tlearn: 0.0638572\ttotal: 294ms\tremaining: 634ms\n",
      "45:\tlearn: 0.0636203\ttotal: 301ms\tremaining: 627ms\n",
      "46:\tlearn: 0.0610858\ttotal: 307ms\tremaining: 620ms\n",
      "47:\tlearn: 0.0597994\ttotal: 313ms\tremaining: 614ms\n",
      "48:\tlearn: 0.0584659\ttotal: 320ms\tremaining: 608ms\n",
      "49:\tlearn: 0.0581310\ttotal: 326ms\tremaining: 600ms\n",
      "50:\tlearn: 0.0573871\ttotal: 333ms\tremaining: 594ms\n",
      "51:\tlearn: 0.0547360\ttotal: 339ms\tremaining: 588ms\n",
      "52:\tlearn: 0.0539950\ttotal: 346ms\tremaining: 581ms\n",
      "53:\tlearn: 0.0524999\ttotal: 352ms\tremaining: 574ms\n",
      "54:\tlearn: 0.0522600\ttotal: 359ms\tremaining: 568ms\n",
      "55:\tlearn: 0.0485155\ttotal: 365ms\tremaining: 561ms\n",
      "56:\tlearn: 0.0477766\ttotal: 372ms\tremaining: 554ms\n",
      "57:\tlearn: 0.0459592\ttotal: 378ms\tremaining: 548ms\n",
      "58:\tlearn: 0.0458064\ttotal: 385ms\tremaining: 541ms\n",
      "59:\tlearn: 0.0456230\ttotal: 391ms\tremaining: 535ms\n",
      "60:\tlearn: 0.0451996\ttotal: 398ms\tremaining: 528ms\n",
      "61:\tlearn: 0.0440741\ttotal: 404ms\tremaining: 522ms\n",
      "62:\tlearn: 0.0431342\ttotal: 411ms\tremaining: 515ms\n",
      "63:\tlearn: 0.0401506\ttotal: 417ms\tremaining: 508ms\n",
      "64:\tlearn: 0.0396298\ttotal: 424ms\tremaining: 502ms\n",
      "65:\tlearn: 0.0364406\ttotal: 431ms\tremaining: 496ms\n",
      "66:\tlearn: 0.0354545\ttotal: 437ms\tremaining: 489ms\n",
      "67:\tlearn: 0.0353420\ttotal: 444ms\tremaining: 483ms\n",
      "68:\tlearn: 0.0350894\ttotal: 450ms\tremaining: 476ms\n",
      "69:\tlearn: 0.0348730\ttotal: 457ms\tremaining: 470ms\n",
      "70:\tlearn: 0.0337371\ttotal: 463ms\tremaining: 463ms\n",
      "71:\tlearn: 0.0310754\ttotal: 470ms\tremaining: 457ms\n",
      "72:\tlearn: 0.0298635\ttotal: 476ms\tremaining: 450ms\n",
      "73:\tlearn: 0.0295168\ttotal: 483ms\tremaining: 443ms\n",
      "74:\tlearn: 0.0280385\ttotal: 489ms\tremaining: 437ms\n",
      "75:\tlearn: 0.0268203\ttotal: 496ms\tremaining: 430ms\n",
      "76:\tlearn: 0.0266320\ttotal: 502ms\tremaining: 424ms\n",
      "77:\tlearn: 0.0261069\ttotal: 509ms\tremaining: 417ms\n",
      "78:\tlearn: 0.0259948\ttotal: 515ms\tremaining: 411ms\n",
      "79:\tlearn: 0.0247598\ttotal: 521ms\tremaining: 404ms\n",
      "80:\tlearn: 0.0235439\ttotal: 528ms\tremaining: 397ms\n",
      "81:\tlearn: 0.0234737\ttotal: 534ms\tremaining: 391ms\n",
      "82:\tlearn: 0.0232324\ttotal: 541ms\tremaining: 384ms\n",
      "83:\tlearn: 0.0230523\ttotal: 547ms\tremaining: 378ms\n",
      "84:\tlearn: 0.0219860\ttotal: 554ms\tremaining: 371ms\n",
      "85:\tlearn: 0.0214558\ttotal: 560ms\tremaining: 365ms\n",
      "86:\tlearn: 0.0211792\ttotal: 567ms\tremaining: 358ms\n",
      "87:\tlearn: 0.0199776\ttotal: 574ms\tremaining: 352ms\n",
      "88:\tlearn: 0.0198420\ttotal: 580ms\tremaining: 345ms\n",
      "89:\tlearn: 0.0189876\ttotal: 587ms\tremaining: 339ms\n",
      "90:\tlearn: 0.0183819\ttotal: 593ms\tremaining: 333ms\n",
      "91:\tlearn: 0.0182662\ttotal: 600ms\tremaining: 326ms\n",
      "92:\tlearn: 0.0178619\ttotal: 607ms\tremaining: 320ms\n",
      "93:\tlearn: 0.0172287\ttotal: 614ms\tremaining: 313ms\n",
      "94:\tlearn: 0.0172036\ttotal: 620ms\tremaining: 307ms\n",
      "95:\tlearn: 0.0171635\ttotal: 627ms\tremaining: 301ms\n",
      "96:\tlearn: 0.0170858\ttotal: 634ms\tremaining: 294ms\n",
      "97:\tlearn: 0.0167770\ttotal: 641ms\tremaining: 288ms\n",
      "98:\tlearn: 0.0165390\ttotal: 648ms\tremaining: 281ms\n",
      "99:\tlearn: 0.0165242\ttotal: 654ms\tremaining: 275ms\n",
      "100:\tlearn: 0.0159019\ttotal: 660ms\tremaining: 268ms\n",
      "101:\tlearn: 0.0154371\ttotal: 667ms\tremaining: 262ms\n",
      "102:\tlearn: 0.0151746\ttotal: 674ms\tremaining: 255ms\n",
      "103:\tlearn: 0.0151413\ttotal: 680ms\tremaining: 249ms\n",
      "104:\tlearn: 0.0146715\ttotal: 687ms\tremaining: 242ms\n",
      "105:\tlearn: 0.0146176\ttotal: 693ms\tremaining: 235ms\n",
      "106:\tlearn: 0.0144182\ttotal: 700ms\tremaining: 229ms\n",
      "107:\tlearn: 0.0139878\ttotal: 707ms\tremaining: 222ms\n",
      "108:\tlearn: 0.0139080\ttotal: 713ms\tremaining: 216ms\n",
      "109:\tlearn: 0.0137059\ttotal: 720ms\tremaining: 209ms\n",
      "110:\tlearn: 0.0134474\ttotal: 726ms\tremaining: 203ms\n",
      "111:\tlearn: 0.0133714\ttotal: 733ms\tremaining: 196ms\n",
      "112:\tlearn: 0.0131994\ttotal: 739ms\tremaining: 190ms\n",
      "113:\tlearn: 0.0131507\ttotal: 746ms\tremaining: 183ms\n",
      "114:\tlearn: 0.0130988\ttotal: 753ms\tremaining: 177ms\n",
      "115:\tlearn: 0.0130695\ttotal: 759ms\tremaining: 170ms\n",
      "116:\tlearn: 0.0127539\ttotal: 766ms\tremaining: 164ms\n",
      "117:\tlearn: 0.0126794\ttotal: 773ms\tremaining: 157ms\n",
      "118:\tlearn: 0.0126355\ttotal: 780ms\tremaining: 151ms\n",
      "119:\tlearn: 0.0122013\ttotal: 787ms\tremaining: 144ms\n",
      "120:\tlearn: 0.0120855\ttotal: 793ms\tremaining: 138ms\n",
      "121:\tlearn: 0.0120589\ttotal: 800ms\tremaining: 131ms\n",
      "122:\tlearn: 0.0120241\ttotal: 806ms\tremaining: 125ms\n",
      "123:\tlearn: 0.0118816\ttotal: 813ms\tremaining: 118ms\n",
      "124:\tlearn: 0.0118398\ttotal: 819ms\tremaining: 111ms\n",
      "125:\tlearn: 0.0118193\ttotal: 826ms\tremaining: 105ms\n",
      "126:\tlearn: 0.0114108\ttotal: 833ms\tremaining: 98.4ms\n",
      "127:\tlearn: 0.0113395\ttotal: 840ms\tremaining: 91.9ms\n",
      "128:\tlearn: 0.0113206\ttotal: 847ms\tremaining: 85.3ms\n",
      "129:\tlearn: 0.0108867\ttotal: 854ms\tremaining: 78.8ms\n",
      "130:\tlearn: 0.0106096\ttotal: 860ms\tremaining: 72.2ms\n",
      "131:\tlearn: 0.0106038\ttotal: 866ms\tremaining: 65.6ms\n",
      "132:\tlearn: 0.0105279\ttotal: 873ms\tremaining: 59.1ms\n",
      "133:\tlearn: 0.0101455\ttotal: 880ms\tremaining: 52.5ms\n",
      "134:\tlearn: 0.0101043\ttotal: 886ms\tremaining: 45.9ms\n",
      "135:\tlearn: 0.0098958\ttotal: 893ms\tremaining: 39.4ms\n",
      "136:\tlearn: 0.0098629\ttotal: 899ms\tremaining: 32.8ms\n",
      "137:\tlearn: 0.0095705\ttotal: 906ms\tremaining: 26.3ms\n",
      "138:\tlearn: 0.0094430\ttotal: 912ms\tremaining: 19.7ms\n",
      "139:\tlearn: 0.0093847\ttotal: 918ms\tremaining: 13.1ms\n",
      "140:\tlearn: 0.0093627\ttotal: 925ms\tremaining: 6.56ms\n",
      "141:\tlearn: 0.0093041\ttotal: 932ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:22:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6226944\ttotal: 3.44ms\tremaining: 513ms\n",
      "1:\tlearn: 0.5640093\ttotal: 6.35ms\tremaining: 470ms\n",
      "2:\tlearn: 0.5006208\ttotal: 8.99ms\tremaining: 440ms\n",
      "3:\tlearn: 0.4317426\ttotal: 11.6ms\tremaining: 424ms\n",
      "4:\tlearn: 0.4015903\ttotal: 14.3ms\tremaining: 416ms\n",
      "5:\tlearn: 0.3695644\ttotal: 17.1ms\tremaining: 410ms\n",
      "6:\tlearn: 0.3398879\ttotal: 19.7ms\tremaining: 403ms\n",
      "7:\tlearn: 0.3261012\ttotal: 22.5ms\tremaining: 400ms\n",
      "8:\tlearn: 0.3135860\ttotal: 25.5ms\tremaining: 399ms\n",
      "9:\tlearn: 0.2901750\ttotal: 28.3ms\tremaining: 397ms\n",
      "10:\tlearn: 0.2802901\ttotal: 31.1ms\tremaining: 393ms\n",
      "11:\tlearn: 0.2759800\ttotal: 33.9ms\tremaining: 390ms\n",
      "12:\tlearn: 0.2667958\ttotal: 36.7ms\tremaining: 387ms\n",
      "13:\tlearn: 0.2554450\ttotal: 39.5ms\tremaining: 383ms\n",
      "14:\tlearn: 0.2343456\ttotal: 42.2ms\tremaining: 380ms\n",
      "15:\tlearn: 0.2239374\ttotal: 45.2ms\tremaining: 379ms\n",
      "16:\tlearn: 0.2221472\ttotal: 48.1ms\tremaining: 377ms\n",
      "17:\tlearn: 0.2166242\ttotal: 50.9ms\tremaining: 373ms\n",
      "18:\tlearn: 0.2148695\ttotal: 53.6ms\tremaining: 370ms\n",
      "19:\tlearn: 0.2034555\ttotal: 56.4ms\tremaining: 366ms\n",
      "20:\tlearn: 0.2014750\ttotal: 59.3ms\tremaining: 364ms\n",
      "21:\tlearn: 0.1999772\ttotal: 62.2ms\tremaining: 362ms\n",
      "22:\tlearn: 0.1930401\ttotal: 65ms\tremaining: 359ms\n",
      "23:\tlearn: 0.1878518\ttotal: 67.8ms\tremaining: 356ms\n",
      "24:\tlearn: 0.1861315\ttotal: 70.6ms\tremaining: 353ms\n",
      "25:\tlearn: 0.1844273\ttotal: 73.6ms\tremaining: 351ms\n",
      "26:\tlearn: 0.1782731\ttotal: 76.2ms\tremaining: 347ms\n",
      "27:\tlearn: 0.1730336\ttotal: 79.3ms\tremaining: 345ms\n",
      "28:\tlearn: 0.1660399\ttotal: 82.2ms\tremaining: 343ms\n",
      "29:\tlearn: 0.1652802\ttotal: 85ms\tremaining: 340ms\n",
      "30:\tlearn: 0.1638423\ttotal: 87.9ms\tremaining: 337ms\n",
      "31:\tlearn: 0.1620401\ttotal: 90.9ms\tremaining: 335ms\n",
      "32:\tlearn: 0.1585153\ttotal: 93.6ms\tremaining: 332ms\n",
      "33:\tlearn: 0.1576196\ttotal: 96.3ms\tremaining: 329ms\n",
      "34:\tlearn: 0.1572405\ttotal: 99.1ms\tremaining: 326ms\n",
      "35:\tlearn: 0.1539486\ttotal: 102ms\tremaining: 323ms\n",
      "36:\tlearn: 0.1492292\ttotal: 105ms\tremaining: 320ms\n",
      "37:\tlearn: 0.1465329\ttotal: 108ms\tremaining: 317ms\n",
      "38:\tlearn: 0.1438311\ttotal: 110ms\tremaining: 314ms\n",
      "39:\tlearn: 0.1394685\ttotal: 113ms\tremaining: 311ms\n",
      "40:\tlearn: 0.1365225\ttotal: 116ms\tremaining: 308ms\n",
      "41:\tlearn: 0.1360802\ttotal: 119ms\tremaining: 305ms\n",
      "42:\tlearn: 0.1355302\ttotal: 122ms\tremaining: 303ms\n",
      "43:\tlearn: 0.1344785\ttotal: 124ms\tremaining: 300ms\n",
      "44:\tlearn: 0.1341352\ttotal: 127ms\tremaining: 297ms\n",
      "45:\tlearn: 0.1327858\ttotal: 130ms\tremaining: 294ms\n",
      "46:\tlearn: 0.1296542\ttotal: 133ms\tremaining: 292ms\n",
      "47:\tlearn: 0.1245187\ttotal: 136ms\tremaining: 289ms\n",
      "48:\tlearn: 0.1232407\ttotal: 139ms\tremaining: 286ms\n",
      "49:\tlearn: 0.1206647\ttotal: 141ms\tremaining: 283ms\n",
      "50:\tlearn: 0.1200931\ttotal: 144ms\tremaining: 280ms\n",
      "51:\tlearn: 0.1155942\ttotal: 147ms\tremaining: 278ms\n",
      "52:\tlearn: 0.1146749\ttotal: 150ms\tremaining: 275ms\n",
      "53:\tlearn: 0.1143722\ttotal: 153ms\tremaining: 272ms\n",
      "54:\tlearn: 0.1138047\ttotal: 156ms\tremaining: 269ms\n",
      "55:\tlearn: 0.1133784\ttotal: 159ms\tremaining: 266ms\n",
      "56:\tlearn: 0.1124569\ttotal: 162ms\tremaining: 264ms\n",
      "57:\tlearn: 0.1114551\ttotal: 164ms\tremaining: 261ms\n",
      "58:\tlearn: 0.1101993\ttotal: 167ms\tremaining: 258ms\n",
      "59:\tlearn: 0.1097744\ttotal: 170ms\tremaining: 255ms\n",
      "60:\tlearn: 0.1085730\ttotal: 173ms\tremaining: 252ms\n",
      "61:\tlearn: 0.1052854\ttotal: 176ms\tremaining: 249ms\n",
      "62:\tlearn: 0.1050575\ttotal: 178ms\tremaining: 246ms\n",
      "63:\tlearn: 0.1049762\ttotal: 181ms\tremaining: 244ms\n",
      "64:\tlearn: 0.1041614\ttotal: 184ms\tremaining: 241ms\n",
      "65:\tlearn: 0.0996318\ttotal: 187ms\tremaining: 238ms\n",
      "66:\tlearn: 0.0987370\ttotal: 190ms\tremaining: 235ms\n",
      "67:\tlearn: 0.0975999\ttotal: 193ms\tremaining: 232ms\n",
      "68:\tlearn: 0.0968581\ttotal: 195ms\tremaining: 229ms\n",
      "69:\tlearn: 0.0966680\ttotal: 198ms\tremaining: 227ms\n",
      "70:\tlearn: 0.0957409\ttotal: 201ms\tremaining: 224ms\n",
      "71:\tlearn: 0.0937861\ttotal: 204ms\tremaining: 221ms\n",
      "72:\tlearn: 0.0935807\ttotal: 207ms\tremaining: 218ms\n",
      "73:\tlearn: 0.0912020\ttotal: 210ms\tremaining: 216ms\n",
      "74:\tlearn: 0.0886837\ttotal: 213ms\tremaining: 213ms\n",
      "75:\tlearn: 0.0885378\ttotal: 215ms\tremaining: 210ms\n",
      "76:\tlearn: 0.0874608\ttotal: 218ms\tremaining: 207ms\n",
      "77:\tlearn: 0.0868433\ttotal: 221ms\tremaining: 204ms\n",
      "78:\tlearn: 0.0858805\ttotal: 224ms\tremaining: 201ms\n",
      "79:\tlearn: 0.0853512\ttotal: 227ms\tremaining: 198ms\n",
      "80:\tlearn: 0.0849337\ttotal: 230ms\tremaining: 196ms\n",
      "81:\tlearn: 0.0846271\ttotal: 233ms\tremaining: 193ms\n",
      "82:\tlearn: 0.0829777\ttotal: 236ms\tremaining: 190ms\n",
      "83:\tlearn: 0.0826454\ttotal: 239ms\tremaining: 188ms\n",
      "84:\tlearn: 0.0811325\ttotal: 241ms\tremaining: 185ms\n",
      "85:\tlearn: 0.0779202\ttotal: 244ms\tremaining: 182ms\n",
      "86:\tlearn: 0.0763091\ttotal: 247ms\tremaining: 179ms\n",
      "87:\tlearn: 0.0758704\ttotal: 250ms\tremaining: 176ms\n",
      "88:\tlearn: 0.0745385\ttotal: 253ms\tremaining: 173ms\n",
      "89:\tlearn: 0.0744289\ttotal: 255ms\tremaining: 170ms\n",
      "90:\tlearn: 0.0718689\ttotal: 258ms\tremaining: 167ms\n",
      "91:\tlearn: 0.0715603\ttotal: 261ms\tremaining: 165ms\n",
      "92:\tlearn: 0.0710596\ttotal: 264ms\tremaining: 162ms\n",
      "93:\tlearn: 0.0684269\ttotal: 266ms\tremaining: 159ms\n",
      "94:\tlearn: 0.0676142\ttotal: 269ms\tremaining: 156ms\n",
      "95:\tlearn: 0.0670198\ttotal: 272ms\tremaining: 153ms\n",
      "96:\tlearn: 0.0664347\ttotal: 274ms\tremaining: 150ms\n",
      "97:\tlearn: 0.0663525\ttotal: 277ms\tremaining: 147ms\n",
      "98:\tlearn: 0.0653312\ttotal: 280ms\tremaining: 144ms\n",
      "99:\tlearn: 0.0652802\ttotal: 283ms\tremaining: 141ms\n",
      "100:\tlearn: 0.0649528\ttotal: 285ms\tremaining: 138ms\n",
      "101:\tlearn: 0.0644311\ttotal: 288ms\tremaining: 136ms\n",
      "102:\tlearn: 0.0640237\ttotal: 291ms\tremaining: 133ms\n",
      "103:\tlearn: 0.0633815\ttotal: 294ms\tremaining: 130ms\n",
      "104:\tlearn: 0.0632089\ttotal: 297ms\tremaining: 127ms\n",
      "105:\tlearn: 0.0630354\ttotal: 299ms\tremaining: 124ms\n",
      "106:\tlearn: 0.0612515\ttotal: 302ms\tremaining: 121ms\n",
      "107:\tlearn: 0.0604960\ttotal: 305ms\tremaining: 119ms\n",
      "108:\tlearn: 0.0604506\ttotal: 308ms\tremaining: 116ms\n",
      "109:\tlearn: 0.0602214\ttotal: 311ms\tremaining: 113ms\n",
      "110:\tlearn: 0.0601760\ttotal: 313ms\tremaining: 110ms\n",
      "111:\tlearn: 0.0597319\ttotal: 316ms\tremaining: 107ms\n",
      "112:\tlearn: 0.0581063\ttotal: 319ms\tremaining: 105ms\n",
      "113:\tlearn: 0.0574633\ttotal: 322ms\tremaining: 102ms\n",
      "114:\tlearn: 0.0567267\ttotal: 325ms\tremaining: 98.9ms\n",
      "115:\tlearn: 0.0560257\ttotal: 328ms\tremaining: 96ms\n",
      "116:\tlearn: 0.0552743\ttotal: 330ms\tremaining: 93.2ms\n",
      "117:\tlearn: 0.0541413\ttotal: 333ms\tremaining: 90.3ms\n",
      "118:\tlearn: 0.0535901\ttotal: 336ms\tremaining: 87.5ms\n",
      "119:\tlearn: 0.0534872\ttotal: 339ms\tremaining: 84.7ms\n",
      "120:\tlearn: 0.0528489\ttotal: 341ms\tremaining: 81.8ms\n",
      "121:\tlearn: 0.0527876\ttotal: 344ms\tremaining: 79ms\n",
      "122:\tlearn: 0.0511273\ttotal: 347ms\tremaining: 76.2ms\n",
      "123:\tlearn: 0.0510756\ttotal: 350ms\tremaining: 73.3ms\n",
      "124:\tlearn: 0.0508192\ttotal: 353ms\tremaining: 70.5ms\n",
      "125:\tlearn: 0.0506649\ttotal: 355ms\tremaining: 67.7ms\n",
      "126:\tlearn: 0.0505235\ttotal: 358ms\tremaining: 64.9ms\n",
      "127:\tlearn: 0.0504923\ttotal: 361ms\tremaining: 62ms\n",
      "128:\tlearn: 0.0504584\ttotal: 364ms\tremaining: 59.2ms\n",
      "129:\tlearn: 0.0504300\ttotal: 367ms\tremaining: 56.4ms\n",
      "130:\tlearn: 0.0499710\ttotal: 369ms\tremaining: 53.6ms\n",
      "131:\tlearn: 0.0496514\ttotal: 372ms\tremaining: 50.7ms\n",
      "132:\tlearn: 0.0495776\ttotal: 375ms\tremaining: 47.9ms\n",
      "133:\tlearn: 0.0492950\ttotal: 378ms\tremaining: 45.1ms\n",
      "134:\tlearn: 0.0489984\ttotal: 380ms\tremaining: 42.3ms\n",
      "135:\tlearn: 0.0482318\ttotal: 383ms\tremaining: 39.4ms\n",
      "136:\tlearn: 0.0479117\ttotal: 386ms\tremaining: 36.6ms\n",
      "137:\tlearn: 0.0472904\ttotal: 389ms\tremaining: 33.8ms\n",
      "138:\tlearn: 0.0471929\ttotal: 392ms\tremaining: 31ms\n",
      "139:\tlearn: 0.0464358\ttotal: 395ms\tremaining: 28.2ms\n",
      "140:\tlearn: 0.0459440\ttotal: 397ms\tremaining: 25.4ms\n",
      "141:\tlearn: 0.0457796\ttotal: 400ms\tremaining: 22.6ms\n",
      "142:\tlearn: 0.0455907\ttotal: 403ms\tremaining: 19.7ms\n",
      "143:\tlearn: 0.0455586\ttotal: 406ms\tremaining: 16.9ms\n",
      "144:\tlearn: 0.0452907\ttotal: 409ms\tremaining: 14.1ms\n",
      "145:\tlearn: 0.0447327\ttotal: 411ms\tremaining: 11.3ms\n",
      "146:\tlearn: 0.0438779\ttotal: 414ms\tremaining: 8.45ms\n",
      "147:\tlearn: 0.0433971\ttotal: 417ms\tremaining: 5.64ms\n",
      "148:\tlearn: 0.0431671\ttotal: 420ms\tremaining: 2.82ms\n",
      "149:\tlearn: 0.0431414\ttotal: 423ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-06-18 20:22:55,108] A new study created in memory with name: no-name-5614bf94-2329-4679-ab64-71f102a2f5b1\n",
      "[I 2025-06-18 20:22:55,238] Trial 0 finished with value: -0.9965624690134718 and parameters: {'C': 0.5611516415334505, 'penalty': 'l1'}. Best is trial 0 with value: -0.9965624690134718.\n",
      "[I 2025-06-18 20:22:55,488] Trial 1 finished with value: -0.9940782606983202 and parameters: {'C': 1.5751320499779735, 'penalty': 'l1'}. Best is trial 0 with value: -0.9965624690134718.\n",
      "[I 2025-06-18 20:22:55,567] Trial 2 finished with value: -0.9983996872584777 and parameters: {'C': 0.13066739238053282, 'penalty': 'l1'}. Best is trial 2 with value: -0.9983996872584777.\n",
      "[I 2025-06-18 20:22:55,842] Trial 3 finished with value: -0.9798114498913938 and parameters: {'C': 2.607024758370768, 'penalty': 'l2'}. Best is trial 2 with value: -0.9983996872584777.\n",
      "[I 2025-06-18 20:22:56,376] Trial 4 finished with value: -0.9923427214524031 and parameters: {'C': 4.622589001020832, 'penalty': 'l1'}. Best is trial 2 with value: -0.9983996872584777.\n",
      "[I 2025-06-18 20:22:56,534] Trial 5 finished with value: -0.9751134862698801 and parameters: {'C': 0.2327067708383781, 'penalty': 'l2'}. Best is trial 2 with value: -0.9983996872584777.\n",
      "[I 2025-06-18 20:22:56,743] Trial 6 finished with value: -0.9780400310530357 and parameters: {'C': 0.7309539835912913, 'penalty': 'l2'}. Best is trial 2 with value: -0.9983996872584777.\n",
      "[I 2025-06-18 20:22:56,895] Trial 7 finished with value: -0.9741606818400893 and parameters: {'C': 0.19010245319870356, 'penalty': 'l2'}. Best is trial 2 with value: -0.9983996872584777.\n",
      "[I 2025-06-18 20:22:57,045] Trial 8 finished with value: -0.9956432120889869 and parameters: {'C': 0.8168455894760165, 'penalty': 'l1'}. Best is trial 2 with value: -0.9983996872584777.\n",
      "[I 2025-06-18 20:22:57,219] Trial 9 finished with value: -0.9952006165001903 and parameters: {'C': 1.0677482709481354, 'penalty': 'l1'}. Best is trial 2 with value: -0.9983996872584777.\n",
      "[I 2025-06-18 20:22:57,303] Trial 10 finished with value: -0.9985018844991524 and parameters: {'C': 0.10991587445851024, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:22:57,386] Trial 11 finished with value: -0.9984678187522608 and parameters: {'C': 0.10353677627159782, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:22:57,468] Trial 12 finished with value: -0.9984678187522608 and parameters: {'C': 0.1069139322389136, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:22:57,577] Trial 13 finished with value: -0.9974819850587495 and parameters: {'C': 0.324255176142218, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:22:57,683] Trial 14 finished with value: -0.9975839231786313 and parameters: {'C': 0.31385189050357676, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:22:58,370] Trial 15 finished with value: -0.9916275998884743 and parameters: {'C': 8.611382274356343, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:22:58,454] Trial 16 finished with value: -0.9984678187522608 and parameters: {'C': 0.11141231165883378, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:22:58,566] Trial 17 finished with value: -0.9972094590836177 and parameters: {'C': 0.394134405489134, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:22:58,730] Trial 18 finished with value: -0.9738200243711743 and parameters: {'C': 0.1736216698299393, 'penalty': 'l2'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:22:58,827] Trial 19 finished with value: -0.9978905149006548 and parameters: {'C': 0.21086760429111312, 'penalty': 'l1'}. Best is trial 10 with value: -0.9985018844991524.\n",
      "[I 2025-06-18 20:22:58,849] A new study created in memory with name: no-name-6fa16bfb-a062-48fe-9aa8-0d29ff068bef\n",
      "[I 2025-06-18 20:23:01,162] Trial 0 finished with value: -0.8590422100861559 and parameters: {'n_estimators': 106, 'max_depth': 5, 'min_samples_split': 3}. Best is trial 0 with value: -0.8590422100861559.\n",
      "[I 2025-06-18 20:23:02,409] Trial 1 finished with value: -0.8705822064170056 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 1 with value: -0.8705822064170056.\n",
      "[I 2025-06-18 20:23:07,171] Trial 2 finished with value: -0.891631849469476 and parameters: {'n_estimators': 175, 'max_depth': None, 'min_samples_split': 5}. Best is trial 2 with value: -0.891631849469476.\n",
      "[I 2025-06-18 20:23:10,200] Trial 3 finished with value: -0.8768383842885734 and parameters: {'n_estimators': 115, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 2 with value: -0.891631849469476.\n",
      "[I 2025-06-18 20:23:12,760] Trial 4 finished with value: -0.8580602632045364 and parameters: {'n_estimators': 118, 'max_depth': 5, 'min_samples_split': 2}. Best is trial 2 with value: -0.891631849469476.\n",
      "[I 2025-06-18 20:23:16,511] Trial 5 finished with value: -0.882387473340789 and parameters: {'n_estimators': 141, 'max_depth': None, 'min_samples_split': 7}. Best is trial 2 with value: -0.891631849469476.\n",
      "[I 2025-06-18 20:23:19,011] Trial 6 finished with value: -0.8828483283081174 and parameters: {'n_estimators': 95, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 2 with value: -0.891631849469476.\n",
      "[I 2025-06-18 20:23:20,211] Trial 7 finished with value: -0.8722532418602384 and parameters: {'n_estimators': 55, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 2 with value: -0.891631849469476.\n",
      "[I 2025-06-18 20:23:23,679] Trial 8 finished with value: -0.8832783651758238 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 2 with value: -0.891631849469476.\n",
      "[I 2025-06-18 20:23:26,668] Trial 9 finished with value: -0.8660909693639759 and parameters: {'n_estimators': 140, 'max_depth': 5, 'min_samples_split': 4}. Best is trial 2 with value: -0.891631849469476.\n",
      "[I 2025-06-18 20:23:31,949] Trial 10 finished with value: -0.8919194044505897 and parameters: {'n_estimators': 197, 'max_depth': None, 'min_samples_split': 6}. Best is trial 10 with value: -0.8919194044505897.\n",
      "[I 2025-06-18 20:23:37,127] Trial 11 finished with value: -0.8909351254818351 and parameters: {'n_estimators': 193, 'max_depth': None, 'min_samples_split': 6}. Best is trial 10 with value: -0.8919194044505897.\n",
      "[I 2025-06-18 20:23:42,541] Trial 12 finished with value: -0.8937852469058386 and parameters: {'n_estimators': 199, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 12 with value: -0.8937852469058386.\n",
      "[I 2025-06-18 20:23:47,959] Trial 13 finished with value: -0.8935134982930849 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 12 with value: -0.8937852469058386.\n",
      "[I 2025-06-18 20:23:52,415] Trial 14 finished with value: -0.885445098695655 and parameters: {'n_estimators': 166, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 12 with value: -0.8937852469058386.\n",
      "[I 2025-06-18 20:23:56,483] Trial 15 finished with value: -0.8952485192974164 and parameters: {'n_estimators': 167, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 15 with value: -0.8952485192974164.\n",
      "[I 2025-06-18 20:24:00,816] Trial 16 finished with value: -0.8857524677800569 and parameters: {'n_estimators': 164, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 15 with value: -0.8952485192974164.\n",
      "[I 2025-06-18 20:24:05,562] Trial 17 finished with value: -0.8847627472746538 and parameters: {'n_estimators': 177, 'max_depth': 15, 'min_samples_split': 4}. Best is trial 15 with value: -0.8952485192974164.\n",
      "[I 2025-06-18 20:24:09,718] Trial 18 finished with value: -0.8934856514452203 and parameters: {'n_estimators': 155, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 15 with value: -0.8952485192974164.\n",
      "[I 2025-06-18 20:24:14,333] Trial 19 finished with value: -0.8860567274149453 and parameters: {'n_estimators': 180, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 15 with value: -0.8952485192974164.\n",
      "[I 2025-06-18 20:24:15,341] A new study created in memory with name: no-name-797be2cd-2a81-4d08-97ad-4cd47c37498a\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:24:16,514] Trial 0 finished with value: -0.9952008756209828 and parameters: {'n_estimators': 106, 'learning_rate': 0.13125830316209655, 'max_depth': 7, 'subsample': 0.8795975452591109}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:24:17,120] Trial 1 finished with value: -0.9797896319206412 and parameters: {'n_estimators': 73, 'learning_rate': 0.015256811898068502, 'max_depth': 3, 'subsample': 0.9598528437324805}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:24:18,097] Trial 2 finished with value: -0.9928921784561444 and parameters: {'n_estimators': 140, 'learning_rate': 0.06803900745073706, 'max_depth': 3, 'subsample': 0.9909729556485982}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:24:19,791] Trial 3 finished with value: -0.994083443114176 and parameters: {'n_estimators': 175, 'learning_rate': 0.01777174904859463, 'max_depth': 4, 'subsample': 0.7550213529560301}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:24:20,998] Trial 4 finished with value: -0.9942501441575343 and parameters: {'n_estimators': 95, 'learning_rate': 0.04141536110538596, 'max_depth': 5, 'subsample': 0.7873687420594125}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:24:22,455] Trial 5 finished with value: -0.9917050597307977 and parameters: {'n_estimators': 142, 'learning_rate': 0.01459007452373112, 'max_depth': 4, 'subsample': 0.8099085529881075}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:24:23,524] Trial 6 finished with value: -0.9944547977596763 and parameters: {'n_estimators': 118, 'learning_rate': 0.0838375512850209, 'max_depth': 4, 'subsample': 0.8542703315240835}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:24:25,767] Trial 7 finished with value: -0.9913235993743787 and parameters: {'n_estimators': 139, 'learning_rate': 0.011340440501807348, 'max_depth': 6, 'subsample': 0.7511572371061874}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:24:45,415] Trial 8 finished with value: -0.9946919623839527 and parameters: {'n_estimators': 59, 'learning_rate': 0.13060986669773664, 'max_depth': 8, 'subsample': 0.9425192044349383}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:25:02,660] Trial 9 finished with value: -0.9876881519263211 and parameters: {'n_estimators': 95, 'learning_rate': 0.01302780710309028, 'max_depth': 7, 'subsample': 0.8320457481218804}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:25:49,440] Trial 10 finished with value: -0.9946911850215743 and parameters: {'n_estimators': 192, 'learning_rate': 0.036030984219246213, 'max_depth': 8, 'subsample': 0.8919394579380205}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:25:52,142] Trial 11 finished with value: -0.994929386129022 and parameters: {'n_estimators': 54, 'learning_rate': 0.11681446704286463, 'max_depth': 8, 'subsample': 0.915028891748686}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:26:00,145] Trial 12 finished with value: -0.9948261524051766 and parameters: {'n_estimators': 82, 'learning_rate': 0.14828432951660628, 'max_depth': 7, 'subsample': 0.885478855453852}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:26:01,174] Trial 13 finished with value: -0.9951678463572626 and parameters: {'n_estimators': 57, 'learning_rate': 0.09915097464555107, 'max_depth': 7, 'subsample': 0.9085942971636803}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:26:02,618] Trial 14 finished with value: -0.9946904076591959 and parameters: {'n_estimators': 114, 'learning_rate': 0.07472114133364743, 'max_depth': 6, 'subsample': 0.8656078720226558}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:26:04,792] Trial 15 finished with value: -0.9942829143004619 and parameters: {'n_estimators': 169, 'learning_rate': 0.05101378363287886, 'max_depth': 7, 'subsample': 0.936187304686775}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:26:06,142] Trial 16 finished with value: -0.9942834325420475 and parameters: {'n_estimators': 102, 'learning_rate': 0.10336125761049329, 'max_depth': 6, 'subsample': 0.9988049595242307}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:26:07,523] Trial 17 finished with value: -0.99230943306789 and parameters: {'n_estimators': 75, 'learning_rate': 0.0278332482623601, 'max_depth': 7, 'subsample': 0.9048907833677927}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:26:08,170] Trial 18 finished with value: -0.9941453557089319 and parameters: {'n_estimators': 53, 'learning_rate': 0.0584848096022614, 'max_depth': 5, 'subsample': 0.8248104175755249}. Best is trial 0 with value: -0.9952008756209828.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:26:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:26:09,507] Trial 19 finished with value: -0.9940090927213661 and parameters: {'n_estimators': 160, 'learning_rate': 0.09826396887908904, 'max_depth': 7, 'subsample': 0.7255806947334577}. Best is trial 0 with value: -0.9952008756209828.\n",
      "[I 2025-06-18 20:26:09,778] A new study created in memory with name: no-name-547d3cae-46d3-4b25-8237-60dacdfeab7d\n",
      "[I 2025-06-18 20:26:15,850] Trial 0 finished with value: -0.992816014217785 and parameters: {'iterations': 106, 'learning_rate': 0.13125830316209655, 'depth': 7, 'l2_leaf_reg': 0.6251373574521749}. Best is trial 0 with value: -0.992816014217785.\n",
      "[I 2025-06-18 20:26:17,253] Trial 1 finished with value: -0.9767711856296446 and parameters: {'iterations': 73, 'learning_rate': 0.015256811898068502, 'depth': 3, 'l2_leaf_reg': 3.9676050770529883}. Best is trial 0 with value: -0.992816014217785.\n",
      "[I 2025-06-18 20:26:19,492] Trial 2 finished with value: -0.9940145342580144 and parameters: {'iterations': 140, 'learning_rate': 0.06803900745073706, 'depth': 3, 'l2_leaf_reg': 8.123245085588687}. Best is trial 2 with value: -0.9940145342580144.\n",
      "[I 2025-06-18 20:26:22,546] Trial 3 finished with value: -0.9898611043451793 and parameters: {'iterations': 175, 'learning_rate': 0.01777174904859463, 'depth': 4, 'l2_leaf_reg': 0.03549878832196503}. Best is trial 2 with value: -0.9940145342580144.\n",
      "[I 2025-06-18 20:26:24,813] Trial 4 finished with value: -0.9892489573843033 and parameters: {'iterations': 95, 'learning_rate': 0.04141536110538596, 'depth': 5, 'l2_leaf_reg': 0.07476312062252301}. Best is trial 2 with value: -0.9940145342580144.\n",
      "[I 2025-06-18 20:26:27,398] Trial 5 finished with value: -0.9890136066055764 and parameters: {'iterations': 142, 'learning_rate': 0.01459007452373112, 'depth': 4, 'l2_leaf_reg': 0.1256277350380703}. Best is trial 2 with value: -0.9940145342580144.\n",
      "[I 2025-06-18 20:26:29,342] Trial 6 finished with value: -0.9912890153859018 and parameters: {'iterations': 118, 'learning_rate': 0.0838375512850209, 'depth': 4, 'l2_leaf_reg': 0.34890188454913873}. Best is trial 2 with value: -0.9940145342580144.\n",
      "[I 2025-06-18 20:26:33,764] Trial 7 finished with value: -0.9886713944119047 and parameters: {'iterations': 139, 'learning_rate': 0.011340440501807348, 'depth': 6, 'l2_leaf_reg': 0.03247673570627449}. Best is trial 2 with value: -0.9940145342580144.\n",
      "[I 2025-06-18 20:26:39,061] Trial 8 finished with value: -0.9898587722580441 and parameters: {'iterations': 59, 'learning_rate': 0.13060986669773664, 'depth': 8, 'l2_leaf_reg': 2.6619018884890564}. Best is trial 2 with value: -0.9940145342580144.\n",
      "[I 2025-06-18 20:26:43,764] Trial 9 finished with value: -0.9875201552789988 and parameters: {'iterations': 95, 'learning_rate': 0.01302780710309028, 'depth': 7, 'l2_leaf_reg': 0.2091498132903561}. Best is trial 2 with value: -0.9940145342580144.\n",
      "[I 2025-06-18 20:26:46,247] Trial 10 finished with value: -0.9941497607624094 and parameters: {'iterations': 194, 'learning_rate': 0.04542131010106151, 'depth': 3, 'l2_leaf_reg': 7.332884431753993}. Best is trial 10 with value: -0.9941497607624094.\n",
      "[I 2025-06-18 20:26:48,711] Trial 11 finished with value: -0.9933345149241484 and parameters: {'iterations': 195, 'learning_rate': 0.047583949325428546, 'depth': 3, 'l2_leaf_reg': 9.116925308189677}. Best is trial 10 with value: -0.9941497607624094.\n",
      "[I 2025-06-18 20:26:50,975] Trial 12 finished with value: -0.9937727054594678 and parameters: {'iterations': 164, 'learning_rate': 0.0696130364836842, 'depth': 3, 'l2_leaf_reg': 1.234433488463974}. Best is trial 10 with value: -0.9941497607624094.\n",
      "[I 2025-06-18 20:26:55,006] Trial 13 finished with value: -0.9921442867492882 and parameters: {'iterations': 195, 'learning_rate': 0.02762080702177393, 'depth': 5, 'l2_leaf_reg': 7.876796449286196}. Best is trial 10 with value: -0.9941497607624094.\n",
      "[I 2025-06-18 20:26:57,130] Trial 14 finished with value: -0.9944540203972977 and parameters: {'iterations': 163, 'learning_rate': 0.06794475579473148, 'depth': 3, 'l2_leaf_reg': 1.6635411479780635}. Best is trial 14 with value: -0.9944540203972977.\n",
      "[I 2025-06-18 20:26:59,859] Trial 15 finished with value: -0.9916671071720143 and parameters: {'iterations': 169, 'learning_rate': 0.027596248822578738, 'depth': 4, 'l2_leaf_reg': 1.6960643201262637}. Best is trial 14 with value: -0.9944540203972977.\n",
      "[I 2025-06-18 20:27:03,106] Trial 16 finished with value: -0.9933628800135986 and parameters: {'iterations': 180, 'learning_rate': 0.05455419207126683, 'depth': 5, 'l2_leaf_reg': 0.8343637397377769}. Best is trial 14 with value: -0.9944540203972977.\n",
      "[I 2025-06-18 20:27:08,277] Trial 17 finished with value: -0.9913610336915765 and parameters: {'iterations': 160, 'learning_rate': 0.029548942085772505, 'depth': 6, 'l2_leaf_reg': 3.790598042922176}. Best is trial 14 with value: -0.9944540203972977.\n",
      "[I 2025-06-18 20:27:10,708] Trial 18 finished with value: -0.9944209911335774 and parameters: {'iterations': 151, 'learning_rate': 0.0870522246183673, 'depth': 3, 'l2_leaf_reg': 2.0272534229425707}. Best is trial 14 with value: -0.9944540203972977.\n",
      "[I 2025-06-18 20:27:13,230] Trial 19 finished with value: -0.9931946242454834 and parameters: {'iterations': 152, 'learning_rate': 0.10019045232920674, 'depth': 4, 'l2_leaf_reg': 0.5505471110066286}. Best is trial 14 with value: -0.9944540203972977.\n",
      "[I 2025-06-18 20:27:13,666] A new study created in memory with name: no-name-1b849fd9-cee7-4a68-857e-4d956c80f1ad\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:27:34,445] Trial 0 finished with value: -0.9286249012317912 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 2.9380279387035334e-05, 'learning_rate_init': 0.00020511104188433984}. Best is trial 0 with value: -0.9286249012317912.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:27:37,216] Trial 1 finished with value: -0.947765445931337 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.1527987128232396e-05, 'learning_rate_init': 0.008706020878304856}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:27:43,228] Trial 2 finished with value: -0.9386665229410001 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 8.17949947521167e-05, 'learning_rate_init': 0.0011207606211860567}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:27:51,269] Trial 3 finished with value: -0.9215674700447727 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 7.52374288453485e-05, 'learning_rate_init': 0.0005404103854647331}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:28:28,043] Trial 4 finished with value: -0.9254929254841153 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0005987474910461401, 'learning_rate_init': 0.0001238513729886094}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:28:29,979] Trial 5 finished with value: -0.9326516556263934 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00788671412999049, 'learning_rate_init': 0.004138040112561018}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:28:34,756] Trial 6 finished with value: -0.9272903773247887 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 2.32335035153901e-05, 'learning_rate_init': 0.0009780337016659412}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:28:41,994] Trial 7 finished with value: -0.9361005879278039 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 8.612579192594876e-05, 'learning_rate_init': 0.001096821720752952}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:28:43,781] Trial 8 finished with value: -0.9364231069412241 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.006584106160121612, 'learning_rate_init': 0.006161049539380964}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:28:54,150] Trial 9 finished with value: -0.9384779348280112 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.3667272915456215e-05, 'learning_rate_init': 0.0004473636174621269}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:28:55,635] Trial 10 finished with value: -0.9468293461553211 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0006446437100534851, 'learning_rate_init': 0.008691089486124973}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:28:56,998] Trial 11 finished with value: -0.9339193436435769 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0008322724281704743, 'learning_rate_init': 0.0032630616334052716}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:28:58,363] Trial 12 finished with value: -0.9436245747395923 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0013141513949245947, 'learning_rate_init': 0.009237992574561581}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:00,898] Trial 13 finished with value: -0.9432178587432365 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0024138827155249917, 'learning_rate_init': 0.002479201332659864}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:02,252] Trial 14 finished with value: -0.9410193915636489 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00022784259374269346, 'learning_rate_init': 0.009841513366747656}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:05,531] Trial 15 finished with value: -0.944787992549759 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.00028674015157718663, 'learning_rate_init': 0.0021527183465656838}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:06,959] Trial 16 finished with value: -0.9476251579341233 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0032549670694108387, 'learning_rate_init': 0.005867338877439117}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:08,688] Trial 17 finished with value: -0.9403238249822156 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.002766709511905194, 'learning_rate_init': 0.004919007339010312}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:11,108] Trial 18 finished with value: -0.9325765278712053 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00015450632914458976, 'learning_rate_init': 0.0017978173136560577}. Best is trial 1 with value: -0.947765445931337.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:12,272] Trial 19 finished with value: -0.9471665141308933 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0034752685500732076, 'learning_rate_init': 0.006238565895449131}. Best is trial 1 with value: -0.947765445931337.\n"
     ]
    }
   ],
   "source": [
    "# --- Основной цикл оценки с тремя методами оптимизации ---\n",
    "all_classification_results = []\n",
    "optimizers = ['RandomizedSearchCV', 'GridSearchCV', 'Optuna']\n",
    "\n",
    "# Извлекаем признаки, исключая все целевые переменные (теперь просто TARGETS_ACTUAL_LOGGED)\n",
    "# и новые бинарные целевые переменные.\n",
    "columns_to_drop_common = TARGETS_ACTUAL_LOGGED + list(classification_targets.keys())\n",
    "\n",
    "# Добавляем специфические для датасетов столбцы, которые не являются признаками (например, SMILES)\n",
    "if 'SMILES' in df_pca.columns:\n",
    "    columns_to_drop_pca_final = columns_to_drop_common + ['SMILES']\n",
    "else:\n",
    "    columns_to_drop_pca_final = columns_to_drop_common\n",
    "\n",
    "if 'SMILES' in df_manual.columns:\n",
    "    columns_to_drop_manual_final = columns_to_drop_common + ['SMILES']\n",
    "else:\n",
    "    columns_to_drop_manual_final = columns_to_drop_common\n",
    "\n",
    "X_pca_features = df_pca.drop(columns=columns_to_drop_pca_final, errors='ignore')\n",
    "X_manual_features = df_manual.drop(columns=columns_to_drop_manual_final, errors='ignore')\n",
    "\n",
    "\n",
    "print(\"Начинаем процесс обучения и оценки моделей классификации...\")\n",
    "\n",
    "for target_name_classification in tqdm(classification_targets.keys(), desc=\"Прогнозирование задач классификации\"):\n",
    "    for data_source_name, X_data_features, df_data in [(\"PCA Aggregated\", X_pca_features, df_pca), (\"Manual Aggregated\", X_manual_features, df_manual)]:\n",
    "        y_data_classification = df_data[target_name_classification]\n",
    "\n",
    "        num_models_to_run = 0\n",
    "        for model_name, config in models_config_classifier.items():\n",
    "            for optimizer_type in optimizers:\n",
    "                # Уточненная логика для подсчета моделей\n",
    "                if (optimizer_type == 'RandomizedSearchCV' and not config.get('random_dist', {})) and model_name != \"LogisticRegression\":\n",
    "                    continue\n",
    "                if (optimizer_type == 'GridSearchCV' and not config.get('grid_params', {})) and model_name != \"LogisticRegression\":\n",
    "                    continue\n",
    "                if (optimizer_type == 'Optuna' and config.get('optuna_space') is None) and model_name != \"LogisticRegression\":\n",
    "                    continue\n",
    "                num_models_to_run += 1\n",
    "\n",
    "        with tqdm(total=num_models_to_run, desc=f\"Оптимизация для {target_name_classification} ({data_source_name})\", leave=False) as pbar_inner:\n",
    "            for optimizer_type in optimizers:\n",
    "                for model_name, config in models_config_classifier.items():\n",
    "                    # Пропускаем неподходящие комбинации модель-оптимизатор, чтобы избежать ошибок и не тратить время\n",
    "                    if (optimizer_type == 'RandomizedSearchCV' and not config.get('random_dist', {})) and model_name != \"LogisticRegression\":\n",
    "                        pbar_inner.update(1)\n",
    "                        continue\n",
    "                    if (optimizer_type == 'GridSearchCV' and not config.get('grid_params', {})) and model_name != \"LogisticRegression\":\n",
    "                        pbar_inner.update(1)\n",
    "                        continue\n",
    "                    if (optimizer_type == 'Optuna' and config.get('optuna_space') is None) and model_name != \"LogisticRegression\":\n",
    "                        pbar_inner.update(1)\n",
    "                        continue\n",
    "\n",
    "                    model_class = config[\"class\"]\n",
    "                    params_config = config\n",
    "\n",
    "                    pbar_inner.set_description(f\"Оптимизация для {target_name_classification} ({data_source_name}) - {model_name} ({optimizer_type})\")\n",
    "\n",
    "                    result = evaluate_model_with_optimizer_classifier(model_name, model_class, params_config,\n",
    "                                                                      X_data_features, y_data_classification, target_name_classification, optimizer_type)\n",
    "                    if result:\n",
    "                        result['data_source'] = data_source_name\n",
    "                        all_classification_results.append(result)\n",
    "                    pbar_inner.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c4fab20-7400-4d47-86f9-ccb611faebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты классификации сохранены в: classification_results_all_optimizers_50_iter.csv\n",
      "\n",
      "--- Сводка результатов классификации по методам оптимизации ---\n",
      "\n",
      "## Результаты RandomizedSearchCV (Классификация):\n",
      "                     model           optimizer         target                                                                                                                             best_params  accuracy  precision    recall  f1_score   roc_auc        data_source\n",
      "14      LogisticRegression  RandomizedSearchCV  is_SI_above_8                                                                        {'C': 3.845401188473625, 'penalty': 'l1', 'solver': 'liblinear'}  0.970149   0.958333  0.958333  0.958333  0.998816  Manual Aggregated\n",
      "0       LogisticRegression  RandomizedSearchCV  is_SI_above_8                                                                        {'C': 3.845401188473625, 'penalty': 'l1', 'solver': 'liblinear'}  0.980100   0.972222  0.972222  0.972222  0.998708     PCA Aggregated\n",
      "17      CatBoostClassifier  RandomizedSearchCV  is_SI_above_8                                {'depth': 6, 'iterations': 142, 'l2_leaf_reg': 2.2840435290631467, 'learning_rate': 0.12695365004091538}  0.970149   1.000000  0.916667  0.956522  0.993002  Manual Aggregated\n",
      "3       CatBoostClassifier  RandomizedSearchCV  is_SI_above_8                                  {'depth': 4, 'iterations': 181, 'l2_leaf_reg': 7.59541228979397, 'learning_rate': 0.09449323267683088}  0.975124   1.000000  0.930556  0.964029  0.990525     PCA Aggregated\n",
      "2            XGBClassifier  RandomizedSearchCV  is_SI_above_8  {'learning_rate': 0.1182998158400237, 'max_depth': 4, 'n_estimators': 70, 'subsample': 0.8852444528883149, 'use_label_encoder': False}  0.960199   1.000000  0.888889  0.941176  0.989556     PCA Aggregated\n",
      "16           XGBClassifier  RandomizedSearchCV  is_SI_above_8  {'learning_rate': 0.1182998158400237, 'max_depth': 4, 'n_estimators': 70, 'subsample': 0.8852444528883149, 'use_label_encoder': False}  0.960199   1.000000  0.888889  0.941176  0.988264  Manual Aggregated\n",
      "18           MLPClassifier  RandomizedSearchCV  is_SI_above_8                             {'alpha': 0.00020292247147901224, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.003709993861334124}  0.920398   0.924242  0.847222  0.884058  0.972868  Manual Aggregated\n",
      "4            MLPClassifier  RandomizedSearchCV  is_SI_above_8                              {'alpha': 0.0034126114217699097, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.002225779372456223}  0.905473   0.895522  0.833333  0.863309  0.969746     PCA Aggregated\n",
      "1   RandomForestClassifier  RandomizedSearchCV  is_SI_above_8                                                                        {'max_depth': None, 'min_samples_split': 3, 'n_estimators': 181}  0.825871   0.793651  0.694444  0.740741  0.895995     PCA Aggregated\n",
      "15  RandomForestClassifier  RandomizedSearchCV  is_SI_above_8                                                                        {'max_depth': None, 'min_samples_split': 6, 'n_estimators': 149}  0.820896   0.790323  0.680556  0.731343  0.895241  Manual Aggregated\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "## Результаты GridSearchCV (Классификация):\n",
      "                     model     optimizer         target                                                                              best_params  accuracy  precision    recall  f1_score   roc_auc        data_source\n",
      "5       LogisticRegression  GridSearchCV  is_SI_above_8                                       {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}  0.995025   0.986301  1.000000  0.993103  0.999569     PCA Aggregated\n",
      "19      LogisticRegression  GridSearchCV  is_SI_above_8                                       {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}  0.995025   0.986301  1.000000  0.993103  0.999569  Manual Aggregated\n",
      "22      CatBoostClassifier  GridSearchCV  is_SI_above_8                                    {'depth': 3, 'iterations': 150, 'learning_rate': 0.1}  0.960199   0.970588  0.916667  0.942857  0.991494  Manual Aggregated\n",
      "8       CatBoostClassifier  GridSearchCV  is_SI_above_8                                    {'depth': 5, 'iterations': 150, 'learning_rate': 0.1}  0.970149   1.000000  0.916667  0.956522  0.991279     PCA Aggregated\n",
      "7            XGBClassifier  GridSearchCV  is_SI_above_8  {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 150, 'use_label_encoder': False}  0.965174   1.000000  0.902778  0.948905  0.989772     PCA Aggregated\n",
      "21           XGBClassifier  GridSearchCV  is_SI_above_8  {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'use_label_encoder': False}  0.960199   1.000000  0.888889  0.941176  0.987941  Manual Aggregated\n",
      "9            MLPClassifier  GridSearchCV  is_SI_above_8                                          {'alpha': 0.0001, 'hidden_layer_sizes': (100,)}  0.895522   0.869565  0.833333  0.851064  0.963394     PCA Aggregated\n",
      "23           MLPClassifier  GridSearchCV  is_SI_above_8                                           {'alpha': 0.001, 'hidden_layer_sizes': (100,)}  0.890547   0.878788  0.805556  0.840580  0.963394  Manual Aggregated\n",
      "6   RandomForestClassifier  GridSearchCV  is_SI_above_8                                                   {'max_depth': 10, 'n_estimators': 150}  0.830846   0.806452  0.694444  0.746269  0.890504     PCA Aggregated\n",
      "20  RandomForestClassifier  GridSearchCV  is_SI_above_8                                                   {'max_depth': 10, 'n_estimators': 150}  0.800995   0.766667  0.638889  0.696970  0.888997  Manual Aggregated\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "## Результаты Optuna (Классификация):\n",
      "                     model optimizer         target                                                                                                   best_params  accuracy  precision    recall  f1_score   roc_auc        data_source\n",
      "11           XGBClassifier    Optuna  is_SI_above_8  {'n_estimators': 109, 'learning_rate': 0.11681446704286463, 'max_depth': 7, 'subsample': 0.8833252799515279}  0.960199   1.000000  0.888889  0.941176  0.991171     PCA Aggregated\n",
      "25           XGBClassifier    Optuna  is_SI_above_8  {'n_estimators': 106, 'learning_rate': 0.13125830316209655, 'max_depth': 7, 'subsample': 0.8795975452591109}  0.955224   0.984615  0.888889  0.934307  0.990956  Manual Aggregated\n",
      "12      CatBoostClassifier    Optuna  is_SI_above_8       {'iterations': 159, 'learning_rate': 0.09004786160906032, 'depth': 5, 'l2_leaf_reg': 9.728583151931058}  0.960199   1.000000  0.888889  0.941176  0.990202     PCA Aggregated\n",
      "26      CatBoostClassifier    Optuna  is_SI_above_8      {'iterations': 163, 'learning_rate': 0.06794475579473148, 'depth': 3, 'l2_leaf_reg': 1.6635411479780635}  0.955224   0.956522  0.916667  0.936170  0.989341  Manual Aggregated\n",
      "27           MLPClassifier    Optuna  is_SI_above_8   {'hidden_layer_sizes': (100,), 'alpha': 1.1527987128232396e-05, 'learning_rate_init': 0.008706020878304856}  0.925373   0.925373  0.861111  0.892086  0.970392  Manual Aggregated\n",
      "13           MLPClassifier    Optuna  is_SI_above_8   {'hidden_layer_sizes': (100,), 'alpha': 1.1527987128232396e-05, 'learning_rate_init': 0.008706020878304856}  0.900498   0.882353  0.833333  0.857143  0.964793     PCA Aggregated\n",
      "10  RandomForestClassifier    Optuna  is_SI_above_8                                              {'n_estimators': 179, 'max_depth': None, 'min_samples_split': 4}  0.840796   0.833333  0.694444  0.757576  0.893949     PCA Aggregated\n",
      "24  RandomForestClassifier    Optuna  is_SI_above_8                                                {'n_estimators': 167, 'max_depth': 15, 'min_samples_split': 6}  0.835821   0.819672  0.694444  0.751880  0.892119  Manual Aggregated\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Сохранение и вывод результатов ---\n",
    "output_classification_file = Path('classification_results_all_optimizers_50_iter.csv')\n",
    "\n",
    "all_classification_results_df = pd.DataFrame(all_classification_results)\n",
    "all_classification_results_df.to_csv(output_classification_file, index=False)\n",
    "print(f\"\\nРезультаты классификации сохранены в: {output_classification_file}\")\n",
    "\n",
    "print(\"\\n--- Сводка результатов классификации по методам оптимизации ---\")\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    print(f\"\\n## Результаты {optimizer} (Классификация):\")\n",
    "    subset_optimizer = all_classification_results_df[all_classification_results_df['optimizer'] == optimizer]\n",
    "    print(subset_optimizer.sort_values(by=['target', 'roc_auc'], ascending=[True, False]).to_string())\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Визуализация метрик классификации (например, ROC-AUC и F1-score)\n",
    "classification_metrics_to_plot = ['roc_auc', 'f1_score', 'accuracy']\n",
    "\n",
    "for target_class in classification_targets.keys():\n",
    "    for metric in classification_metrics_to_plot:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        subset = all_classification_results_df[all_classification_results_df['target'] == target_class].sort_values(by=metric, ascending=False)\n",
    "        sns.barplot(x='model', y=metric, hue='optimizer', data=subset, palette='viridis')\n",
    "        plt.title(f'Сравнение {metric.upper()} для \"{target_class}\" по методам оптимизации', fontsize=16)\n",
    "        plt.ylabel(metric.upper(), fontsize=12)\n",
    "        plt.xlabel('Модель', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.legend(title='Метод оптимизации', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'classification_{target_class}_{metric}_comparison.png')\n",
    "        plt.close() # Close plot to free memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
