{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddde29b9-e3eb-4c5c-8dd4-d127058ba0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Data (actual logged targets):\n",
      "         SI\n",
      "0  3.371597\n",
      "1  2.079442\n",
      "2  0.542324\n",
      "3  4.162553\n",
      "4  0.832909\n",
      "\n",
      "Manual Data (actual logged targets):\n",
      "         SI\n",
      "0  3.371597\n",
      "1  2.079442\n",
      "2  0.542324\n",
      "3  4.162553\n",
      "4  0.832909\n",
      "\n",
      "Созданные бинарные целевые переменные:\n",
      "PCA - is_SI_above_median value counts:\n",
      " is_SI_above_median\n",
      "0    501\n",
      "1    500\n",
      "Name: count, dtype: int64\n",
      "Manual - is_SI_above_median value counts:\n",
      " is_SI_above_median\n",
      "0    501\n",
      "1    500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import uniform, randint\n",
    "import optuna\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Загрузка данных ---\n",
    "file_url_pca = 'https://drive.google.com/uc?export=download&id=1SuUhkpfj-3uJQnxwmUCyDUogfa2TixTe'\n",
    "file_url_manual = 'https://drive.google.com/uc?export=download&id=1p8VYp23oOylSFrfJztQVheNLop-bX40o'\n",
    "\n",
    "df_pca = pd.read_csv(file_url_pca, encoding='utf-8')\n",
    "df_manual = pd.read_csv(file_url_manual, encoding='utf-8')\n",
    "\n",
    "# --- Определяем фактические целевые переменные, которые уже логарифмированы ---\n",
    "# Поскольку вы подтвердили, что 'IC50, mM', 'CC50, mM', 'SI' уже логарифмированы,\n",
    "# мы будем использовать их напрямую как наши \"лог-цели\".\n",
    "TARGETS_ACTUAL_LOGGED = ['SI']\n",
    "\n",
    "print(\"PCA Data (actual logged targets):\")\n",
    "print(df_pca[TARGETS_ACTUAL_LOGGED].head())\n",
    "print(\"\\nManual Data (actual logged targets):\")\n",
    "print(df_manual[TARGETS_ACTUAL_LOGGED].head())\n",
    "\n",
    "# --- Создание бинарных целевых переменных для классификации ---\n",
    "\n",
    "classification_targets = {}\n",
    "\n",
    "\n",
    "# 3. SI > медианы\n",
    "median_si_pca = df_pca['SI'].median()\n",
    "df_pca['is_SI_above_median'] = (df_pca['SI'] > median_si_pca).astype(int)\n",
    "median_si_manual = df_manual['SI'].median()\n",
    "df_manual['is_SI_above_median'] = (df_manual['SI'] > median_si_manual).astype(int)\n",
    "classification_targets['is_SI_above_median'] = 'SI'\n",
    "\n",
    "\n",
    "print(\"\\nСозданные бинарные целевые переменные:\")\n",
    "print(\"PCA - is_SI_above_median value counts:\\n\", df_pca['is_SI_above_median'].value_counts())\n",
    "\n",
    "print(\"Manual - is_SI_above_median value counts:\\n\", df_manual['is_SI_above_median'].value_counts())\n",
    "\n",
    "\n",
    "# --- Вспомогательная функция для расчета метрик классификации ---\n",
    "def calculate_classification_metrics(y_true, y_pred, y_pred_proba):\n",
    "    \"\"\"Вычисляет метрики классификации: Accuracy, Precision, Recall, F1, ROC-AUC.\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0) # Добавлено zero_division\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# --- Функции для каждого метода оптимизации (адаптированные для классификации) ---\n",
    "\n",
    "def run_randomized_search_classifier(model_instance, param_distributions, X_train_scaled, y_train, n_iter_search=20):\n",
    "    \"\"\"Выполняет RandomizedSearchCV для подбора гиперпараметров для классификации.\"\"\"\n",
    "    if not param_distributions:\n",
    "        model_instance.fit(X_train_scaled, y_train)\n",
    "        return model_instance, {}\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    random_search = RandomizedSearchCV(model_instance, param_distributions, n_iter=n_iter_search,\n",
    "                                       cv=cv, scoring='roc_auc',\n",
    "                                       n_jobs=-1, verbose=0, random_state=42)\n",
    "    random_search.fit(X_train_scaled, y_train)\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "def run_grid_search_classifier(model_instance, param_grid, X_train_scaled, y_train):\n",
    "    \"\"\"Выполняет GridSearchCV для подбора гиперпараметров для классификации.\"\"\"\n",
    "    if not param_grid:\n",
    "        model_instance.fit(X_train_scaled, y_train)\n",
    "        return model_instance, {}\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(model_instance, param_grid, cv=cv, scoring='roc_auc',\n",
    "                               n_jobs=-1, verbose=0)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def run_optuna_search_classifier(model_class, optuna_search_space, X_train_scaled, y_train, n_trials=20):\n",
    "    \"\"\"Выполняет оптимизацию гиперпараметров с помощью Optuna для классификации.\"\"\"\n",
    "    def objective(trial):\n",
    "        params = optuna_search_space(trial)\n",
    "\n",
    "        # Обработка random_state/random_seed для Optuna\n",
    "        # Random_state может быть не поддерживаем для всех моделей или определенных solvers\n",
    "        # Здесь мы исходим из того, что Optuna space уже определяет правильный параметр ('random_state' или 'random_seed')\n",
    "        if model_class in [LogisticRegression, MLPClassifier] and 'random_state' in params:\n",
    "            model = model_class(**{k: v for k, v in params.items() if k != 'random_state'})\n",
    "        else:\n",
    "            model = model_class(**params)\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = []\n",
    "        for train_idx, val_idx in kf.split(X_train_scaled, y_train):\n",
    "            X_train_fold, X_val_fold = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            try:\n",
    "                if isinstance(model, CatBoostClassifier):\n",
    "                    train_pool = Pool(X_train_fold, y_train_fold)\n",
    "                    val_pool = Pool(X_val_fold, y_val_fold)\n",
    "                    model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=10, verbose=False)\n",
    "                    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "                else:\n",
    "                    model.fit(X_train_fold, y_train_fold)\n",
    "                    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "                roc_auc_fold = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
    "                cv_scores.append(roc_auc_fold)\n",
    "            except Exception as e:\n",
    "                # print(f\"Ошибка при обучении/предсказании в Optuna (фолд): {e}\") # Для дебага\n",
    "                return -float('inf')\n",
    "\n",
    "        return -np.mean(cv_scores)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False, catch=(ValueError, Exception))\n",
    "\n",
    "    best_params = study.best_params\n",
    "    \n",
    "    # Final model instance with best parameters\n",
    "    if model_class in [LogisticRegression, MLPClassifier] and 'random_state' in best_params:\n",
    "        best_model_instance = model_class(**{k: v for k, v in best_params.items() if k != 'random_state'})\n",
    "    else:\n",
    "        best_model_instance = model_class(**best_params)\n",
    "\n",
    "    try:\n",
    "        if isinstance(best_model_instance, CatBoostClassifier):\n",
    "            train_pool_final = Pool(X_train_scaled, y_train)\n",
    "            best_model_instance.fit(train_pool_final, verbose=False)\n",
    "        else:\n",
    "            best_model_instance.fit(X_train_scaled, y_train)\n",
    "    except Exception as e:\n",
    "        # print(f\"Ошибка при окончательном обучении CatBoost: {e}\") # Для дебага\n",
    "        return None, {}\n",
    "\n",
    "    return best_model_instance, best_params\n",
    "\n",
    "# --- Общая функция для оценки моделей с различными оптимизаторами (адаптированная) ---\n",
    "def evaluate_model_with_optimizer_classifier(model_name, model_class, params_config, X, y, target_name, optimizer_type):\n",
    "    \"\"\"Оценивает производительность модели классификации, используя указанный метод оптимизации.\"\"\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    best_model = None\n",
    "    best_params = {}\n",
    "\n",
    "    # Инициализация параметров для воспроизводимости:\n",
    "    model_init_params = {}\n",
    "    if model_name == \"CatBoostClassifier\":\n",
    "        model_init_params['random_seed'] = 42\n",
    "    elif model_name in [\"LogisticRegression\", \"RandomForestClassifier\", \"XGBClassifier\", \"MLPClassifier\"]:\n",
    "        # Эти модели обычно принимают random_state для воспроизводимости\n",
    "        model_init_params['random_state'] = 42\n",
    "\n",
    "    if optimizer_type == 'RandomizedSearchCV':\n",
    "        param_distributions = params_config.get('random_dist', {})\n",
    "        # Для LogisticRegression, если нет dist, используем дефолтный инстанс\n",
    "        if model_name == \"LogisticRegression\" and not param_distributions:\n",
    "             model_instance = model_class(**model_init_params)\n",
    "             model_instance.fit(X_train_scaled, y_train)\n",
    "             best_model, best_params = model_instance, {}\n",
    "        else:\n",
    "            best_model, best_params = run_randomized_search_classifier(model_class(**model_init_params), param_distributions, X_train_scaled, y_train, n_iter_search=20)\n",
    "\n",
    "    elif optimizer_type == 'GridSearchCV':\n",
    "        param_grid = params_config.get('grid_params', {})\n",
    "        if not param_grid:\n",
    "            model_instance = model_class(**model_init_params)\n",
    "            model_instance.fit(X_train_scaled, y_train)\n",
    "            best_model, best_params = model_instance, {}\n",
    "        else:\n",
    "            best_model, best_params = run_grid_search_classifier(model_class(**model_init_params), param_grid, X_train_scaled, y_train)\n",
    "\n",
    "    elif optimizer_type == 'Optuna':\n",
    "        optuna_space = params_config.get('optuna_space')\n",
    "        if optuna_space is None:\n",
    "            model_instance = model_class(**model_init_params)\n",
    "            model_instance.fit(X_train_scaled, y_train)\n",
    "            best_model, best_params = model_instance, {}\n",
    "        else:\n",
    "            # Optuna уже обрабатывает random_state/random_seed в своей objective функции\n",
    "            best_model, best_params = run_optuna_search_classifier(model_class, optuna_space, X_train_scaled, y_train, n_trials=20)\n",
    "    else:\n",
    "        raise ValueError(f\"Неизвестный тип оптимизатора: {optimizer_type}\")\n",
    "\n",
    "    if best_model is None:\n",
    "        return None\n",
    "\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    # predict_proba может отсутствовать для некоторых моделей (например, SVM с probability=False)\n",
    "    # или если модель не была обучена с этой функциональностью.\n",
    "    # Проверяем наличие predict_proba\n",
    "    if hasattr(best_model, \"predict_proba\") and len(best_model.predict_proba(X_test_scaled).shape) > 1:\n",
    "        y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        # Для моделей без predict_proba, ROC-AUC не может быть рассчитан.\n",
    "        # В таком случае, можно либо пропустить ROC-AUC, либо вернуть NaN.\n",
    "        # Для SVM, если probability=True не установлен при инициализации, его не будет.\n",
    "        # Для LogisticRegression и Tree-based моделей predict_proba всегда есть.\n",
    "        print(f\"Warning: Model {model_name} does not have predict_proba or it's not applicable. ROC-AUC will be NaN.\")\n",
    "        y_pred_proba = np.full_like(y_pred, np.nan, dtype=float) # Заполняем NaN для ROC-AUC\n",
    "\n",
    "    accuracy, precision, recall, f1, roc_auc = calculate_classification_metrics(y_test, y_pred, y_pred_proba)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'optimizer': optimizer_type,\n",
    "        'target': target_name,\n",
    "        'best_params': best_params,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "\n",
    "# --- Определение моделей и их гиперпараметров для разных оптимизаторов (адаптированные для классификации) ---\n",
    "models_config_classifier = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"class\": LogisticRegression,\n",
    "        \"random_dist\": {\n",
    "            'C': uniform(loc=0.1, scale=10),\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear']\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear']\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'C': trial.suggest_float('C', 0.1, 10.0, log=True),\n",
    "            'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
    "            'solver': 'liblinear',\n",
    "            'random_state': 42 # Добавлен random_state здесь, чтобы управлять им\n",
    "        }\n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"class\": RandomForestClassifier,\n",
    "        \"random_dist\": {\n",
    "            'n_estimators': randint(50, 200),\n",
    "            'max_depth': [5, 10, None],\n",
    "            'min_samples_split': randint(2, 8)\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'n_estimators': [100, 150],\n",
    "            'max_depth': [5, 10],\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [5, 10, 15, None]),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 8),\n",
    "            'random_state': 42\n",
    "        }\n",
    "    },\n",
    "    \"XGBClassifier\": {\n",
    "        \"class\": XGBClassifier,\n",
    "        \"random_dist\": {\n",
    "            'n_estimators': randint(50, 200),\n",
    "            'learning_rate': uniform(0.01, 0.15),\n",
    "            'max_depth': randint(3, 8),\n",
    "            'subsample': uniform(0.7, 0.3),\n",
    "            'use_label_encoder': [False]\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'n_estimators': [100, 150],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'max_depth': [3, 5],\n",
    "            'use_label_encoder': [False]\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'eval_metric': 'logloss',\n",
    "            'n_jobs': -1,\n",
    "            'random_state': 42,\n",
    "            'use_label_encoder': False\n",
    "        }\n",
    "    },\n",
    "    \"CatBoostClassifier\": {\n",
    "        \"class\": CatBoostClassifier,\n",
    "        \"random_dist\": {\n",
    "            'iterations': randint(50, 200),\n",
    "            'learning_rate': uniform(0.01, 0.15),\n",
    "            'depth': randint(3, 8),\n",
    "            'l2_leaf_reg': uniform(1, 7)\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'iterations': [100, 150],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'depth': [3, 5]\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'iterations': trial.suggest_int('iterations', 50, 200),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15, log=True),\n",
    "            'depth': trial.suggest_int('depth', 3, 8),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 10, log=True),\n",
    "            'verbose': False,\n",
    "            'random_seed': 42, # CatBoost uses random_seed\n",
    "            'thread_count': -1,\n",
    "            'objective': 'Logloss'\n",
    "        }\n",
    "    },\n",
    "    \"MLPClassifier\": {\n",
    "        \"class\": MLPClassifier,\n",
    "        \"random_dist\": {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "            'alpha': uniform(0.0001, 0.005),\n",
    "            'learning_rate_init': uniform(0.0001, 0.005)\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'hidden_layer_sizes': [(50,), (100,)],\n",
    "            'alpha': [0.0001, 0.001]\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50)]),\n",
    "            'alpha': trial.suggest_float('alpha', 1e-5, 1e-2, log=True),\n",
    "            'learning_rate_init': trial.suggest_float('learning_rate_init', 1e-4, 1e-2, log=True),\n",
    "            'max_iter': 2000,\n",
    "            'random_state': 42,\n",
    "            'solver': 'adam'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65441089-d139-4982-9de4-11c9d5367183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем процесс обучения и оценки моделей классификации...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee4aebc0b3b4dbbbf81ddebb765e031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Прогнозирование задач классификации:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Оптимизация для is_SI_above_median (PCA Aggregated):   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:10:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6322770\ttotal: 151ms\tremaining: 27.5s\n",
      "1:\tlearn: 0.5808480\ttotal: 157ms\tremaining: 14.2s\n",
      "2:\tlearn: 0.5519801\ttotal: 163ms\tremaining: 9.76s\n",
      "3:\tlearn: 0.5065076\ttotal: 171ms\tremaining: 7.67s\n",
      "4:\tlearn: 0.4713751\ttotal: 177ms\tremaining: 6.3s\n",
      "5:\tlearn: 0.4309107\ttotal: 186ms\tremaining: 5.47s\n",
      "6:\tlearn: 0.4015809\ttotal: 191ms\tremaining: 4.8s\n",
      "7:\tlearn: 0.3701903\ttotal: 200ms\tremaining: 4.36s\n",
      "8:\tlearn: 0.3469439\ttotal: 205ms\tremaining: 3.97s\n",
      "9:\tlearn: 0.3354301\ttotal: 213ms\tremaining: 3.69s\n",
      "10:\tlearn: 0.3204116\ttotal: 220ms\tremaining: 3.44s\n",
      "11:\tlearn: 0.3055000\ttotal: 232ms\tremaining: 3.3s\n",
      "12:\tlearn: 0.3005256\ttotal: 238ms\tremaining: 3.11s\n",
      "13:\tlearn: 0.2940480\ttotal: 249ms\tremaining: 3s\n",
      "14:\tlearn: 0.2814103\ttotal: 259ms\tremaining: 2.9s\n",
      "15:\tlearn: 0.2757114\ttotal: 272ms\tremaining: 2.84s\n",
      "16:\tlearn: 0.2708085\ttotal: 279ms\tremaining: 2.72s\n",
      "17:\tlearn: 0.2666366\ttotal: 288ms\tremaining: 2.64s\n",
      "18:\tlearn: 0.2531082\ttotal: 297ms\tremaining: 2.56s\n",
      "19:\tlearn: 0.2465242\ttotal: 308ms\tremaining: 2.51s\n",
      "20:\tlearn: 0.2421956\ttotal: 317ms\tremaining: 2.44s\n",
      "21:\tlearn: 0.2345947\ttotal: 326ms\tremaining: 2.39s\n",
      "22:\tlearn: 0.2295470\ttotal: 334ms\tremaining: 2.33s\n",
      "23:\tlearn: 0.2240678\ttotal: 344ms\tremaining: 2.28s\n",
      "24:\tlearn: 0.2221885\ttotal: 350ms\tremaining: 2.21s\n",
      "25:\tlearn: 0.2211438\ttotal: 358ms\tremaining: 2.16s\n",
      "26:\tlearn: 0.2186900\ttotal: 367ms\tremaining: 2.12s\n",
      "27:\tlearn: 0.2096319\ttotal: 376ms\tremaining: 2.08s\n",
      "28:\tlearn: 0.2064307\ttotal: 385ms\tremaining: 2.05s\n",
      "29:\tlearn: 0.2017806\ttotal: 394ms\tremaining: 2.01s\n",
      "30:\tlearn: 0.1988526\ttotal: 404ms\tremaining: 1.98s\n",
      "31:\tlearn: 0.1943981\ttotal: 412ms\tremaining: 1.95s\n",
      "32:\tlearn: 0.1934021\ttotal: 423ms\tremaining: 1.92s\n",
      "33:\tlearn: 0.1882823\ttotal: 429ms\tremaining: 1.88s\n",
      "34:\tlearn: 0.1867486\ttotal: 439ms\tremaining: 1.86s\n",
      "35:\tlearn: 0.1859356\ttotal: 448ms\tremaining: 1.83s\n",
      "36:\tlearn: 0.1841110\ttotal: 459ms\tremaining: 1.81s\n",
      "37:\tlearn: 0.1812041\ttotal: 467ms\tremaining: 1.78s\n",
      "38:\tlearn: 0.1801134\ttotal: 477ms\tremaining: 1.76s\n",
      "39:\tlearn: 0.1787385\ttotal: 486ms\tremaining: 1.74s\n",
      "40:\tlearn: 0.1780751\ttotal: 494ms\tremaining: 1.71s\n",
      "41:\tlearn: 0.1758174\ttotal: 502ms\tremaining: 1.69s\n",
      "42:\tlearn: 0.1741064\ttotal: 510ms\tremaining: 1.66s\n",
      "43:\tlearn: 0.1709193\ttotal: 518ms\tremaining: 1.64s\n",
      "44:\tlearn: 0.1697365\ttotal: 524ms\tremaining: 1.61s\n",
      "45:\tlearn: 0.1694324\ttotal: 532ms\tremaining: 1.58s\n",
      "46:\tlearn: 0.1649707\ttotal: 539ms\tremaining: 1.56s\n",
      "47:\tlearn: 0.1641557\ttotal: 548ms\tremaining: 1.54s\n",
      "48:\tlearn: 0.1613537\ttotal: 553ms\tremaining: 1.51s\n",
      "49:\tlearn: 0.1563143\ttotal: 563ms\tremaining: 1.5s\n",
      "50:\tlearn: 0.1503374\ttotal: 568ms\tremaining: 1.47s\n",
      "51:\tlearn: 0.1476732\ttotal: 578ms\tremaining: 1.46s\n",
      "52:\tlearn: 0.1471083\ttotal: 584ms\tremaining: 1.43s\n",
      "53:\tlearn: 0.1462306\ttotal: 593ms\tremaining: 1.42s\n",
      "54:\tlearn: 0.1450068\ttotal: 600ms\tremaining: 1.4s\n",
      "55:\tlearn: 0.1448639\ttotal: 608ms\tremaining: 1.38s\n",
      "56:\tlearn: 0.1397688\ttotal: 615ms\tremaining: 1.36s\n",
      "57:\tlearn: 0.1351923\ttotal: 623ms\tremaining: 1.34s\n",
      "58:\tlearn: 0.1349816\ttotal: 630ms\tremaining: 1.32s\n",
      "59:\tlearn: 0.1340234\ttotal: 639ms\tremaining: 1.31s\n",
      "60:\tlearn: 0.1329465\ttotal: 647ms\tremaining: 1.29s\n",
      "61:\tlearn: 0.1323038\ttotal: 655ms\tremaining: 1.28s\n",
      "62:\tlearn: 0.1304350\ttotal: 660ms\tremaining: 1.26s\n",
      "63:\tlearn: 0.1292649\ttotal: 669ms\tremaining: 1.24s\n",
      "64:\tlearn: 0.1284942\ttotal: 675ms\tremaining: 1.23s\n",
      "65:\tlearn: 0.1280153\ttotal: 681ms\tremaining: 1.21s\n",
      "66:\tlearn: 0.1254759\ttotal: 691ms\tremaining: 1.2s\n",
      "67:\tlearn: 0.1233554\ttotal: 696ms\tremaining: 1.18s\n",
      "68:\tlearn: 0.1231952\ttotal: 708ms\tremaining: 1.17s\n",
      "69:\tlearn: 0.1212364\ttotal: 714ms\tremaining: 1.15s\n",
      "70:\tlearn: 0.1185195\ttotal: 724ms\tremaining: 1.14s\n",
      "71:\tlearn: 0.1181827\ttotal: 731ms\tremaining: 1.13s\n",
      "72:\tlearn: 0.1177623\ttotal: 739ms\tremaining: 1.11s\n",
      "73:\tlearn: 0.1171375\ttotal: 746ms\tremaining: 1.1s\n",
      "74:\tlearn: 0.1160849\ttotal: 751ms\tremaining: 1.08s\n",
      "75:\tlearn: 0.1135074\ttotal: 756ms\tremaining: 1.06s\n",
      "76:\tlearn: 0.1133881\ttotal: 763ms\tremaining: 1.05s\n",
      "77:\tlearn: 0.1118947\ttotal: 771ms\tremaining: 1.04s\n",
      "78:\tlearn: 0.1117607\ttotal: 777ms\tremaining: 1.02s\n",
      "79:\tlearn: 0.1109841\ttotal: 785ms\tremaining: 1.01s\n",
      "80:\tlearn: 0.1058271\ttotal: 790ms\tremaining: 995ms\n",
      "81:\tlearn: 0.1013780\ttotal: 798ms\tremaining: 983ms\n",
      "82:\tlearn: 0.1009763\ttotal: 805ms\tremaining: 970ms\n",
      "83:\tlearn: 0.0991180\ttotal: 813ms\tremaining: 959ms\n",
      "84:\tlearn: 0.0978127\ttotal: 819ms\tremaining: 944ms\n",
      "85:\tlearn: 0.0952032\ttotal: 830ms\tremaining: 936ms\n",
      "86:\tlearn: 0.0947423\ttotal: 835ms\tremaining: 921ms\n",
      "87:\tlearn: 0.0945141\ttotal: 844ms\tremaining: 911ms\n",
      "88:\tlearn: 0.0931419\ttotal: 849ms\tremaining: 897ms\n",
      "89:\tlearn: 0.0924230\ttotal: 859ms\tremaining: 888ms\n",
      "90:\tlearn: 0.0917271\ttotal: 864ms\tremaining: 874ms\n",
      "91:\tlearn: 0.0886001\ttotal: 872ms\tremaining: 862ms\n",
      "92:\tlearn: 0.0882868\ttotal: 880ms\tremaining: 852ms\n",
      "93:\tlearn: 0.0845151\ttotal: 886ms\tremaining: 839ms\n",
      "94:\tlearn: 0.0832085\ttotal: 894ms\tremaining: 828ms\n",
      "95:\tlearn: 0.0830842\ttotal: 900ms\tremaining: 815ms\n",
      "96:\tlearn: 0.0824199\ttotal: 910ms\tremaining: 807ms\n",
      "97:\tlearn: 0.0820840\ttotal: 916ms\tremaining: 795ms\n",
      "98:\tlearn: 0.0818532\ttotal: 926ms\tremaining: 785ms\n",
      "99:\tlearn: 0.0815743\ttotal: 931ms\tremaining: 773ms\n",
      "100:\tlearn: 0.0810479\ttotal: 941ms\tremaining: 764ms\n",
      "101:\tlearn: 0.0779441\ttotal: 948ms\tremaining: 753ms\n",
      "102:\tlearn: 0.0778312\ttotal: 956ms\tremaining: 742ms\n",
      "103:\tlearn: 0.0758285\ttotal: 960ms\tremaining: 729ms\n",
      "104:\tlearn: 0.0750107\ttotal: 975ms\tremaining: 725ms\n",
      "105:\tlearn: 0.0744327\ttotal: 986ms\tremaining: 716ms\n",
      "106:\tlearn: 0.0742859\ttotal: 991ms\tremaining: 704ms\n",
      "107:\tlearn: 0.0726031\ttotal: 995ms\tremaining: 691ms\n",
      "108:\tlearn: 0.0706893\ttotal: 1000ms\tremaining: 679ms\n",
      "109:\tlearn: 0.0692127\ttotal: 1s\tremaining: 667ms\n",
      "110:\tlearn: 0.0688112\ttotal: 1.01s\tremaining: 655ms\n",
      "111:\tlearn: 0.0685597\ttotal: 1.01s\tremaining: 643ms\n",
      "112:\tlearn: 0.0681749\ttotal: 1.02s\tremaining: 631ms\n",
      "113:\tlearn: 0.0662600\ttotal: 1.02s\tremaining: 619ms\n",
      "114:\tlearn: 0.0634861\ttotal: 1.03s\tremaining: 607ms\n",
      "115:\tlearn: 0.0627009\ttotal: 1.03s\tremaining: 595ms\n",
      "116:\tlearn: 0.0618622\ttotal: 1.03s\tremaining: 583ms\n",
      "117:\tlearn: 0.0615035\ttotal: 1.04s\tremaining: 571ms\n",
      "118:\tlearn: 0.0610999\ttotal: 1.04s\tremaining: 559ms\n",
      "119:\tlearn: 0.0607235\ttotal: 1.04s\tremaining: 547ms\n",
      "120:\tlearn: 0.0599542\ttotal: 1.05s\tremaining: 536ms\n",
      "121:\tlearn: 0.0585974\ttotal: 1.05s\tremaining: 525ms\n",
      "122:\tlearn: 0.0561283\ttotal: 1.05s\tremaining: 513ms\n",
      "123:\tlearn: 0.0554249\ttotal: 1.05s\tremaining: 502ms\n",
      "124:\tlearn: 0.0553731\ttotal: 1.06s\tremaining: 491ms\n",
      "125:\tlearn: 0.0553251\ttotal: 1.06s\tremaining: 480ms\n",
      "126:\tlearn: 0.0549318\ttotal: 1.06s\tremaining: 470ms\n",
      "127:\tlearn: 0.0535492\ttotal: 1.07s\tremaining: 459ms\n",
      "128:\tlearn: 0.0535064\ttotal: 1.07s\tremaining: 449ms\n",
      "129:\tlearn: 0.0531786\ttotal: 1.07s\tremaining: 438ms\n",
      "130:\tlearn: 0.0516757\ttotal: 1.08s\tremaining: 428ms\n",
      "131:\tlearn: 0.0515410\ttotal: 1.08s\tremaining: 418ms\n",
      "132:\tlearn: 0.0514865\ttotal: 1.08s\tremaining: 408ms\n",
      "133:\tlearn: 0.0510165\ttotal: 1.09s\tremaining: 398ms\n",
      "134:\tlearn: 0.0503849\ttotal: 1.09s\tremaining: 388ms\n",
      "135:\tlearn: 0.0501890\ttotal: 1.09s\tremaining: 379ms\n",
      "136:\tlearn: 0.0496658\ttotal: 1.1s\tremaining: 369ms\n",
      "137:\tlearn: 0.0492714\ttotal: 1.1s\tremaining: 360ms\n",
      "138:\tlearn: 0.0487976\ttotal: 1.11s\tremaining: 351ms\n",
      "139:\tlearn: 0.0475098\ttotal: 1.11s\tremaining: 341ms\n",
      "140:\tlearn: 0.0471827\ttotal: 1.11s\tremaining: 332ms\n",
      "141:\tlearn: 0.0470877\ttotal: 1.12s\tremaining: 323ms\n",
      "142:\tlearn: 0.0468134\ttotal: 1.12s\tremaining: 314ms\n",
      "143:\tlearn: 0.0466020\ttotal: 1.13s\tremaining: 305ms\n",
      "144:\tlearn: 0.0463269\ttotal: 1.13s\tremaining: 296ms\n",
      "145:\tlearn: 0.0462755\ttotal: 1.13s\tremaining: 287ms\n",
      "146:\tlearn: 0.0457658\ttotal: 1.14s\tremaining: 278ms\n",
      "147:\tlearn: 0.0445402\ttotal: 1.14s\tremaining: 270ms\n",
      "148:\tlearn: 0.0441298\ttotal: 1.14s\tremaining: 261ms\n",
      "149:\tlearn: 0.0430425\ttotal: 1.15s\tremaining: 252ms\n",
      "150:\tlearn: 0.0421405\ttotal: 1.15s\tremaining: 244ms\n",
      "151:\tlearn: 0.0420782\ttotal: 1.15s\tremaining: 235ms\n",
      "152:\tlearn: 0.0418110\ttotal: 1.16s\tremaining: 227ms\n",
      "153:\tlearn: 0.0414835\ttotal: 1.16s\tremaining: 219ms\n",
      "154:\tlearn: 0.0404778\ttotal: 1.17s\tremaining: 210ms\n",
      "155:\tlearn: 0.0391561\ttotal: 1.17s\tremaining: 202ms\n",
      "156:\tlearn: 0.0383957\ttotal: 1.17s\tremaining: 194ms\n",
      "157:\tlearn: 0.0380949\ttotal: 1.18s\tremaining: 186ms\n",
      "158:\tlearn: 0.0378789\ttotal: 1.18s\tremaining: 178ms\n",
      "159:\tlearn: 0.0376430\ttotal: 1.18s\tremaining: 170ms\n",
      "160:\tlearn: 0.0371899\ttotal: 1.19s\tremaining: 162ms\n",
      "161:\tlearn: 0.0371543\ttotal: 1.19s\tremaining: 154ms\n",
      "162:\tlearn: 0.0369267\ttotal: 1.19s\tremaining: 146ms\n",
      "163:\tlearn: 0.0360518\ttotal: 1.2s\tremaining: 139ms\n",
      "164:\tlearn: 0.0359784\ttotal: 1.2s\tremaining: 131ms\n",
      "165:\tlearn: 0.0358072\ttotal: 1.2s\tremaining: 123ms\n",
      "166:\tlearn: 0.0354768\ttotal: 1.21s\tremaining: 116ms\n",
      "167:\tlearn: 0.0345822\ttotal: 1.21s\tremaining: 108ms\n",
      "168:\tlearn: 0.0345519\ttotal: 1.22s\tremaining: 101ms\n",
      "169:\tlearn: 0.0345148\ttotal: 1.22s\tremaining: 93.2ms\n",
      "170:\tlearn: 0.0342970\ttotal: 1.22s\tremaining: 85.8ms\n",
      "171:\tlearn: 0.0340180\ttotal: 1.23s\tremaining: 78.5ms\n",
      "172:\tlearn: 0.0333491\ttotal: 1.23s\tremaining: 71.1ms\n",
      "173:\tlearn: 0.0329900\ttotal: 1.23s\tremaining: 63.8ms\n",
      "174:\tlearn: 0.0329559\ttotal: 1.24s\tremaining: 56.6ms\n",
      "175:\tlearn: 0.0328424\ttotal: 1.24s\tremaining: 49.4ms\n",
      "176:\tlearn: 0.0327226\ttotal: 1.24s\tremaining: 42.2ms\n",
      "177:\tlearn: 0.0326432\ttotal: 1.25s\tremaining: 35ms\n",
      "178:\tlearn: 0.0324525\ttotal: 1.25s\tremaining: 28ms\n",
      "179:\tlearn: 0.0324306\ttotal: 1.25s\tremaining: 20.9ms\n",
      "180:\tlearn: 0.0317664\ttotal: 1.26s\tremaining: 13.9ms\n",
      "181:\tlearn: 0.0317322\ttotal: 1.26s\tremaining: 6.93ms\n",
      "182:\tlearn: 0.0315712\ttotal: 1.26s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6284020\ttotal: 6.49ms\tremaining: 967ms\n",
      "1:\tlearn: 0.5669791\ttotal: 11.9ms\tremaining: 882ms\n",
      "2:\tlearn: 0.5170338\ttotal: 17.7ms\tremaining: 869ms\n",
      "3:\tlearn: 0.4666842\ttotal: 24.6ms\tremaining: 896ms\n",
      "4:\tlearn: 0.4353049\ttotal: 30.3ms\tremaining: 878ms\n",
      "5:\tlearn: 0.4127328\ttotal: 36ms\tremaining: 865ms\n",
      "6:\tlearn: 0.3887460\ttotal: 42.8ms\tremaining: 875ms\n",
      "7:\tlearn: 0.3769063\ttotal: 49.7ms\tremaining: 882ms\n",
      "8:\tlearn: 0.3454787\ttotal: 55.8ms\tremaining: 875ms\n",
      "9:\tlearn: 0.3155290\ttotal: 63.1ms\tremaining: 883ms\n",
      "10:\tlearn: 0.3025630\ttotal: 69.9ms\tremaining: 884ms\n",
      "11:\tlearn: 0.2894313\ttotal: 75.7ms\tremaining: 871ms\n",
      "12:\tlearn: 0.2846856\ttotal: 81.4ms\tremaining: 858ms\n",
      "13:\tlearn: 0.2749604\ttotal: 87.8ms\tremaining: 853ms\n",
      "14:\tlearn: 0.2618136\ttotal: 94.2ms\tremaining: 848ms\n",
      "15:\tlearn: 0.2527423\ttotal: 101ms\tremaining: 850ms\n",
      "16:\tlearn: 0.2453737\ttotal: 107ms\tremaining: 835ms\n",
      "17:\tlearn: 0.2316849\ttotal: 113ms\tremaining: 830ms\n",
      "18:\tlearn: 0.2297259\ttotal: 121ms\tremaining: 833ms\n",
      "19:\tlearn: 0.2214267\ttotal: 128ms\tremaining: 829ms\n",
      "20:\tlearn: 0.2183578\ttotal: 135ms\tremaining: 830ms\n",
      "21:\tlearn: 0.2162838\ttotal: 142ms\tremaining: 827ms\n",
      "22:\tlearn: 0.2086839\ttotal: 148ms\tremaining: 817ms\n",
      "23:\tlearn: 0.2066065\ttotal: 155ms\tremaining: 815ms\n",
      "24:\tlearn: 0.2035468\ttotal: 162ms\tremaining: 811ms\n",
      "25:\tlearn: 0.1987933\ttotal: 171ms\tremaining: 817ms\n",
      "26:\tlearn: 0.1952429\ttotal: 180ms\tremaining: 819ms\n",
      "27:\tlearn: 0.1894219\ttotal: 188ms\tremaining: 818ms\n",
      "28:\tlearn: 0.1844646\ttotal: 201ms\tremaining: 837ms\n",
      "29:\tlearn: 0.1819637\ttotal: 210ms\tremaining: 839ms\n",
      "30:\tlearn: 0.1797232\ttotal: 217ms\tremaining: 835ms\n",
      "31:\tlearn: 0.1791024\ttotal: 226ms\tremaining: 834ms\n",
      "32:\tlearn: 0.1766677\ttotal: 236ms\tremaining: 836ms\n",
      "33:\tlearn: 0.1726382\ttotal: 245ms\tremaining: 835ms\n",
      "34:\tlearn: 0.1708404\ttotal: 255ms\tremaining: 836ms\n",
      "35:\tlearn: 0.1672772\ttotal: 278ms\tremaining: 879ms\n",
      "36:\tlearn: 0.1668171\ttotal: 286ms\tremaining: 873ms\n",
      "37:\tlearn: 0.1661640\ttotal: 293ms\tremaining: 863ms\n",
      "38:\tlearn: 0.1649475\ttotal: 306ms\tremaining: 872ms\n",
      "39:\tlearn: 0.1595319\ttotal: 317ms\tremaining: 871ms\n",
      "40:\tlearn: 0.1580677\ttotal: 325ms\tremaining: 864ms\n",
      "41:\tlearn: 0.1576227\ttotal: 332ms\tremaining: 854ms\n",
      "42:\tlearn: 0.1537758\ttotal: 341ms\tremaining: 848ms\n",
      "43:\tlearn: 0.1527282\ttotal: 348ms\tremaining: 839ms\n",
      "44:\tlearn: 0.1514644\ttotal: 355ms\tremaining: 828ms\n",
      "45:\tlearn: 0.1465152\ttotal: 363ms\tremaining: 821ms\n",
      "46:\tlearn: 0.1456208\ttotal: 370ms\tremaining: 811ms\n",
      "47:\tlearn: 0.1426899\ttotal: 377ms\tremaining: 801ms\n",
      "48:\tlearn: 0.1398939\ttotal: 384ms\tremaining: 791ms\n",
      "49:\tlearn: 0.1388196\ttotal: 391ms\tremaining: 782ms\n",
      "50:\tlearn: 0.1364583\ttotal: 397ms\tremaining: 771ms\n",
      "51:\tlearn: 0.1346188\ttotal: 405ms\tremaining: 763ms\n",
      "52:\tlearn: 0.1339900\ttotal: 411ms\tremaining: 753ms\n",
      "53:\tlearn: 0.1333908\ttotal: 418ms\tremaining: 743ms\n",
      "54:\tlearn: 0.1324856\ttotal: 426ms\tremaining: 735ms\n",
      "55:\tlearn: 0.1286009\ttotal: 432ms\tremaining: 726ms\n",
      "56:\tlearn: 0.1263560\ttotal: 442ms\tremaining: 721ms\n",
      "57:\tlearn: 0.1258796\ttotal: 450ms\tremaining: 713ms\n",
      "58:\tlearn: 0.1218160\ttotal: 458ms\tremaining: 706ms\n",
      "59:\tlearn: 0.1216330\ttotal: 464ms\tremaining: 695ms\n",
      "60:\tlearn: 0.1209647\ttotal: 471ms\tremaining: 687ms\n",
      "61:\tlearn: 0.1171984\ttotal: 478ms\tremaining: 678ms\n",
      "62:\tlearn: 0.1166726\ttotal: 484ms\tremaining: 668ms\n",
      "63:\tlearn: 0.1160027\ttotal: 491ms\tremaining: 659ms\n",
      "64:\tlearn: 0.1149368\ttotal: 496ms\tremaining: 649ms\n",
      "65:\tlearn: 0.1142873\ttotal: 505ms\tremaining: 643ms\n",
      "66:\tlearn: 0.1141229\ttotal: 511ms\tremaining: 632ms\n",
      "67:\tlearn: 0.1110522\ttotal: 517ms\tremaining: 623ms\n",
      "68:\tlearn: 0.1093868\ttotal: 524ms\tremaining: 616ms\n",
      "69:\tlearn: 0.1069779\ttotal: 530ms\tremaining: 605ms\n",
      "70:\tlearn: 0.1055333\ttotal: 537ms\tremaining: 598ms\n",
      "71:\tlearn: 0.1006725\ttotal: 544ms\tremaining: 590ms\n",
      "72:\tlearn: 0.0996527\ttotal: 553ms\tremaining: 583ms\n",
      "73:\tlearn: 0.0993595\ttotal: 560ms\tremaining: 575ms\n",
      "74:\tlearn: 0.0990647\ttotal: 566ms\tremaining: 566ms\n",
      "75:\tlearn: 0.0947241\ttotal: 576ms\tremaining: 560ms\n",
      "76:\tlearn: 0.0917682\ttotal: 583ms\tremaining: 553ms\n",
      "77:\tlearn: 0.0889968\ttotal: 590ms\tremaining: 545ms\n",
      "78:\tlearn: 0.0885917\ttotal: 600ms\tremaining: 539ms\n",
      "79:\tlearn: 0.0840394\ttotal: 608ms\tremaining: 532ms\n",
      "80:\tlearn: 0.0838285\ttotal: 616ms\tremaining: 525ms\n",
      "81:\tlearn: 0.0825301\ttotal: 623ms\tremaining: 517ms\n",
      "82:\tlearn: 0.0792439\ttotal: 631ms\tremaining: 509ms\n",
      "83:\tlearn: 0.0786867\ttotal: 638ms\tremaining: 501ms\n",
      "84:\tlearn: 0.0785109\ttotal: 645ms\tremaining: 493ms\n",
      "85:\tlearn: 0.0783836\ttotal: 652ms\tremaining: 485ms\n",
      "86:\tlearn: 0.0781370\ttotal: 658ms\tremaining: 476ms\n",
      "87:\tlearn: 0.0744126\ttotal: 665ms\tremaining: 468ms\n",
      "88:\tlearn: 0.0738926\ttotal: 672ms\tremaining: 460ms\n",
      "89:\tlearn: 0.0720078\ttotal: 680ms\tremaining: 453ms\n",
      "90:\tlearn: 0.0682878\ttotal: 688ms\tremaining: 446ms\n",
      "91:\tlearn: 0.0677033\ttotal: 697ms\tremaining: 439ms\n",
      "92:\tlearn: 0.0665141\ttotal: 704ms\tremaining: 431ms\n",
      "93:\tlearn: 0.0663977\ttotal: 713ms\tremaining: 425ms\n",
      "94:\tlearn: 0.0662771\ttotal: 720ms\tremaining: 417ms\n",
      "95:\tlearn: 0.0638674\ttotal: 726ms\tremaining: 408ms\n",
      "96:\tlearn: 0.0637746\ttotal: 733ms\tremaining: 401ms\n",
      "97:\tlearn: 0.0631826\ttotal: 740ms\tremaining: 393ms\n",
      "98:\tlearn: 0.0617703\ttotal: 748ms\tremaining: 385ms\n",
      "99:\tlearn: 0.0604843\ttotal: 755ms\tremaining: 378ms\n",
      "100:\tlearn: 0.0578786\ttotal: 764ms\tremaining: 371ms\n",
      "101:\tlearn: 0.0564557\ttotal: 773ms\tremaining: 364ms\n",
      "102:\tlearn: 0.0563231\ttotal: 781ms\tremaining: 356ms\n",
      "103:\tlearn: 0.0558103\ttotal: 788ms\tremaining: 349ms\n",
      "104:\tlearn: 0.0538662\ttotal: 795ms\tremaining: 341ms\n",
      "105:\tlearn: 0.0527019\ttotal: 802ms\tremaining: 333ms\n",
      "106:\tlearn: 0.0501794\ttotal: 808ms\tremaining: 325ms\n",
      "107:\tlearn: 0.0497728\ttotal: 816ms\tremaining: 317ms\n",
      "108:\tlearn: 0.0492329\ttotal: 823ms\tremaining: 310ms\n",
      "109:\tlearn: 0.0482469\ttotal: 830ms\tremaining: 302ms\n",
      "110:\tlearn: 0.0475031\ttotal: 838ms\tremaining: 294ms\n",
      "111:\tlearn: 0.0470757\ttotal: 846ms\tremaining: 287ms\n",
      "112:\tlearn: 0.0469927\ttotal: 853ms\tremaining: 279ms\n",
      "113:\tlearn: 0.0458444\ttotal: 861ms\tremaining: 272ms\n",
      "114:\tlearn: 0.0457794\ttotal: 869ms\tremaining: 264ms\n",
      "115:\tlearn: 0.0451832\ttotal: 877ms\tremaining: 257ms\n",
      "116:\tlearn: 0.0440480\ttotal: 884ms\tremaining: 249ms\n",
      "117:\tlearn: 0.0439377\ttotal: 892ms\tremaining: 242ms\n",
      "118:\tlearn: 0.0436130\ttotal: 897ms\tremaining: 234ms\n",
      "119:\tlearn: 0.0434943\ttotal: 903ms\tremaining: 226ms\n",
      "120:\tlearn: 0.0434395\ttotal: 910ms\tremaining: 218ms\n",
      "121:\tlearn: 0.0431293\ttotal: 933ms\tremaining: 214ms\n",
      "122:\tlearn: 0.0418326\ttotal: 938ms\tremaining: 206ms\n",
      "123:\tlearn: 0.0412492\ttotal: 945ms\tremaining: 198ms\n",
      "124:\tlearn: 0.0403011\ttotal: 953ms\tremaining: 191ms\n",
      "125:\tlearn: 0.0401623\ttotal: 961ms\tremaining: 183ms\n",
      "126:\tlearn: 0.0398981\ttotal: 966ms\tremaining: 175ms\n",
      "127:\tlearn: 0.0382885\ttotal: 972ms\tremaining: 167ms\n",
      "128:\tlearn: 0.0379378\ttotal: 980ms\tremaining: 159ms\n",
      "129:\tlearn: 0.0377363\ttotal: 988ms\tremaining: 152ms\n",
      "130:\tlearn: 0.0369402\ttotal: 994ms\tremaining: 144ms\n",
      "131:\tlearn: 0.0359204\ttotal: 1s\tremaining: 136ms\n",
      "132:\tlearn: 0.0358767\ttotal: 1.01s\tremaining: 129ms\n",
      "133:\tlearn: 0.0357150\ttotal: 1.01s\tremaining: 121ms\n",
      "134:\tlearn: 0.0354992\ttotal: 1.02s\tremaining: 113ms\n",
      "135:\tlearn: 0.0353028\ttotal: 1.03s\tremaining: 106ms\n",
      "136:\tlearn: 0.0352316\ttotal: 1.03s\tremaining: 98.2ms\n",
      "137:\tlearn: 0.0350494\ttotal: 1.04s\tremaining: 90.6ms\n",
      "138:\tlearn: 0.0350111\ttotal: 1.05s\tremaining: 83ms\n",
      "139:\tlearn: 0.0345504\ttotal: 1.06s\tremaining: 75.4ms\n",
      "140:\tlearn: 0.0337380\ttotal: 1.06s\tremaining: 68ms\n",
      "141:\tlearn: 0.0333377\ttotal: 1.07s\tremaining: 60.4ms\n",
      "142:\tlearn: 0.0328995\ttotal: 1.08s\tremaining: 52.8ms\n",
      "143:\tlearn: 0.0328661\ttotal: 1.09s\tremaining: 45.3ms\n",
      "144:\tlearn: 0.0326708\ttotal: 1.09s\tremaining: 37.7ms\n",
      "145:\tlearn: 0.0324494\ttotal: 1.1s\tremaining: 30.2ms\n",
      "146:\tlearn: 0.0313763\ttotal: 1.11s\tremaining: 22.6ms\n",
      "147:\tlearn: 0.0311789\ttotal: 1.11s\tremaining: 15.1ms\n",
      "148:\tlearn: 0.0309219\ttotal: 1.12s\tremaining: 7.53ms\n",
      "149:\tlearn: 0.0307747\ttotal: 1.13s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-06-18 20:16:27,338] A new study created in memory with name: no-name-713d4645-229d-4931-9c6e-1a58abd3a9f5\n",
      "[I 2025-06-18 20:16:27,535] Trial 0 finished with value: -0.99653125 and parameters: {'C': 0.5611516415334505, 'penalty': 'l1'}. Best is trial 0 with value: -0.99653125.\n",
      "[I 2025-06-18 20:16:27,856] Trial 1 finished with value: -0.9962500000000001 and parameters: {'C': 1.5751320499779735, 'penalty': 'l1'}. Best is trial 0 with value: -0.99653125.\n",
      "[I 2025-06-18 20:16:27,957] Trial 2 finished with value: -0.9970000000000001 and parameters: {'C': 0.13066739238053282, 'penalty': 'l1'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:28,272] Trial 3 finished with value: -0.9821874999999999 and parameters: {'C': 2.607024758370768, 'penalty': 'l2'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:28,769] Trial 4 finished with value: -0.9952499999999999 and parameters: {'C': 4.622589001020832, 'penalty': 'l1'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:28,969] Trial 5 finished with value: -0.97440625 and parameters: {'C': 0.2327067708383781, 'penalty': 'l2'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:29,184] Trial 6 finished with value: -0.97990625 and parameters: {'C': 0.7309539835912913, 'penalty': 'l2'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:29,369] Trial 7 finished with value: -0.9728749999999999 and parameters: {'C': 0.19010245319870356, 'penalty': 'l2'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:29,610] Trial 8 finished with value: -0.9961250000000001 and parameters: {'C': 0.8168455894760165, 'penalty': 'l1'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:29,871] Trial 9 finished with value: -0.99609375 and parameters: {'C': 1.0677482709481354, 'penalty': 'l1'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:29,977] Trial 10 finished with value: -0.99684375 and parameters: {'C': 0.10991587445851024, 'penalty': 'l1'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:30,082] Trial 11 finished with value: -0.99684375 and parameters: {'C': 0.10353677627159782, 'penalty': 'l1'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:30,177] Trial 12 finished with value: -0.9969687500000001 and parameters: {'C': 0.10691887002123487, 'penalty': 'l1'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:30,321] Trial 13 finished with value: -0.9967500000000001 and parameters: {'C': 0.324255176142218, 'penalty': 'l1'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:30,462] Trial 14 finished with value: -0.9967812500000001 and parameters: {'C': 0.31876142671215074, 'penalty': 'l1'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:31,090] Trial 15 finished with value: -0.994375 and parameters: {'C': 8.611382274356343, 'penalty': 'l1'}. Best is trial 2 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:16:31,213] Trial 16 finished with value: -0.99703125 and parameters: {'C': 0.1588471280716395, 'penalty': 'l1'}. Best is trial 16 with value: -0.99703125.\n",
      "[I 2025-06-18 20:16:31,326] Trial 17 finished with value: -0.99703125 and parameters: {'C': 0.18273464454980845, 'penalty': 'l1'}. Best is trial 16 with value: -0.99703125.\n",
      "[I 2025-06-18 20:16:31,515] Trial 18 finished with value: -0.9778125 and parameters: {'C': 0.43239045729560244, 'penalty': 'l2'}. Best is trial 16 with value: -0.99703125.\n",
      "[I 2025-06-18 20:16:31,635] Trial 19 finished with value: -0.99709375 and parameters: {'C': 0.19433714520506473, 'penalty': 'l1'}. Best is trial 19 with value: -0.99709375.\n",
      "[I 2025-06-18 20:16:31,669] A new study created in memory with name: no-name-3d71af0a-924c-4c1c-83c9-280fecfe2300\n",
      "[I 2025-06-18 20:16:34,457] Trial 0 finished with value: -0.8315312499999999 and parameters: {'n_estimators': 106, 'max_depth': 5, 'min_samples_split': 3}. Best is trial 0 with value: -0.8315312499999999.\n",
      "[I 2025-06-18 20:16:36,040] Trial 1 finished with value: -0.8235625000000001 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 0 with value: -0.8315312499999999.\n",
      "[I 2025-06-18 20:16:41,496] Trial 2 finished with value: -0.8729687499999998 and parameters: {'n_estimators': 175, 'max_depth': None, 'min_samples_split': 5}. Best is trial 2 with value: -0.8729687499999998.\n",
      "[I 2025-06-18 20:16:44,266] Trial 3 finished with value: -0.8619999999999999 and parameters: {'n_estimators': 115, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 2 with value: -0.8729687499999998.\n",
      "[I 2025-06-18 20:16:46,498] Trial 4 finished with value: -0.83765625 and parameters: {'n_estimators': 118, 'max_depth': 5, 'min_samples_split': 2}. Best is trial 2 with value: -0.8729687499999998.\n",
      "[I 2025-06-18 20:16:49,823] Trial 5 finished with value: -0.86471875 and parameters: {'n_estimators': 141, 'max_depth': None, 'min_samples_split': 7}. Best is trial 2 with value: -0.8729687499999998.\n",
      "[I 2025-06-18 20:16:51,710] Trial 6 finished with value: -0.8595312500000001 and parameters: {'n_estimators': 95, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 2 with value: -0.8729687499999998.\n",
      "[I 2025-06-18 20:16:52,570] Trial 7 finished with value: -0.8234999999999999 and parameters: {'n_estimators': 55, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 2 with value: -0.8729687499999998.\n",
      "[I 2025-06-18 20:16:55,117] Trial 8 finished with value: -0.8651562499999998 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 2 with value: -0.8729687499999998.\n",
      "[I 2025-06-18 20:16:57,273] Trial 9 finished with value: -0.8414375 and parameters: {'n_estimators': 140, 'max_depth': 5, 'min_samples_split': 4}. Best is trial 2 with value: -0.8729687499999998.\n",
      "[I 2025-06-18 20:17:01,622] Trial 10 finished with value: -0.8751249999999999 and parameters: {'n_estimators': 197, 'max_depth': None, 'min_samples_split': 6}. Best is trial 10 with value: -0.8751249999999999.\n",
      "[I 2025-06-18 20:17:05,604] Trial 11 finished with value: -0.8752187499999999 and parameters: {'n_estimators': 193, 'max_depth': None, 'min_samples_split': 6}. Best is trial 11 with value: -0.8752187499999999.\n",
      "[I 2025-06-18 20:17:09,690] Trial 12 finished with value: -0.87321875 and parameters: {'n_estimators': 198, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 11 with value: -0.8752187499999999.\n",
      "[I 2025-06-18 20:17:14,072] Trial 13 finished with value: -0.8758437499999999 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 6}. Best is trial 13 with value: -0.8758437499999999.\n",
      "[I 2025-06-18 20:17:18,139] Trial 14 finished with value: -0.87325 and parameters: {'n_estimators': 170, 'max_depth': None, 'min_samples_split': 6}. Best is trial 13 with value: -0.8758437499999999.\n",
      "[I 2025-06-18 20:17:22,183] Trial 15 finished with value: -0.8727812500000001 and parameters: {'n_estimators': 168, 'max_depth': None, 'min_samples_split': 6}. Best is trial 13 with value: -0.8758437499999999.\n",
      "[I 2025-06-18 20:17:26,703] Trial 16 finished with value: -0.8717499999999999 and parameters: {'n_estimators': 183, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 13 with value: -0.8758437499999999.\n",
      "[I 2025-06-18 20:17:31,032] Trial 17 finished with value: -0.870953125 and parameters: {'n_estimators': 154, 'max_depth': None, 'min_samples_split': 4}. Best is trial 13 with value: -0.8758437499999999.\n",
      "[I 2025-06-18 20:17:36,240] Trial 18 finished with value: -0.8756562499999999 and parameters: {'n_estimators': 188, 'max_depth': None, 'min_samples_split': 6}. Best is trial 13 with value: -0.8758437499999999.\n",
      "[I 2025-06-18 20:17:40,565] Trial 19 finished with value: -0.8667187499999999 and parameters: {'n_estimators': 157, 'max_depth': None, 'min_samples_split': 7}. Best is trial 13 with value: -0.8758437499999999.\n",
      "[I 2025-06-18 20:17:41,922] A new study created in memory with name: no-name-913e939c-1250-41b6-b70d-0d39c3ee2d4b\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:43,810] Trial 0 finished with value: -0.9922187499999999 and parameters: {'n_estimators': 106, 'learning_rate': 0.13125830316209655, 'max_depth': 7, 'subsample': 0.8795975452591109}. Best is trial 0 with value: -0.9922187499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:44,655] Trial 1 finished with value: -0.972640625 and parameters: {'n_estimators': 73, 'learning_rate': 0.015256811898068502, 'max_depth': 3, 'subsample': 0.9598528437324805}. Best is trial 0 with value: -0.9922187499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:46,228] Trial 2 finished with value: -0.9922500000000001 and parameters: {'n_estimators': 140, 'learning_rate': 0.06803900745073706, 'max_depth': 3, 'subsample': 0.9909729556485982}. Best is trial 2 with value: -0.9922500000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:48,872] Trial 3 finished with value: -0.9907187499999999 and parameters: {'n_estimators': 175, 'learning_rate': 0.01777174904859463, 'max_depth': 4, 'subsample': 0.7550213529560301}. Best is trial 2 with value: -0.9922500000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:50,591] Trial 4 finished with value: -0.9923125 and parameters: {'n_estimators': 95, 'learning_rate': 0.04141536110538596, 'max_depth': 5, 'subsample': 0.7873687420594125}. Best is trial 4 with value: -0.9923125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:52,717] Trial 5 finished with value: -0.98878125 and parameters: {'n_estimators': 142, 'learning_rate': 0.01459007452373112, 'max_depth': 4, 'subsample': 0.8099085529881075}. Best is trial 4 with value: -0.9923125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:54,315] Trial 6 finished with value: -0.9920937499999999 and parameters: {'n_estimators': 118, 'learning_rate': 0.0838375512850209, 'max_depth': 4, 'subsample': 0.8542703315240835}. Best is trial 4 with value: -0.9923125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:57,351] Trial 7 finished with value: -0.988875 and parameters: {'n_estimators': 139, 'learning_rate': 0.011340440501807348, 'max_depth': 6, 'subsample': 0.7511572371061874}. Best is trial 4 with value: -0.9923125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:59,544] Trial 8 finished with value: -0.9920937500000001 and parameters: {'n_estimators': 59, 'learning_rate': 0.13060986669773664, 'max_depth': 8, 'subsample': 0.9425192044349383}. Best is trial 4 with value: -0.9923125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:03,544] Trial 9 finished with value: -0.98675 and parameters: {'n_estimators': 95, 'learning_rate': 0.01302780710309028, 'max_depth': 7, 'subsample': 0.8320457481218804}. Best is trial 4 with value: -0.9923125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:07,256] Trial 10 finished with value: -0.9926562500000001 and parameters: {'n_estimators': 192, 'learning_rate': 0.028825693577590687, 'max_depth': 5, 'subsample': 0.7053885626844458}. Best is trial 10 with value: -0.9926562500000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:10,934] Trial 11 finished with value: -0.9924062499999999 and parameters: {'n_estimators': 191, 'learning_rate': 0.03223498404215344, 'max_depth': 5, 'subsample': 0.7054367296359227}. Best is trial 10 with value: -0.9926562500000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:15,248] Trial 12 finished with value: -0.99225 and parameters: {'n_estimators': 198, 'learning_rate': 0.027954339326293067, 'max_depth': 5, 'subsample': 0.7014481884937426}. Best is trial 10 with value: -0.9926562500000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:19,430] Trial 13 finished with value: -0.9925625 and parameters: {'n_estimators': 178, 'learning_rate': 0.03242221000947164, 'max_depth': 6, 'subsample': 0.7060063846342731}. Best is trial 10 with value: -0.9926562500000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:26,055] Trial 14 finished with value: -0.99278125 and parameters: {'n_estimators': 168, 'learning_rate': 0.04964482136657893, 'max_depth': 6, 'subsample': 0.7432273803164781}. Best is trial 14 with value: -0.99278125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:27,671] Trial 15 finished with value: -0.9922187499999999 and parameters: {'n_estimators': 164, 'learning_rate': 0.06470799889081995, 'max_depth': 7, 'subsample': 0.7609021695894858}. Best is trial 14 with value: -0.99278125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:30,150] Trial 16 finished with value: -0.99296875 and parameters: {'n_estimators': 161, 'learning_rate': 0.023328856410404736, 'max_depth': 6, 'subsample': 0.7408415462126681}. Best is trial 16 with value: -0.99296875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:31,973] Trial 17 finished with value: -0.9926875000000001 and parameters: {'n_estimators': 158, 'learning_rate': 0.04845288719847123, 'max_depth': 8, 'subsample': 0.8974752436176948}. Best is trial 16 with value: -0.99296875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:37,349] Trial 18 finished with value: -0.9919687500000001 and parameters: {'n_estimators': 153, 'learning_rate': 0.02083463664643419, 'max_depth': 6, 'subsample': 0.7904645445912986}. Best is trial 16 with value: -0.99296875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:46,374] Trial 19 finished with value: -0.9924375 and parameters: {'n_estimators': 178, 'learning_rate': 0.02263866065837982, 'max_depth': 7, 'subsample': 0.7540160474845709}. Best is trial 16 with value: -0.99296875.\n",
      "[I 2025-06-18 20:18:46,916] A new study created in memory with name: no-name-ce589419-c355-4fcf-89cf-6df1bb32e826\n",
      "[I 2025-06-18 20:18:54,063] Trial 0 finished with value: -0.9852187500000001 and parameters: {'iterations': 106, 'learning_rate': 0.13125830316209655, 'depth': 7, 'l2_leaf_reg': 0.6251373574521749}. Best is trial 0 with value: -0.9852187500000001.\n",
      "[I 2025-06-18 20:18:56,163] Trial 1 finished with value: -0.9586874999999999 and parameters: {'iterations': 73, 'learning_rate': 0.015256811898068502, 'depth': 3, 'l2_leaf_reg': 3.9676050770529883}. Best is trial 0 with value: -0.9852187500000001.\n",
      "[I 2025-06-18 20:18:59,353] Trial 2 finished with value: -0.9862500000000001 and parameters: {'iterations': 140, 'learning_rate': 0.06803900745073706, 'depth': 3, 'l2_leaf_reg': 8.123245085588687}. Best is trial 2 with value: -0.9862500000000001.\n",
      "[I 2025-06-18 20:19:05,210] Trial 3 finished with value: -0.98028125 and parameters: {'iterations': 175, 'learning_rate': 0.01777174904859463, 'depth': 4, 'l2_leaf_reg': 0.03549878832196503}. Best is trial 2 with value: -0.9862500000000001.\n",
      "[I 2025-06-18 20:19:10,234] Trial 4 finished with value: -0.9779687499999999 and parameters: {'iterations': 95, 'learning_rate': 0.04141536110538596, 'depth': 5, 'l2_leaf_reg': 0.07476312062252301}. Best is trial 2 with value: -0.9862500000000001.\n",
      "[I 2025-06-18 20:19:16,450] Trial 5 finished with value: -0.97596875 and parameters: {'iterations': 142, 'learning_rate': 0.01459007452373112, 'depth': 4, 'l2_leaf_reg': 0.1256277350380703}. Best is trial 2 with value: -0.9862500000000001.\n",
      "[I 2025-06-18 20:19:21,460] Trial 6 finished with value: -0.9847187500000001 and parameters: {'iterations': 118, 'learning_rate': 0.0838375512850209, 'depth': 4, 'l2_leaf_reg': 0.34890188454913873}. Best is trial 2 with value: -0.9862500000000001.\n",
      "[I 2025-06-18 20:19:30,674] Trial 7 finished with value: -0.97828125 and parameters: {'iterations': 139, 'learning_rate': 0.011340440501807348, 'depth': 6, 'l2_leaf_reg': 0.03247673570627449}. Best is trial 2 with value: -0.9862500000000001.\n",
      "[I 2025-06-18 20:19:41,380] Trial 8 finished with value: -0.9786875 and parameters: {'iterations': 59, 'learning_rate': 0.13060986669773664, 'depth': 8, 'l2_leaf_reg': 2.6619018884890564}. Best is trial 2 with value: -0.9862500000000001.\n",
      "[I 2025-06-18 20:19:49,373] Trial 9 finished with value: -0.974625 and parameters: {'iterations': 95, 'learning_rate': 0.01302780710309028, 'depth': 7, 'l2_leaf_reg': 0.2091498132903561}. Best is trial 2 with value: -0.9862500000000001.\n",
      "[I 2025-06-18 20:19:55,340] Trial 10 finished with value: -0.98628125 and parameters: {'iterations': 194, 'learning_rate': 0.04542131010106151, 'depth': 3, 'l2_leaf_reg': 7.332884431753993}. Best is trial 10 with value: -0.98628125.\n",
      "[I 2025-06-18 20:20:00,086] Trial 11 finished with value: -0.98496875 and parameters: {'iterations': 195, 'learning_rate': 0.047583949325428546, 'depth': 3, 'l2_leaf_reg': 9.116925308189677}. Best is trial 10 with value: -0.98628125.\n",
      "[I 2025-06-18 20:20:04,485] Trial 12 finished with value: -0.9879062500000002 and parameters: {'iterations': 164, 'learning_rate': 0.0696130364836842, 'depth': 3, 'l2_leaf_reg': 1.234433488463974}. Best is trial 12 with value: -0.9879062500000002.\n",
      "[I 2025-06-18 20:20:12,926] Trial 13 finished with value: -0.9818125 and parameters: {'iterations': 171, 'learning_rate': 0.02659986258001816, 'depth': 5, 'l2_leaf_reg': 1.0841314642634914}. Best is trial 12 with value: -0.9879062500000002.\n",
      "[I 2025-06-18 20:20:17,435] Trial 14 finished with value: -0.9907812499999998 and parameters: {'iterations': 199, 'learning_rate': 0.06481997376425686, 'depth': 3, 'l2_leaf_reg': 1.82020492563511}. Best is trial 14 with value: -0.9907812499999998.\n",
      "[I 2025-06-18 20:20:21,891] Trial 15 finished with value: -0.98965625 and parameters: {'iterations': 169, 'learning_rate': 0.07531619451353291, 'depth': 4, 'l2_leaf_reg': 1.2597189568080893}. Best is trial 14 with value: -0.9907812499999998.\n",
      "[I 2025-06-18 20:20:25,897] Trial 16 finished with value: -0.98765625 and parameters: {'iterations': 199, 'learning_rate': 0.09815822307211873, 'depth': 4, 'l2_leaf_reg': 1.3675191184068176}. Best is trial 14 with value: -0.9907812499999998.\n",
      "[I 2025-06-18 20:20:32,198] Trial 17 finished with value: -0.9809375000000001 and parameters: {'iterations': 163, 'learning_rate': 0.02995483198218181, 'depth': 5, 'l2_leaf_reg': 0.4538752398417268}. Best is trial 14 with value: -0.9907812499999998.\n",
      "[I 2025-06-18 20:20:37,823] Trial 18 finished with value: -0.9876249999999999 and parameters: {'iterations': 181, 'learning_rate': 0.0602873926891976, 'depth': 4, 'l2_leaf_reg': 2.6125080031297907}. Best is trial 14 with value: -0.9907812499999998.\n",
      "[I 2025-06-18 20:20:44,045] Trial 19 finished with value: -0.9881249999999999 and parameters: {'iterations': 152, 'learning_rate': 0.09717191344255731, 'depth': 6, 'l2_leaf_reg': 0.647855234463543}. Best is trial 14 with value: -0.9907812499999998.\n",
      "[I 2025-06-18 20:20:44,794] A new study created in memory with name: no-name-c319d8b5-8bed-4872-95da-71c05bb1c947\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:21:06,810] Trial 0 finished with value: -0.94009375 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 2.9380279387035334e-05, 'learning_rate_init': 0.00020511104188433984}. Best is trial 0 with value: -0.94009375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:21:08,592] Trial 1 finished with value: -0.945875 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.1527987128232396e-05, 'learning_rate_init': 0.008706020878304856}. Best is trial 1 with value: -0.945875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:21:16,151] Trial 2 finished with value: -0.9450312499999999 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 8.17949947521167e-05, 'learning_rate_init': 0.0011207606211860567}. Best is trial 1 with value: -0.945875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:22:43,095] Trial 3 finished with value: -0.9354374999999999 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 7.52374288453485e-05, 'learning_rate_init': 0.0005404103854647331}. Best is trial 1 with value: -0.945875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:17,028] Trial 4 finished with value: -0.93215625 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0005987474910461401, 'learning_rate_init': 0.0001238513729886094}. Best is trial 1 with value: -0.945875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:19,488] Trial 5 finished with value: -0.9477812499999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00788671412999049, 'learning_rate_init': 0.004138040112561018}. Best is trial 5 with value: -0.9477812499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:24,783] Trial 6 finished with value: -0.9376562500000001 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 2.32335035153901e-05, 'learning_rate_init': 0.0009780337016659412}. Best is trial 5 with value: -0.9477812499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:32,317] Trial 7 finished with value: -0.9500624999999999 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 8.612579192594876e-05, 'learning_rate_init': 0.001096821720752952}. Best is trial 7 with value: -0.9500624999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:33,600] Trial 8 finished with value: -0.93690625 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.006584106160121612, 'learning_rate_init': 0.006161049539380964}. Best is trial 7 with value: -0.9500624999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:47,519] Trial 9 finished with value: -0.94240625 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.3667272915456215e-05, 'learning_rate_init': 0.0004473636174621269}. Best is trial 7 with value: -0.9500624999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:49,981] Trial 10 finished with value: -0.9375312499999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0005419455959713102, 'learning_rate_init': 0.0024673775376624486}. Best is trial 7 with value: -0.9500624999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:51,866] Trial 11 finished with value: -0.9414999999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.008947232156563659, 'learning_rate_init': 0.0030212949837585194}. Best is trial 7 with value: -0.9500624999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:53,978] Trial 12 finished with value: -0.9348124999999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0014267936837498493, 'learning_rate_init': 0.002792346336213017}. Best is trial 7 with value: -0.9500624999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:59,701] Trial 13 finished with value: -0.9456562500000001 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.00015666022383765016, 'learning_rate_init': 0.0014157259823495414}. Best is trial 7 with value: -0.9500624999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:01,400] Trial 14 finished with value: -0.94790625 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0022581792073715907, 'learning_rate_init': 0.005490056775613342}. Best is trial 7 with value: -0.9500624999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:03,177] Trial 15 finished with value: -0.9543750000000001 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0019633158825389874, 'learning_rate_init': 0.009914072534938173}. Best is trial 15 with value: -0.9543750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:17,310] Trial 16 finished with value: -0.93925 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0002827448689421037, 'learning_rate_init': 0.0003722831881434341}. Best is trial 15 with value: -0.9543750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:22,151] Trial 17 finished with value: -0.95078125 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.002163765438068398, 'learning_rate_init': 0.0020200513082957827}. Best is trial 15 with value: -0.9543750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:23,751] Trial 18 finished with value: -0.95684375 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0024605732643850557, 'learning_rate_init': 0.009737456278942954}. Best is trial 18 with value: -0.95684375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:25,296] Trial 19 finished with value: -0.94625 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0034752685500732076, 'learning_rate_init': 0.009807809182773151}. Best is trial 18 with value: -0.95684375.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Оптимизация для is_SI_above_median (Manual Aggregated):   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:24:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6577397\ttotal: 4.02ms\tremaining: 723ms\n",
      "1:\tlearn: 0.5890835\ttotal: 7.81ms\tremaining: 699ms\n",
      "2:\tlearn: 0.5380949\ttotal: 11.2ms\tremaining: 667ms\n",
      "3:\tlearn: 0.5059439\ttotal: 14.6ms\tremaining: 645ms\n",
      "4:\tlearn: 0.4743358\ttotal: 17.8ms\tremaining: 625ms\n",
      "5:\tlearn: 0.4422253\ttotal: 20.9ms\tremaining: 609ms\n",
      "6:\tlearn: 0.4292620\ttotal: 24ms\tremaining: 597ms\n",
      "7:\tlearn: 0.3964552\ttotal: 27.3ms\tremaining: 591ms\n",
      "8:\tlearn: 0.3771384\ttotal: 31.1ms\tremaining: 595ms\n",
      "9:\tlearn: 0.3613671\ttotal: 34.4ms\tremaining: 588ms\n",
      "10:\tlearn: 0.3450046\ttotal: 38ms\tremaining: 587ms\n",
      "11:\tlearn: 0.3385975\ttotal: 41.7ms\tremaining: 587ms\n",
      "12:\tlearn: 0.3295845\ttotal: 44.8ms\tremaining: 580ms\n",
      "13:\tlearn: 0.3228625\ttotal: 47.9ms\tremaining: 571ms\n",
      "14:\tlearn: 0.3172186\ttotal: 52.4ms\tremaining: 580ms\n",
      "15:\tlearn: 0.2989872\ttotal: 55.6ms\tremaining: 574ms\n",
      "16:\tlearn: 0.2862629\ttotal: 58.9ms\tremaining: 568ms\n",
      "17:\tlearn: 0.2800706\ttotal: 62.1ms\tremaining: 562ms\n",
      "18:\tlearn: 0.2749556\ttotal: 65.2ms\tremaining: 556ms\n",
      "19:\tlearn: 0.2727578\ttotal: 68.7ms\tremaining: 553ms\n",
      "20:\tlearn: 0.2701682\ttotal: 72ms\tremaining: 549ms\n",
      "21:\tlearn: 0.2673784\ttotal: 75.3ms\tremaining: 544ms\n",
      "22:\tlearn: 0.2660590\ttotal: 78.4ms\tremaining: 538ms\n",
      "23:\tlearn: 0.2595578\ttotal: 81.5ms\tremaining: 533ms\n",
      "24:\tlearn: 0.2564196\ttotal: 85ms\tremaining: 531ms\n",
      "25:\tlearn: 0.2552909\ttotal: 89.1ms\tremaining: 531ms\n",
      "26:\tlearn: 0.2493488\ttotal: 92.9ms\tremaining: 530ms\n",
      "27:\tlearn: 0.2487346\ttotal: 96.8ms\tremaining: 529ms\n",
      "28:\tlearn: 0.2481253\ttotal: 100ms\tremaining: 526ms\n",
      "29:\tlearn: 0.2382420\ttotal: 104ms\tremaining: 526ms\n",
      "30:\tlearn: 0.2296658\ttotal: 109ms\tremaining: 528ms\n",
      "31:\tlearn: 0.2291330\ttotal: 113ms\tremaining: 527ms\n",
      "32:\tlearn: 0.2280577\ttotal: 117ms\tremaining: 524ms\n",
      "33:\tlearn: 0.2205568\ttotal: 121ms\tremaining: 521ms\n",
      "34:\tlearn: 0.2136140\ttotal: 124ms\tremaining: 519ms\n",
      "35:\tlearn: 0.2125683\ttotal: 128ms\tremaining: 517ms\n",
      "36:\tlearn: 0.2122286\ttotal: 132ms\tremaining: 512ms\n",
      "37:\tlearn: 0.2116513\ttotal: 135ms\tremaining: 507ms\n",
      "38:\tlearn: 0.2090851\ttotal: 139ms\tremaining: 506ms\n",
      "39:\tlearn: 0.2066455\ttotal: 143ms\tremaining: 504ms\n",
      "40:\tlearn: 0.2064248\ttotal: 146ms\tremaining: 500ms\n",
      "41:\tlearn: 0.1990251\ttotal: 150ms\tremaining: 495ms\n",
      "42:\tlearn: 0.1971002\ttotal: 153ms\tremaining: 493ms\n",
      "43:\tlearn: 0.1930688\ttotal: 157ms\tremaining: 490ms\n",
      "44:\tlearn: 0.1925397\ttotal: 161ms\tremaining: 486ms\n",
      "45:\tlearn: 0.1896903\ttotal: 164ms\tremaining: 482ms\n",
      "46:\tlearn: 0.1877164\ttotal: 167ms\tremaining: 477ms\n",
      "47:\tlearn: 0.1820867\ttotal: 172ms\tremaining: 478ms\n",
      "48:\tlearn: 0.1808688\ttotal: 176ms\tremaining: 475ms\n",
      "49:\tlearn: 0.1802330\ttotal: 180ms\tremaining: 471ms\n",
      "50:\tlearn: 0.1795523\ttotal: 183ms\tremaining: 467ms\n",
      "51:\tlearn: 0.1793493\ttotal: 187ms\tremaining: 465ms\n",
      "52:\tlearn: 0.1789004\ttotal: 191ms\tremaining: 461ms\n",
      "53:\tlearn: 0.1748636\ttotal: 194ms\tremaining: 457ms\n",
      "54:\tlearn: 0.1722312\ttotal: 198ms\tremaining: 454ms\n",
      "55:\tlearn: 0.1712485\ttotal: 202ms\tremaining: 451ms\n",
      "56:\tlearn: 0.1708372\ttotal: 205ms\tremaining: 447ms\n",
      "57:\tlearn: 0.1691612\ttotal: 209ms\tremaining: 443ms\n",
      "58:\tlearn: 0.1684974\ttotal: 212ms\tremaining: 438ms\n",
      "59:\tlearn: 0.1681056\ttotal: 216ms\tremaining: 435ms\n",
      "60:\tlearn: 0.1628222\ttotal: 219ms\tremaining: 431ms\n",
      "61:\tlearn: 0.1556198\ttotal: 232ms\tremaining: 445ms\n",
      "62:\tlearn: 0.1550151\ttotal: 235ms\tremaining: 440ms\n",
      "63:\tlearn: 0.1513370\ttotal: 238ms\tremaining: 436ms\n",
      "64:\tlearn: 0.1468275\ttotal: 241ms\tremaining: 431ms\n",
      "65:\tlearn: 0.1467490\ttotal: 245ms\tremaining: 427ms\n",
      "66:\tlearn: 0.1464092\ttotal: 248ms\tremaining: 422ms\n",
      "67:\tlearn: 0.1440767\ttotal: 251ms\tremaining: 418ms\n",
      "68:\tlearn: 0.1436086\ttotal: 255ms\tremaining: 413ms\n",
      "69:\tlearn: 0.1429168\ttotal: 258ms\tremaining: 408ms\n",
      "70:\tlearn: 0.1406381\ttotal: 261ms\tremaining: 405ms\n",
      "71:\tlearn: 0.1386336\ttotal: 264ms\tremaining: 400ms\n",
      "72:\tlearn: 0.1381368\ttotal: 267ms\tremaining: 395ms\n",
      "73:\tlearn: 0.1359879\ttotal: 270ms\tremaining: 391ms\n",
      "74:\tlearn: 0.1329506\ttotal: 274ms\tremaining: 387ms\n",
      "75:\tlearn: 0.1299361\ttotal: 278ms\tremaining: 383ms\n",
      "76:\tlearn: 0.1271635\ttotal: 281ms\tremaining: 379ms\n",
      "77:\tlearn: 0.1268760\ttotal: 284ms\tremaining: 375ms\n",
      "78:\tlearn: 0.1267177\ttotal: 287ms\tremaining: 371ms\n",
      "79:\tlearn: 0.1250665\ttotal: 291ms\tremaining: 367ms\n",
      "80:\tlearn: 0.1247859\ttotal: 294ms\tremaining: 363ms\n",
      "81:\tlearn: 0.1216918\ttotal: 297ms\tremaining: 358ms\n",
      "82:\tlearn: 0.1180291\ttotal: 300ms\tremaining: 355ms\n",
      "83:\tlearn: 0.1178561\ttotal: 304ms\tremaining: 351ms\n",
      "84:\tlearn: 0.1170262\ttotal: 309ms\tremaining: 349ms\n",
      "85:\tlearn: 0.1167637\ttotal: 313ms\tremaining: 345ms\n",
      "86:\tlearn: 0.1165840\ttotal: 316ms\tremaining: 341ms\n",
      "87:\tlearn: 0.1164438\ttotal: 319ms\tremaining: 337ms\n",
      "88:\tlearn: 0.1162475\ttotal: 322ms\tremaining: 333ms\n",
      "89:\tlearn: 0.1160872\ttotal: 325ms\tremaining: 329ms\n",
      "90:\tlearn: 0.1143301\ttotal: 328ms\tremaining: 324ms\n",
      "91:\tlearn: 0.1109242\ttotal: 331ms\tremaining: 320ms\n",
      "92:\tlearn: 0.1092542\ttotal: 334ms\tremaining: 316ms\n",
      "93:\tlearn: 0.1063855\ttotal: 337ms\tremaining: 312ms\n",
      "94:\tlearn: 0.1058866\ttotal: 340ms\tremaining: 308ms\n",
      "95:\tlearn: 0.1046109\ttotal: 343ms\tremaining: 304ms\n",
      "96:\tlearn: 0.1031246\ttotal: 346ms\tremaining: 300ms\n",
      "97:\tlearn: 0.1030179\ttotal: 349ms\tremaining: 296ms\n",
      "98:\tlearn: 0.1027833\ttotal: 352ms\tremaining: 292ms\n",
      "99:\tlearn: 0.1016704\ttotal: 355ms\tremaining: 288ms\n",
      "100:\tlearn: 0.1014437\ttotal: 358ms\tremaining: 284ms\n",
      "101:\tlearn: 0.1013395\ttotal: 361ms\tremaining: 280ms\n",
      "102:\tlearn: 0.1009689\ttotal: 365ms\tremaining: 276ms\n",
      "103:\tlearn: 0.0985586\ttotal: 368ms\tremaining: 273ms\n",
      "104:\tlearn: 0.0951314\ttotal: 371ms\tremaining: 269ms\n",
      "105:\tlearn: 0.0949989\ttotal: 374ms\tremaining: 265ms\n",
      "106:\tlearn: 0.0945693\ttotal: 377ms\tremaining: 261ms\n",
      "107:\tlearn: 0.0944945\ttotal: 381ms\tremaining: 258ms\n",
      "108:\tlearn: 0.0944193\ttotal: 384ms\tremaining: 254ms\n",
      "109:\tlearn: 0.0941450\ttotal: 388ms\tremaining: 250ms\n",
      "110:\tlearn: 0.0938978\ttotal: 392ms\tremaining: 247ms\n",
      "111:\tlearn: 0.0936443\ttotal: 395ms\tremaining: 243ms\n",
      "112:\tlearn: 0.0936038\ttotal: 398ms\tremaining: 240ms\n",
      "113:\tlearn: 0.0921319\ttotal: 402ms\tremaining: 236ms\n",
      "114:\tlearn: 0.0902264\ttotal: 405ms\tremaining: 233ms\n",
      "115:\tlearn: 0.0898347\ttotal: 409ms\tremaining: 229ms\n",
      "116:\tlearn: 0.0895550\ttotal: 412ms\tremaining: 226ms\n",
      "117:\tlearn: 0.0892369\ttotal: 416ms\tremaining: 222ms\n",
      "118:\tlearn: 0.0882859\ttotal: 419ms\tremaining: 218ms\n",
      "119:\tlearn: 0.0881306\ttotal: 423ms\tremaining: 215ms\n",
      "120:\tlearn: 0.0848528\ttotal: 426ms\tremaining: 211ms\n",
      "121:\tlearn: 0.0847117\ttotal: 430ms\tremaining: 208ms\n",
      "122:\tlearn: 0.0846772\ttotal: 433ms\tremaining: 204ms\n",
      "123:\tlearn: 0.0819667\ttotal: 436ms\tremaining: 200ms\n",
      "124:\tlearn: 0.0818989\ttotal: 439ms\tremaining: 197ms\n",
      "125:\tlearn: 0.0816235\ttotal: 442ms\tremaining: 193ms\n",
      "126:\tlearn: 0.0814635\ttotal: 446ms\tremaining: 190ms\n",
      "127:\tlearn: 0.0813756\ttotal: 450ms\tremaining: 186ms\n",
      "128:\tlearn: 0.0788137\ttotal: 453ms\tremaining: 183ms\n",
      "129:\tlearn: 0.0772925\ttotal: 457ms\tremaining: 179ms\n",
      "130:\tlearn: 0.0770669\ttotal: 461ms\tremaining: 176ms\n",
      "131:\tlearn: 0.0757657\ttotal: 464ms\tremaining: 172ms\n",
      "132:\tlearn: 0.0749086\ttotal: 467ms\tremaining: 169ms\n",
      "133:\tlearn: 0.0748365\ttotal: 471ms\tremaining: 165ms\n",
      "134:\tlearn: 0.0739060\ttotal: 475ms\tremaining: 162ms\n",
      "135:\tlearn: 0.0738510\ttotal: 478ms\tremaining: 158ms\n",
      "136:\tlearn: 0.0714305\ttotal: 482ms\tremaining: 155ms\n",
      "137:\tlearn: 0.0713398\ttotal: 486ms\tremaining: 151ms\n",
      "138:\tlearn: 0.0713066\ttotal: 489ms\tremaining: 148ms\n",
      "139:\tlearn: 0.0710965\ttotal: 492ms\tremaining: 144ms\n",
      "140:\tlearn: 0.0699100\ttotal: 496ms\tremaining: 141ms\n",
      "141:\tlearn: 0.0697965\ttotal: 499ms\tremaining: 137ms\n",
      "142:\tlearn: 0.0697712\ttotal: 502ms\tremaining: 133ms\n",
      "143:\tlearn: 0.0693987\ttotal: 505ms\tremaining: 130ms\n",
      "144:\tlearn: 0.0693749\ttotal: 509ms\tremaining: 126ms\n",
      "145:\tlearn: 0.0681644\ttotal: 512ms\tremaining: 123ms\n",
      "146:\tlearn: 0.0670244\ttotal: 515ms\tremaining: 119ms\n",
      "147:\tlearn: 0.0669807\ttotal: 518ms\tremaining: 116ms\n",
      "148:\tlearn: 0.0669444\ttotal: 522ms\tremaining: 112ms\n",
      "149:\tlearn: 0.0667759\ttotal: 525ms\tremaining: 108ms\n",
      "150:\tlearn: 0.0666411\ttotal: 528ms\tremaining: 105ms\n",
      "151:\tlearn: 0.0652364\ttotal: 532ms\tremaining: 101ms\n",
      "152:\tlearn: 0.0639099\ttotal: 535ms\tremaining: 97.9ms\n",
      "153:\tlearn: 0.0638119\ttotal: 539ms\tremaining: 94.4ms\n",
      "154:\tlearn: 0.0637628\ttotal: 543ms\tremaining: 91ms\n",
      "155:\tlearn: 0.0637121\ttotal: 546ms\tremaining: 87.5ms\n",
      "156:\tlearn: 0.0635599\ttotal: 549ms\tremaining: 84ms\n",
      "157:\tlearn: 0.0623477\ttotal: 552ms\tremaining: 80.4ms\n",
      "158:\tlearn: 0.0616111\ttotal: 556ms\tremaining: 76.9ms\n",
      "159:\tlearn: 0.0615812\ttotal: 559ms\tremaining: 73.4ms\n",
      "160:\tlearn: 0.0614452\ttotal: 562ms\tremaining: 69.8ms\n",
      "161:\tlearn: 0.0608044\ttotal: 565ms\tremaining: 66.3ms\n",
      "162:\tlearn: 0.0606362\ttotal: 568ms\tremaining: 62.7ms\n",
      "163:\tlearn: 0.0591881\ttotal: 571ms\tremaining: 59.2ms\n",
      "164:\tlearn: 0.0590587\ttotal: 575ms\tremaining: 55.7ms\n",
      "165:\tlearn: 0.0589086\ttotal: 578ms\tremaining: 52.2ms\n",
      "166:\tlearn: 0.0580676\ttotal: 581ms\tremaining: 48.7ms\n",
      "167:\tlearn: 0.0579657\ttotal: 584ms\tremaining: 45.2ms\n",
      "168:\tlearn: 0.0579285\ttotal: 587ms\tremaining: 41.7ms\n",
      "169:\tlearn: 0.0577966\ttotal: 590ms\tremaining: 38.2ms\n",
      "170:\tlearn: 0.0576804\ttotal: 593ms\tremaining: 34.7ms\n",
      "171:\tlearn: 0.0575798\ttotal: 596ms\tremaining: 31.2ms\n",
      "172:\tlearn: 0.0562350\ttotal: 599ms\tremaining: 27.7ms\n",
      "173:\tlearn: 0.0559978\ttotal: 602ms\tremaining: 24.2ms\n",
      "174:\tlearn: 0.0548954\ttotal: 605ms\tremaining: 20.7ms\n",
      "175:\tlearn: 0.0545976\ttotal: 608ms\tremaining: 17.3ms\n",
      "176:\tlearn: 0.0545641\ttotal: 611ms\tremaining: 13.8ms\n",
      "177:\tlearn: 0.0545312\ttotal: 613ms\tremaining: 10.3ms\n",
      "178:\tlearn: 0.0536183\ttotal: 617ms\tremaining: 6.89ms\n",
      "179:\tlearn: 0.0533206\ttotal: 620ms\tremaining: 3.44ms\n",
      "180:\tlearn: 0.0531949\ttotal: 623ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:25:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6325181\ttotal: 5.58ms\tremaining: 831ms\n",
      "1:\tlearn: 0.5795591\ttotal: 10.3ms\tremaining: 765ms\n",
      "2:\tlearn: 0.5342047\ttotal: 15ms\tremaining: 736ms\n",
      "3:\tlearn: 0.4926796\ttotal: 19.4ms\tremaining: 707ms\n",
      "4:\tlearn: 0.4630151\ttotal: 24.4ms\tremaining: 707ms\n",
      "5:\tlearn: 0.4438544\ttotal: 29.4ms\tremaining: 705ms\n",
      "6:\tlearn: 0.4190594\ttotal: 34ms\tremaining: 695ms\n",
      "7:\tlearn: 0.3921964\ttotal: 39.1ms\tremaining: 694ms\n",
      "8:\tlearn: 0.3531651\ttotal: 44.1ms\tremaining: 691ms\n",
      "9:\tlearn: 0.3276347\ttotal: 49.1ms\tremaining: 688ms\n",
      "10:\tlearn: 0.3115109\ttotal: 53.7ms\tremaining: 679ms\n",
      "11:\tlearn: 0.2990683\ttotal: 58.3ms\tremaining: 671ms\n",
      "12:\tlearn: 0.2847420\ttotal: 63ms\tremaining: 664ms\n",
      "13:\tlearn: 0.2717905\ttotal: 67.6ms\tremaining: 656ms\n",
      "14:\tlearn: 0.2626801\ttotal: 71.7ms\tremaining: 646ms\n",
      "15:\tlearn: 0.2562705\ttotal: 76.1ms\tremaining: 638ms\n",
      "16:\tlearn: 0.2477995\ttotal: 80.9ms\tremaining: 633ms\n",
      "17:\tlearn: 0.2448623\ttotal: 85.7ms\tremaining: 628ms\n",
      "18:\tlearn: 0.2318486\ttotal: 90.6ms\tremaining: 624ms\n",
      "19:\tlearn: 0.2236391\ttotal: 95.3ms\tremaining: 619ms\n",
      "20:\tlearn: 0.2217225\ttotal: 99.8ms\tremaining: 613ms\n",
      "21:\tlearn: 0.2172818\ttotal: 104ms\tremaining: 607ms\n",
      "22:\tlearn: 0.2092935\ttotal: 109ms\tremaining: 602ms\n",
      "23:\tlearn: 0.2056489\ttotal: 114ms\tremaining: 599ms\n",
      "24:\tlearn: 0.1995675\ttotal: 120ms\tremaining: 599ms\n",
      "25:\tlearn: 0.1934115\ttotal: 124ms\tremaining: 590ms\n",
      "26:\tlearn: 0.1838976\ttotal: 128ms\tremaining: 584ms\n",
      "27:\tlearn: 0.1799744\ttotal: 134ms\tremaining: 584ms\n",
      "28:\tlearn: 0.1780501\ttotal: 139ms\tremaining: 579ms\n",
      "29:\tlearn: 0.1728588\ttotal: 144ms\tremaining: 575ms\n",
      "30:\tlearn: 0.1699372\ttotal: 149ms\tremaining: 570ms\n",
      "31:\tlearn: 0.1663642\ttotal: 153ms\tremaining: 563ms\n",
      "32:\tlearn: 0.1651082\ttotal: 157ms\tremaining: 558ms\n",
      "33:\tlearn: 0.1644790\ttotal: 162ms\tremaining: 554ms\n",
      "34:\tlearn: 0.1579868\ttotal: 167ms\tremaining: 549ms\n",
      "35:\tlearn: 0.1567091\ttotal: 171ms\tremaining: 543ms\n",
      "36:\tlearn: 0.1531021\ttotal: 177ms\tremaining: 539ms\n",
      "37:\tlearn: 0.1477238\ttotal: 181ms\tremaining: 533ms\n",
      "38:\tlearn: 0.1469245\ttotal: 186ms\tremaining: 530ms\n",
      "39:\tlearn: 0.1460346\ttotal: 191ms\tremaining: 524ms\n",
      "40:\tlearn: 0.1432334\ttotal: 195ms\tremaining: 518ms\n",
      "41:\tlearn: 0.1427970\ttotal: 199ms\tremaining: 512ms\n",
      "42:\tlearn: 0.1414804\ttotal: 204ms\tremaining: 508ms\n",
      "43:\tlearn: 0.1398046\ttotal: 209ms\tremaining: 504ms\n",
      "44:\tlearn: 0.1388147\ttotal: 214ms\tremaining: 500ms\n",
      "45:\tlearn: 0.1363910\ttotal: 219ms\tremaining: 495ms\n",
      "46:\tlearn: 0.1352232\ttotal: 224ms\tremaining: 491ms\n",
      "47:\tlearn: 0.1338838\ttotal: 229ms\tremaining: 486ms\n",
      "48:\tlearn: 0.1321221\ttotal: 233ms\tremaining: 480ms\n",
      "49:\tlearn: 0.1308982\ttotal: 238ms\tremaining: 476ms\n",
      "50:\tlearn: 0.1299883\ttotal: 243ms\tremaining: 471ms\n",
      "51:\tlearn: 0.1294536\ttotal: 247ms\tremaining: 466ms\n",
      "52:\tlearn: 0.1279640\ttotal: 252ms\tremaining: 461ms\n",
      "53:\tlearn: 0.1245136\ttotal: 256ms\tremaining: 456ms\n",
      "54:\tlearn: 0.1241473\ttotal: 261ms\tremaining: 450ms\n",
      "55:\tlearn: 0.1239218\ttotal: 265ms\tremaining: 445ms\n",
      "56:\tlearn: 0.1232708\ttotal: 272ms\tremaining: 444ms\n",
      "57:\tlearn: 0.1198682\ttotal: 277ms\tremaining: 440ms\n",
      "58:\tlearn: 0.1171942\ttotal: 282ms\tremaining: 435ms\n",
      "59:\tlearn: 0.1168869\ttotal: 287ms\tremaining: 430ms\n",
      "60:\tlearn: 0.1159755\ttotal: 291ms\tremaining: 425ms\n",
      "61:\tlearn: 0.1125159\ttotal: 296ms\tremaining: 420ms\n",
      "62:\tlearn: 0.1117432\ttotal: 300ms\tremaining: 415ms\n",
      "63:\tlearn: 0.1076975\ttotal: 304ms\tremaining: 409ms\n",
      "64:\tlearn: 0.1065225\ttotal: 309ms\tremaining: 404ms\n",
      "65:\tlearn: 0.1054682\ttotal: 313ms\tremaining: 399ms\n",
      "66:\tlearn: 0.1052369\ttotal: 318ms\tremaining: 393ms\n",
      "67:\tlearn: 0.1040355\ttotal: 322ms\tremaining: 388ms\n",
      "68:\tlearn: 0.1031485\ttotal: 326ms\tremaining: 383ms\n",
      "69:\tlearn: 0.1011844\ttotal: 331ms\tremaining: 378ms\n",
      "70:\tlearn: 0.1006499\ttotal: 335ms\tremaining: 372ms\n",
      "71:\tlearn: 0.1002464\ttotal: 339ms\tremaining: 368ms\n",
      "72:\tlearn: 0.0997997\ttotal: 344ms\tremaining: 363ms\n",
      "73:\tlearn: 0.0986801\ttotal: 348ms\tremaining: 358ms\n",
      "74:\tlearn: 0.0973423\ttotal: 353ms\tremaining: 353ms\n",
      "75:\tlearn: 0.0933127\ttotal: 357ms\tremaining: 348ms\n",
      "76:\tlearn: 0.0923259\ttotal: 361ms\tremaining: 343ms\n",
      "77:\tlearn: 0.0891580\ttotal: 366ms\tremaining: 338ms\n",
      "78:\tlearn: 0.0856794\ttotal: 371ms\tremaining: 333ms\n",
      "79:\tlearn: 0.0816883\ttotal: 376ms\tremaining: 329ms\n",
      "80:\tlearn: 0.0815790\ttotal: 380ms\tremaining: 323ms\n",
      "81:\tlearn: 0.0809362\ttotal: 383ms\tremaining: 318ms\n",
      "82:\tlearn: 0.0804707\ttotal: 387ms\tremaining: 313ms\n",
      "83:\tlearn: 0.0801034\ttotal: 392ms\tremaining: 308ms\n",
      "84:\tlearn: 0.0778629\ttotal: 396ms\tremaining: 303ms\n",
      "85:\tlearn: 0.0774971\ttotal: 400ms\tremaining: 298ms\n",
      "86:\tlearn: 0.0750153\ttotal: 405ms\tremaining: 293ms\n",
      "87:\tlearn: 0.0748216\ttotal: 409ms\tremaining: 288ms\n",
      "88:\tlearn: 0.0703007\ttotal: 413ms\tremaining: 283ms\n",
      "89:\tlearn: 0.0697672\ttotal: 418ms\tremaining: 278ms\n",
      "90:\tlearn: 0.0686456\ttotal: 423ms\tremaining: 274ms\n",
      "91:\tlearn: 0.0682566\ttotal: 427ms\tremaining: 269ms\n",
      "92:\tlearn: 0.0652105\ttotal: 431ms\tremaining: 264ms\n",
      "93:\tlearn: 0.0628236\ttotal: 436ms\tremaining: 260ms\n",
      "94:\tlearn: 0.0626335\ttotal: 441ms\tremaining: 255ms\n",
      "95:\tlearn: 0.0624971\ttotal: 445ms\tremaining: 250ms\n",
      "96:\tlearn: 0.0622422\ttotal: 450ms\tremaining: 246ms\n",
      "97:\tlearn: 0.0602314\ttotal: 454ms\tremaining: 241ms\n",
      "98:\tlearn: 0.0596443\ttotal: 459ms\tremaining: 237ms\n",
      "99:\tlearn: 0.0579201\ttotal: 464ms\tremaining: 232ms\n",
      "100:\tlearn: 0.0565287\ttotal: 468ms\tremaining: 227ms\n",
      "101:\tlearn: 0.0564115\ttotal: 472ms\tremaining: 222ms\n",
      "102:\tlearn: 0.0545583\ttotal: 476ms\tremaining: 217ms\n",
      "103:\tlearn: 0.0531042\ttotal: 481ms\tremaining: 213ms\n",
      "104:\tlearn: 0.0529979\ttotal: 485ms\tremaining: 208ms\n",
      "105:\tlearn: 0.0509570\ttotal: 490ms\tremaining: 203ms\n",
      "106:\tlearn: 0.0505635\ttotal: 494ms\tremaining: 199ms\n",
      "107:\tlearn: 0.0492966\ttotal: 499ms\tremaining: 194ms\n",
      "108:\tlearn: 0.0490836\ttotal: 503ms\tremaining: 189ms\n",
      "109:\tlearn: 0.0489188\ttotal: 507ms\tremaining: 185ms\n",
      "110:\tlearn: 0.0484299\ttotal: 512ms\tremaining: 180ms\n",
      "111:\tlearn: 0.0467229\ttotal: 517ms\tremaining: 175ms\n",
      "112:\tlearn: 0.0459527\ttotal: 522ms\tremaining: 171ms\n",
      "113:\tlearn: 0.0458446\ttotal: 527ms\tremaining: 166ms\n",
      "114:\tlearn: 0.0451241\ttotal: 531ms\tremaining: 162ms\n",
      "115:\tlearn: 0.0441253\ttotal: 535ms\tremaining: 157ms\n",
      "116:\tlearn: 0.0423578\ttotal: 540ms\tremaining: 152ms\n",
      "117:\tlearn: 0.0415709\ttotal: 544ms\tremaining: 148ms\n",
      "118:\tlearn: 0.0414503\ttotal: 549ms\tremaining: 143ms\n",
      "119:\tlearn: 0.0411607\ttotal: 553ms\tremaining: 138ms\n",
      "120:\tlearn: 0.0400789\ttotal: 558ms\tremaining: 134ms\n",
      "121:\tlearn: 0.0395960\ttotal: 564ms\tremaining: 129ms\n",
      "122:\tlearn: 0.0393798\ttotal: 569ms\tremaining: 125ms\n",
      "123:\tlearn: 0.0387393\ttotal: 573ms\tremaining: 120ms\n",
      "124:\tlearn: 0.0386915\ttotal: 578ms\tremaining: 116ms\n",
      "125:\tlearn: 0.0377122\ttotal: 583ms\tremaining: 111ms\n",
      "126:\tlearn: 0.0375621\ttotal: 588ms\tremaining: 107ms\n",
      "127:\tlearn: 0.0375093\ttotal: 594ms\tremaining: 102ms\n",
      "128:\tlearn: 0.0367727\ttotal: 600ms\tremaining: 97.7ms\n",
      "129:\tlearn: 0.0363634\ttotal: 607ms\tremaining: 93.4ms\n",
      "130:\tlearn: 0.0354546\ttotal: 614ms\tremaining: 89.1ms\n",
      "131:\tlearn: 0.0352696\ttotal: 619ms\tremaining: 84.4ms\n",
      "132:\tlearn: 0.0348774\ttotal: 623ms\tremaining: 79.7ms\n",
      "133:\tlearn: 0.0339577\ttotal: 629ms\tremaining: 75.1ms\n",
      "134:\tlearn: 0.0336982\ttotal: 634ms\tremaining: 70.4ms\n",
      "135:\tlearn: 0.0336166\ttotal: 638ms\tremaining: 65.7ms\n",
      "136:\tlearn: 0.0326238\ttotal: 642ms\tremaining: 61ms\n",
      "137:\tlearn: 0.0325884\ttotal: 647ms\tremaining: 56.2ms\n",
      "138:\tlearn: 0.0316336\ttotal: 651ms\tremaining: 51.5ms\n",
      "139:\tlearn: 0.0315950\ttotal: 656ms\tremaining: 46.8ms\n",
      "140:\tlearn: 0.0315019\ttotal: 660ms\tremaining: 42.1ms\n",
      "141:\tlearn: 0.0310606\ttotal: 664ms\tremaining: 37.4ms\n",
      "142:\tlearn: 0.0303808\ttotal: 670ms\tremaining: 32.8ms\n",
      "143:\tlearn: 0.0302903\ttotal: 675ms\tremaining: 28.1ms\n",
      "144:\tlearn: 0.0301689\ttotal: 680ms\tremaining: 23.4ms\n",
      "145:\tlearn: 0.0297917\ttotal: 685ms\tremaining: 18.8ms\n",
      "146:\tlearn: 0.0296840\ttotal: 689ms\tremaining: 14.1ms\n",
      "147:\tlearn: 0.0295180\ttotal: 694ms\tremaining: 9.38ms\n",
      "148:\tlearn: 0.0289240\ttotal: 700ms\tremaining: 4.7ms\n",
      "149:\tlearn: 0.0288676\ttotal: 704ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-06-18 20:26:01,599] A new study created in memory with name: no-name-4efef4fb-c8eb-48a8-8fa5-23583a97bdb1\n",
      "[I 2025-06-18 20:26:01,741] Trial 0 finished with value: -0.9964375000000001 and parameters: {'C': 0.5611516415334505, 'penalty': 'l1'}. Best is trial 0 with value: -0.9964375000000001.\n",
      "[I 2025-06-18 20:26:01,972] Trial 1 finished with value: -0.9957499999999999 and parameters: {'C': 1.5751320499779735, 'penalty': 'l1'}. Best is trial 0 with value: -0.9964375000000001.\n",
      "[I 2025-06-18 20:26:02,044] Trial 2 finished with value: -0.99690625 and parameters: {'C': 0.13066739238053282, 'penalty': 'l1'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:02,280] Trial 3 finished with value: -0.9827187499999999 and parameters: {'C': 2.607024758370768, 'penalty': 'l2'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:02,644] Trial 4 finished with value: -0.995125 and parameters: {'C': 4.622589001020832, 'penalty': 'l1'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:02,782] Trial 5 finished with value: -0.974625 and parameters: {'C': 0.2327067708383781, 'penalty': 'l2'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:02,961] Trial 6 finished with value: -0.9797812499999999 and parameters: {'C': 0.7309539835912913, 'penalty': 'l2'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:03,097] Trial 7 finished with value: -0.97284375 and parameters: {'C': 0.19010245319870356, 'penalty': 'l2'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:03,252] Trial 8 finished with value: -0.9960625000000002 and parameters: {'C': 0.8168455894760165, 'penalty': 'l1'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:03,431] Trial 9 finished with value: -0.9958750000000001 and parameters: {'C': 1.0677482709481354, 'penalty': 'l1'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:03,512] Trial 10 finished with value: -0.9968124999999999 and parameters: {'C': 0.10991587445851024, 'penalty': 'l1'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:03,587] Trial 11 finished with value: -0.99690625 and parameters: {'C': 0.10353677627159782, 'penalty': 'l1'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:03,663] Trial 12 finished with value: -0.99690625 and parameters: {'C': 0.10691887002123487, 'penalty': 'l1'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:03,766] Trial 13 finished with value: -0.9967500000000001 and parameters: {'C': 0.324255176142218, 'penalty': 'l1'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:03,864] Trial 14 finished with value: -0.9967812500000001 and parameters: {'C': 0.31385189050357676, 'penalty': 'l1'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:04,272] Trial 15 finished with value: -0.9942499999999999 and parameters: {'C': 8.611382274356343, 'penalty': 'l1'}. Best is trial 2 with value: -0.99690625.\n",
      "[I 2025-06-18 20:26:04,350] Trial 16 finished with value: -0.9970000000000001 and parameters: {'C': 0.1588471280716395, 'penalty': 'l1'}. Best is trial 16 with value: -0.9970000000000001.\n",
      "[I 2025-06-18 20:26:04,434] Trial 17 finished with value: -0.9970625 and parameters: {'C': 0.18273464454980845, 'penalty': 'l1'}. Best is trial 17 with value: -0.9970625.\n",
      "[I 2025-06-18 20:26:04,598] Trial 18 finished with value: -0.9778437500000001 and parameters: {'C': 0.43239045729560244, 'penalty': 'l2'}. Best is trial 17 with value: -0.9970625.\n",
      "[I 2025-06-18 20:26:04,688] Trial 19 finished with value: -0.9970625 and parameters: {'C': 0.19352083428946948, 'penalty': 'l1'}. Best is trial 17 with value: -0.9970625.\n",
      "[I 2025-06-18 20:26:04,708] A new study created in memory with name: no-name-6fb273ca-b5a7-45a5-b863-e0a330775725\n",
      "[I 2025-06-18 20:26:06,926] Trial 0 finished with value: -0.8422812499999999 and parameters: {'n_estimators': 106, 'max_depth': 5, 'min_samples_split': 3}. Best is trial 0 with value: -0.8422812499999999.\n",
      "[I 2025-06-18 20:26:08,116] Trial 1 finished with value: -0.8523125 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 1 with value: -0.8523125.\n",
      "[I 2025-06-18 20:26:12,637] Trial 2 finished with value: -0.8661249999999999 and parameters: {'n_estimators': 175, 'max_depth': None, 'min_samples_split': 5}. Best is trial 2 with value: -0.8661249999999999.\n",
      "[I 2025-06-18 20:26:15,712] Trial 3 finished with value: -0.8676562499999999 and parameters: {'n_estimators': 115, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 3 with value: -0.8676562499999999.\n",
      "[I 2025-06-18 20:26:17,775] Trial 4 finished with value: -0.84175 and parameters: {'n_estimators': 118, 'max_depth': 5, 'min_samples_split': 2}. Best is trial 3 with value: -0.8676562499999999.\n",
      "[I 2025-06-18 20:26:20,859] Trial 5 finished with value: -0.874875 and parameters: {'n_estimators': 141, 'max_depth': None, 'min_samples_split': 7}. Best is trial 5 with value: -0.874875.\n",
      "[I 2025-06-18 20:26:22,928] Trial 6 finished with value: -0.8677187499999999 and parameters: {'n_estimators': 95, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 5 with value: -0.874875.\n",
      "[I 2025-06-18 20:26:23,813] Trial 7 finished with value: -0.853875 and parameters: {'n_estimators': 55, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 5 with value: -0.874875.\n",
      "[I 2025-06-18 20:26:26,644] Trial 8 finished with value: -0.86725 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 5 with value: -0.874875.\n",
      "[I 2025-06-18 20:26:28,849] Trial 9 finished with value: -0.8503437500000001 and parameters: {'n_estimators': 140, 'max_depth': 5, 'min_samples_split': 4}. Best is trial 5 with value: -0.874875.\n",
      "[I 2025-06-18 20:26:33,094] Trial 10 finished with value: -0.8731875 and parameters: {'n_estimators': 194, 'max_depth': None, 'min_samples_split': 7}. Best is trial 5 with value: -0.874875.\n",
      "[I 2025-06-18 20:26:37,879] Trial 11 finished with value: -0.87240625 and parameters: {'n_estimators': 190, 'max_depth': None, 'min_samples_split': 7}. Best is trial 5 with value: -0.874875.\n",
      "[I 2025-06-18 20:26:41,663] Trial 12 finished with value: -0.8717812500000001 and parameters: {'n_estimators': 159, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 5 with value: -0.874875.\n",
      "[I 2025-06-18 20:26:45,927] Trial 13 finished with value: -0.875 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 7}. Best is trial 13 with value: -0.875.\n",
      "[I 2025-06-18 20:26:49,060] Trial 14 finished with value: -0.8756875 and parameters: {'n_estimators': 156, 'max_depth': None, 'min_samples_split': 6}. Best is trial 14 with value: -0.8756875.\n",
      "[I 2025-06-18 20:26:52,591] Trial 15 finished with value: -0.875 and parameters: {'n_estimators': 167, 'max_depth': None, 'min_samples_split': 6}. Best is trial 14 with value: -0.8756875.\n",
      "[I 2025-06-18 20:26:55,811] Trial 16 finished with value: -0.8759062500000001 and parameters: {'n_estimators': 156, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 16 with value: -0.8759062500000001.\n",
      "[I 2025-06-18 20:26:58,844] Trial 17 finished with value: -0.8759375 and parameters: {'n_estimators': 154, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 17 with value: -0.8759375.\n",
      "[I 2025-06-18 20:27:00,705] Trial 18 finished with value: -0.87246875 and parameters: {'n_estimators': 89, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 17 with value: -0.8759375.\n",
      "[I 2025-06-18 20:27:03,847] Trial 19 finished with value: -0.86890625 and parameters: {'n_estimators': 148, 'max_depth': 15, 'min_samples_split': 4}. Best is trial 17 with value: -0.8759375.\n",
      "[I 2025-06-18 20:27:04,685] A new study created in memory with name: no-name-0e449df4-68f9-4cbf-b5c8-3a8eb5b042d7\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:06,500] Trial 0 finished with value: -0.9921875 and parameters: {'n_estimators': 106, 'learning_rate': 0.13125830316209655, 'max_depth': 7, 'subsample': 0.8795975452591109}. Best is trial 0 with value: -0.9921875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:07,333] Trial 1 finished with value: -0.9726250000000001 and parameters: {'n_estimators': 73, 'learning_rate': 0.015256811898068502, 'max_depth': 3, 'subsample': 0.9598528437324805}. Best is trial 0 with value: -0.9921875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:08,603] Trial 2 finished with value: -0.9914062500000002 and parameters: {'n_estimators': 140, 'learning_rate': 0.06803900745073706, 'max_depth': 3, 'subsample': 0.9909729556485982}. Best is trial 0 with value: -0.9921875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:10,221] Trial 3 finished with value: -0.99046875 and parameters: {'n_estimators': 175, 'learning_rate': 0.01777174904859463, 'max_depth': 4, 'subsample': 0.7550213529560301}. Best is trial 0 with value: -0.9921875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:11,408] Trial 4 finished with value: -0.992 and parameters: {'n_estimators': 95, 'learning_rate': 0.04141536110538596, 'max_depth': 5, 'subsample': 0.7873687420594125}. Best is trial 0 with value: -0.9921875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:12,827] Trial 5 finished with value: -0.9885625000000001 and parameters: {'n_estimators': 142, 'learning_rate': 0.01459007452373112, 'max_depth': 4, 'subsample': 0.8099085529881075}. Best is trial 0 with value: -0.9921875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:13,905] Trial 6 finished with value: -0.991625 and parameters: {'n_estimators': 118, 'learning_rate': 0.0838375512850209, 'max_depth': 4, 'subsample': 0.8542703315240835}. Best is trial 0 with value: -0.9921875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:15,924] Trial 7 finished with value: -0.9887499999999999 and parameters: {'n_estimators': 139, 'learning_rate': 0.011340440501807348, 'max_depth': 6, 'subsample': 0.7511572371061874}. Best is trial 0 with value: -0.9921875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:16,813] Trial 8 finished with value: -0.992375 and parameters: {'n_estimators': 59, 'learning_rate': 0.13060986669773664, 'max_depth': 8, 'subsample': 0.9425192044349383}. Best is trial 8 with value: -0.992375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:18,392] Trial 9 finished with value: -0.98671875 and parameters: {'n_estimators': 95, 'learning_rate': 0.01302780710309028, 'max_depth': 7, 'subsample': 0.8320457481218804}. Best is trial 8 with value: -0.992375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:19,350] Trial 10 finished with value: -0.987015625 and parameters: {'n_estimators': 53, 'learning_rate': 0.036030984219246213, 'max_depth': 8, 'subsample': 0.9128919539143554}. Best is trial 8 with value: -0.992375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:20,203] Trial 11 finished with value: -0.991625 and parameters: {'n_estimators': 54, 'learning_rate': 0.11681446704286463, 'max_depth': 8, 'subsample': 0.9033772971497525}. Best is trial 8 with value: -0.992375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:21,229] Trial 12 finished with value: -0.9913125 and parameters: {'n_estimators': 93, 'learning_rate': 0.14830152777682598, 'max_depth': 7, 'subsample': 0.8968844335983657}. Best is trial 8 with value: -0.992375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:23,191] Trial 13 finished with value: -0.9919062500000001 and parameters: {'n_estimators': 170, 'learning_rate': 0.07363789110295953, 'max_depth': 7, 'subsample': 0.9392893405541536}. Best is trial 8 with value: -0.992375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:24,439] Trial 14 finished with value: -0.9918437499999999 and parameters: {'n_estimators': 114, 'learning_rate': 0.1492427639193562, 'max_depth': 8, 'subsample': 0.8656078720226558}. Best is trial 8 with value: -0.992375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:25,586] Trial 15 finished with value: -0.9910625 and parameters: {'n_estimators': 74, 'learning_rate': 0.04745529899041336, 'max_depth': 6, 'subsample': 0.9765685201196648}. Best is trial 8 with value: -0.992375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:26,752] Trial 16 finished with value: -0.98753125 and parameters: {'n_estimators': 67, 'learning_rate': 0.024936487899726186, 'max_depth': 7, 'subsample': 0.8796662231078229}. Best is trial 8 with value: -0.992375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:28,525] Trial 17 finished with value: -0.99159375 and parameters: {'n_estimators': 196, 'learning_rate': 0.09083155231968416, 'max_depth': 6, 'subsample': 0.9378635101508794}. Best is trial 8 with value: -0.992375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:30,044] Trial 18 finished with value: -0.9919062499999999 and parameters: {'n_estimators': 104, 'learning_rate': 0.055420433407029006, 'max_depth': 8, 'subsample': 0.9423245136752461}. Best is trial 8 with value: -0.992375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:27:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:27:31,150] Trial 19 finished with value: -0.9924062499999999 and parameters: {'n_estimators': 81, 'learning_rate': 0.1031933293032663, 'max_depth': 7, 'subsample': 0.9988050968083642}. Best is trial 19 with value: -0.9924062499999999.\n",
      "[I 2025-06-18 20:27:31,437] A new study created in memory with name: no-name-6cdd709c-124d-4546-a068-0acf3ca314a0\n",
      "[I 2025-06-18 20:27:36,639] Trial 0 finished with value: -0.985125 and parameters: {'iterations': 106, 'learning_rate': 0.13125830316209655, 'depth': 7, 'l2_leaf_reg': 0.6251373574521749}. Best is trial 0 with value: -0.985125.\n",
      "[I 2025-06-18 20:27:38,163] Trial 1 finished with value: -0.9586875000000001 and parameters: {'iterations': 73, 'learning_rate': 0.015256811898068502, 'depth': 3, 'l2_leaf_reg': 3.9676050770529883}. Best is trial 0 with value: -0.985125.\n",
      "[I 2025-06-18 20:27:40,591] Trial 2 finished with value: -0.9862500000000001 and parameters: {'iterations': 140, 'learning_rate': 0.06803900745073706, 'depth': 3, 'l2_leaf_reg': 8.123245085588687}. Best is trial 2 with value: -0.9862500000000001.\n",
      "[I 2025-06-18 20:27:43,987] Trial 3 finished with value: -0.98003125 and parameters: {'iterations': 175, 'learning_rate': 0.01777174904859463, 'depth': 4, 'l2_leaf_reg': 0.03549878832196503}. Best is trial 2 with value: -0.9862500000000001.\n",
      "[I 2025-06-18 20:27:46,715] Trial 4 finished with value: -0.9782187500000001 and parameters: {'iterations': 95, 'learning_rate': 0.04141536110538596, 'depth': 5, 'l2_leaf_reg': 0.07476312062252301}. Best is trial 2 with value: -0.9862500000000001.\n",
      "[I 2025-06-18 20:27:49,813] Trial 5 finished with value: -0.977625 and parameters: {'iterations': 142, 'learning_rate': 0.01459007452373112, 'depth': 4, 'l2_leaf_reg': 0.1256277350380703}. Best is trial 2 with value: -0.9862500000000001.\n",
      "[I 2025-06-18 20:27:52,640] Trial 6 finished with value: -0.98821875 and parameters: {'iterations': 118, 'learning_rate': 0.0838375512850209, 'depth': 4, 'l2_leaf_reg': 0.34890188454913873}. Best is trial 6 with value: -0.98821875.\n",
      "[I 2025-06-18 20:27:58,040] Trial 7 finished with value: -0.9772812500000001 and parameters: {'iterations': 139, 'learning_rate': 0.011340440501807348, 'depth': 6, 'l2_leaf_reg': 0.03247673570627449}. Best is trial 6 with value: -0.98821875.\n",
      "[I 2025-06-18 20:28:03,600] Trial 8 finished with value: -0.9785625 and parameters: {'iterations': 59, 'learning_rate': 0.13060986669773664, 'depth': 8, 'l2_leaf_reg': 2.6619018884890564}. Best is trial 6 with value: -0.98821875.\n",
      "[I 2025-06-18 20:28:08,695] Trial 9 finished with value: -0.9725312500000001 and parameters: {'iterations': 95, 'learning_rate': 0.01302780710309028, 'depth': 7, 'l2_leaf_reg': 0.2091498132903561}. Best is trial 6 with value: -0.98821875.\n",
      "[I 2025-06-18 20:28:13,127] Trial 10 finished with value: -0.9881562500000001 and parameters: {'iterations': 192, 'learning_rate': 0.06768269073143275, 'depth': 5, 'l2_leaf_reg': 0.8306050731972228}. Best is trial 6 with value: -0.98821875.\n",
      "[I 2025-06-18 20:28:17,545] Trial 11 finished with value: -0.9890000000000001 and parameters: {'iterations': 191, 'learning_rate': 0.06883422377244944, 'depth': 5, 'l2_leaf_reg': 0.7451617972708874}. Best is trial 11 with value: -0.9890000000000001.\n",
      "[I 2025-06-18 20:28:21,197] Trial 12 finished with value: -0.9886249999999999 and parameters: {'iterations': 168, 'learning_rate': 0.07386391228000026, 'depth': 4, 'l2_leaf_reg': 0.711808908422532}. Best is trial 11 with value: -0.9890000000000001.\n",
      "[I 2025-06-18 20:28:27,526] Trial 13 finished with value: -0.9811875000000001 and parameters: {'iterations': 170, 'learning_rate': 0.03651879338919804, 'depth': 6, 'l2_leaf_reg': 1.0960613851484895}. Best is trial 11 with value: -0.9890000000000001.\n",
      "[I 2025-06-18 20:28:32,127] Trial 14 finished with value: -0.9857187499999999 and parameters: {'iterations': 199, 'learning_rate': 0.0380706515618729, 'depth': 5, 'l2_leaf_reg': 1.7606431522691666}. Best is trial 11 with value: -0.9890000000000001.\n",
      "[I 2025-06-18 20:28:34,921] Trial 15 finished with value: -0.9885624999999999 and parameters: {'iterations': 168, 'learning_rate': 0.08692107583205226, 'depth': 4, 'l2_leaf_reg': 0.3076974779163993}. Best is trial 11 with value: -0.9890000000000001.\n",
      "[I 2025-06-18 20:28:37,511] Trial 16 finished with value: -0.9844375 and parameters: {'iterations': 157, 'learning_rate': 0.05295417213469978, 'depth': 3, 'l2_leaf_reg': 9.728583151931058}. Best is trial 11 with value: -0.9890000000000001.\n",
      "[I 2025-06-18 20:28:42,318] Trial 17 finished with value: -0.9764062499999999 and parameters: {'iterations': 188, 'learning_rate': 0.02202425447845193, 'depth': 6, 'l2_leaf_reg': 0.01585083492156818}. Best is trial 11 with value: -0.9890000000000001.\n",
      "[I 2025-06-18 20:28:46,171] Trial 18 finished with value: -0.98125 and parameters: {'iterations': 152, 'learning_rate': 0.02737149737770575, 'depth': 5, 'l2_leaf_reg': 0.49263375848025487}. Best is trial 11 with value: -0.9890000000000001.\n",
      "[I 2025-06-18 20:28:48,776] Trial 19 finished with value: -0.9894375 and parameters: {'iterations': 181, 'learning_rate': 0.09620446377106859, 'depth': 4, 'l2_leaf_reg': 1.5846390335620455}. Best is trial 19 with value: -0.9894375.\n",
      "[I 2025-06-18 20:28:49,422] A new study created in memory with name: no-name-0468ca2a-8c2b-4f7f-91e7-9e091b7ad8f3\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:05,941] Trial 0 finished with value: -0.9334687500000001 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 2.9380279387035334e-05, 'learning_rate_init': 0.00020511104188433984}. Best is trial 0 with value: -0.9334687500000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:07,204] Trial 1 finished with value: -0.93925 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.1527987128232396e-05, 'learning_rate_init': 0.008706020878304856}. Best is trial 1 with value: -0.93925.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:12,602] Trial 2 finished with value: -0.94890625 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 8.17949947521167e-05, 'learning_rate_init': 0.0011207606211860567}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:16,910] Trial 3 finished with value: -0.9305 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 7.52374288453485e-05, 'learning_rate_init': 0.0005404103854647331}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:31,615] Trial 4 finished with value: -0.9291562500000001 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0005987474910461401, 'learning_rate_init': 0.0001238513729886094}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:32,533] Trial 5 finished with value: -0.9400000000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00788671412999049, 'learning_rate_init': 0.004138040112561018}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:35,103] Trial 6 finished with value: -0.94103125 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 2.32335035153901e-05, 'learning_rate_init': 0.0009780337016659412}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:38,965] Trial 7 finished with value: -0.9455625000000001 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 8.612579192594876e-05, 'learning_rate_init': 0.001096821720752952}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:39,944] Trial 8 finished with value: -0.93534375 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.006584106160121612, 'learning_rate_init': 0.006161049539380964}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:48,074] Trial 9 finished with value: -0.9381562500000001 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.3667272915456215e-05, 'learning_rate_init': 0.0004473636174621269}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:50,459] Trial 10 finished with value: -0.94809375 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0007619408233517919, 'learning_rate_init': 0.0024673775376624486}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:52,697] Trial 11 finished with value: -0.94665625 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0006733230478395729, 'learning_rate_init': 0.0024015639024822476}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:55,407] Trial 12 finished with value: -0.9477499999999999 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0017870856762200685, 'learning_rate_init': 0.0023840599245347404}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:29:58,343] Trial 13 finished with value: -0.944 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.00016286997838076145, 'learning_rate_init': 0.0017175482489007405}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:30:04,675] Trial 14 finished with value: -0.94121875 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.00029617690445854955, 'learning_rate_init': 0.0005988751231170377}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:30:05,843] Trial 15 finished with value: -0.9448437500000001 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0017760804701515485, 'learning_rate_init': 0.004050150573974884}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:30:08,425] Trial 16 finished with value: -0.94165625 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 7.586814414469523e-05, 'learning_rate_init': 0.0012385214939024582}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:30:15,879] Trial 17 finished with value: -0.9380625 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.002065344154282732, 'learning_rate_init': 0.00035397284510561627}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:30:17,522] Trial 18 finished with value: -0.9488125000000001 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0006074934745323871, 'learning_rate_init': 0.003498317056382218}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:30:18,858] Trial 19 finished with value: -0.94725 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.00019062321394368613, 'learning_rate_init': 0.003748538946407633}. Best is trial 2 with value: -0.94890625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- Основной цикл оценки с тремя методами оптимизации ---\n",
    "all_classification_results = []\n",
    "optimizers = ['RandomizedSearchCV', 'GridSearchCV', 'Optuna']\n",
    "\n",
    "# Извлекаем признаки, исключая все целевые переменные (теперь просто TARGETS_ACTUAL_LOGGED)\n",
    "# и новые бинарные целевые переменные.\n",
    "columns_to_drop_common = TARGETS_ACTUAL_LOGGED + list(classification_targets.keys())\n",
    "\n",
    "# Добавляем специфические для датасетов столбцы, которые не являются признаками (например, SMILES)\n",
    "if 'SMILES' in df_pca.columns:\n",
    "    columns_to_drop_pca_final = columns_to_drop_common + ['SMILES']\n",
    "else:\n",
    "    columns_to_drop_pca_final = columns_to_drop_common\n",
    "\n",
    "if 'SMILES' in df_manual.columns:\n",
    "    columns_to_drop_manual_final = columns_to_drop_common + ['SMILES']\n",
    "else:\n",
    "    columns_to_drop_manual_final = columns_to_drop_common\n",
    "\n",
    "X_pca_features = df_pca.drop(columns=columns_to_drop_pca_final, errors='ignore')\n",
    "X_manual_features = df_manual.drop(columns=columns_to_drop_manual_final, errors='ignore')\n",
    "\n",
    "\n",
    "print(\"Начинаем процесс обучения и оценки моделей классификации...\")\n",
    "\n",
    "for target_name_classification in tqdm(classification_targets.keys(), desc=\"Прогнозирование задач классификации\"):\n",
    "    for data_source_name, X_data_features, df_data in [(\"PCA Aggregated\", X_pca_features, df_pca), (\"Manual Aggregated\", X_manual_features, df_manual)]:\n",
    "        y_data_classification = df_data[target_name_classification]\n",
    "\n",
    "        num_models_to_run = 0\n",
    "        for model_name, config in models_config_classifier.items():\n",
    "            for optimizer_type in optimizers:\n",
    "                # Уточненная логика для подсчета моделей\n",
    "                if (optimizer_type == 'RandomizedSearchCV' and not config.get('random_dist', {})) and model_name != \"LogisticRegression\":\n",
    "                    continue\n",
    "                if (optimizer_type == 'GridSearchCV' and not config.get('grid_params', {})) and model_name != \"LogisticRegression\":\n",
    "                    continue\n",
    "                if (optimizer_type == 'Optuna' and config.get('optuna_space') is None) and model_name != \"LogisticRegression\":\n",
    "                    continue\n",
    "                num_models_to_run += 1\n",
    "\n",
    "        with tqdm(total=num_models_to_run, desc=f\"Оптимизация для {target_name_classification} ({data_source_name})\", leave=False) as pbar_inner:\n",
    "            for optimizer_type in optimizers:\n",
    "                for model_name, config in models_config_classifier.items():\n",
    "                    # Пропускаем неподходящие комбинации модель-оптимизатор, чтобы избежать ошибок и не тратить время\n",
    "                    if (optimizer_type == 'RandomizedSearchCV' and not config.get('random_dist', {})) and model_name != \"LogisticRegression\":\n",
    "                        pbar_inner.update(1)\n",
    "                        continue\n",
    "                    if (optimizer_type == 'GridSearchCV' and not config.get('grid_params', {})) and model_name != \"LogisticRegression\":\n",
    "                        pbar_inner.update(1)\n",
    "                        continue\n",
    "                    if (optimizer_type == 'Optuna' and config.get('optuna_space') is None) and model_name != \"LogisticRegression\":\n",
    "                        pbar_inner.update(1)\n",
    "                        continue\n",
    "\n",
    "                    model_class = config[\"class\"]\n",
    "                    params_config = config\n",
    "\n",
    "                    pbar_inner.set_description(f\"Оптимизация для {target_name_classification} ({data_source_name}) - {model_name} ({optimizer_type})\")\n",
    "\n",
    "                    result = evaluate_model_with_optimizer_classifier(model_name, model_class, params_config,\n",
    "                                                                      X_data_features, y_data_classification, target_name_classification, optimizer_type)\n",
    "                    if result:\n",
    "                        result['data_source'] = data_source_name\n",
    "                        all_classification_results.append(result)\n",
    "                    pbar_inner.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c4fab20-7400-4d47-86f9-ccb611faebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты классификации сохранены в: classification_results_all_optimizers_50_iter.csv\n",
      "\n",
      "--- Сводка результатов классификации по методам оптимизации ---\n",
      "\n",
      "## Результаты RandomizedSearchCV (Классификация):\n",
      "                     model           optimizer              target                                                                                                                               best_params  accuracy  precision  recall  f1_score   roc_auc        data_source\n",
      "17      CatBoostClassifier  RandomizedSearchCV  is_SI_above_median                                    {'depth': 4, 'iterations': 181, 'l2_leaf_reg': 7.59541228979397, 'learning_rate': 0.09449323267683088}  0.970149   0.979592    0.96  0.969697  0.997129  Manual Aggregated\n",
      "16           XGBClassifier  RandomizedSearchCV  is_SI_above_median  {'learning_rate': 0.04463407384332235, 'max_depth': 6, 'n_estimators': 160, 'subsample': 0.9049790556476374, 'use_label_encoder': False}  0.970149   1.000000    0.94  0.969072  0.996931  Manual Aggregated\n",
      "2            XGBClassifier  RandomizedSearchCV  is_SI_above_median  {'learning_rate': 0.04463407384332235, 'max_depth': 6, 'n_estimators': 160, 'subsample': 0.9049790556476374, 'use_label_encoder': False}  0.975124   1.000000    0.95  0.974359  0.996733     PCA Aggregated\n",
      "3       CatBoostClassifier  RandomizedSearchCV  is_SI_above_median                                   {'depth': 4, 'iterations': 183, 'l2_leaf_reg': 2.455591640077322, 'learning_rate': 0.09515504917299872}  0.950249   0.978723    0.92  0.948454  0.995248     PCA Aggregated\n",
      "14      LogisticRegression  RandomizedSearchCV  is_SI_above_median                                                                          {'C': 3.845401188473625, 'penalty': 'l1', 'solver': 'liblinear'}  0.960199   0.960000    0.96  0.960000  0.992871  Manual Aggregated\n",
      "0       LogisticRegression  RandomizedSearchCV  is_SI_above_median                                                                          {'C': 3.845401188473625, 'penalty': 'l1', 'solver': 'liblinear'}  0.955224   0.959596    0.95  0.954774  0.992277     PCA Aggregated\n",
      "4            MLPClassifier  RandomizedSearchCV  is_SI_above_median                                {'alpha': 0.0034126114217699097, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.002225779372456223}  0.855721   0.851485    0.86  0.855721  0.932970     PCA Aggregated\n",
      "18           MLPClassifier  RandomizedSearchCV  is_SI_above_median                               {'alpha': 0.00020292247147901224, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.003709993861334124}  0.865672   0.861386    0.87  0.865672  0.932871  Manual Aggregated\n",
      "1   RandomForestClassifier  RandomizedSearchCV  is_SI_above_median                                                                            {'max_depth': 10, 'min_samples_split': 6, 'n_estimators': 179}  0.800995   0.833333    0.75  0.789474  0.879901     PCA Aggregated\n",
      "15  RandomForestClassifier  RandomizedSearchCV  is_SI_above_median                                                                           {'max_depth': None, 'min_samples_split': 3, 'n_estimators': 64}  0.771144   0.813953    0.70  0.752688  0.861089  Manual Aggregated\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "## Результаты GridSearchCV (Классификация):\n",
      "                     model     optimizer              target                                                                              best_params  accuracy  precision  recall  f1_score   roc_auc        data_source\n",
      "5       LogisticRegression  GridSearchCV  is_SI_above_median                                       {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}  0.965174   1.000000    0.93  0.963731  0.997327     PCA Aggregated\n",
      "19      LogisticRegression  GridSearchCV  is_SI_above_median                                       {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}  0.965174   1.000000    0.93  0.963731  0.997327  Manual Aggregated\n",
      "22      CatBoostClassifier  GridSearchCV  is_SI_above_median                                    {'depth': 5, 'iterations': 150, 'learning_rate': 0.1}  0.950249   0.989130    0.91  0.947917  0.997030  Manual Aggregated\n",
      "7            XGBClassifier  GridSearchCV  is_SI_above_median  {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 150, 'use_label_encoder': False}  0.965174   0.989474    0.94  0.964103  0.996832     PCA Aggregated\n",
      "8       CatBoostClassifier  GridSearchCV  is_SI_above_median                                    {'depth': 5, 'iterations': 150, 'learning_rate': 0.1}  0.960199   0.989362    0.93  0.958763  0.996832     PCA Aggregated\n",
      "21           XGBClassifier  GridSearchCV  is_SI_above_median  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150, 'use_label_encoder': False}  0.970149   0.989583    0.95  0.969388  0.995941  Manual Aggregated\n",
      "9            MLPClassifier  GridSearchCV  is_SI_above_median                                           {'alpha': 0.001, 'hidden_layer_sizes': (100,)}  0.830846   0.836735    0.82  0.828283  0.912475     PCA Aggregated\n",
      "23           MLPClassifier  GridSearchCV  is_SI_above_median                                          {'alpha': 0.0001, 'hidden_layer_sizes': (100,)}  0.810945   0.816327    0.80  0.808081  0.904752  Manual Aggregated\n",
      "20  RandomForestClassifier  GridSearchCV  is_SI_above_median                                                   {'max_depth': 10, 'n_estimators': 150}  0.805970   0.835165    0.76  0.795812  0.877921  Manual Aggregated\n",
      "6   RandomForestClassifier  GridSearchCV  is_SI_above_median                                                   {'max_depth': 10, 'n_estimators': 150}  0.781095   0.818182    0.72  0.765957  0.857624     PCA Aggregated\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "## Результаты Optuna (Классификация):\n",
      "                     model optimizer              target                                                                                                    best_params  accuracy  precision  recall  f1_score   roc_auc        data_source\n",
      "11           XGBClassifier    Optuna  is_SI_above_median  {'n_estimators': 161, 'learning_rate': 0.023328856410404736, 'max_depth': 6, 'subsample': 0.7408415462126681}  0.975124   1.000000    0.95  0.974359  0.997228     PCA Aggregated\n",
      "26      CatBoostClassifier    Optuna  is_SI_above_median       {'iterations': 181, 'learning_rate': 0.09620446377106859, 'depth': 4, 'l2_leaf_reg': 1.5846390335620455}  0.965174   0.979381    0.95  0.964467  0.996337  Manual Aggregated\n",
      "25           XGBClassifier    Optuna  is_SI_above_median     {'n_estimators': 81, 'learning_rate': 0.1031933293032663, 'max_depth': 7, 'subsample': 0.9988050968083642}  0.965174   1.000000    0.93  0.963731  0.995347  Manual Aggregated\n",
      "12      CatBoostClassifier    Optuna  is_SI_above_median         {'iterations': 199, 'learning_rate': 0.06481997376425686, 'depth': 3, 'l2_leaf_reg': 1.82020492563511}  0.960199   0.979167    0.94  0.959184  0.995050     PCA Aggregated\n",
      "13           MLPClassifier    Optuna  is_SI_above_median     {'hidden_layer_sizes': (100,), 'alpha': 0.0024605732643850557, 'learning_rate_init': 0.009737456278942954}  0.855721   0.881720    0.82  0.849741  0.941386     PCA Aggregated\n",
      "27           MLPClassifier    Optuna  is_SI_above_median      {'hidden_layer_sizes': (50,), 'alpha': 8.17949947521167e-05, 'learning_rate_init': 0.0011207606211860567}  0.815920   0.831579    0.79  0.810256  0.903267  Manual Aggregated\n",
      "10  RandomForestClassifier    Optuna  is_SI_above_median                                               {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 6}  0.786070   0.820225    0.73  0.772487  0.866634     PCA Aggregated\n",
      "24  RandomForestClassifier    Optuna  is_SI_above_median                                                 {'n_estimators': 154, 'max_depth': 15, 'min_samples_split': 6}  0.786070   0.835294    0.71  0.767568  0.864752  Manual Aggregated\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Сохранение и вывод результатов ---\n",
    "output_classification_file = Path('classification_results_all_optimizers_50_iter.csv')\n",
    "\n",
    "all_classification_results_df = pd.DataFrame(all_classification_results)\n",
    "all_classification_results_df.to_csv(output_classification_file, index=False)\n",
    "print(f\"\\nРезультаты классификации сохранены в: {output_classification_file}\")\n",
    "\n",
    "print(\"\\n--- Сводка результатов классификации по методам оптимизации ---\")\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    print(f\"\\n## Результаты {optimizer} (Классификация):\")\n",
    "    subset_optimizer = all_classification_results_df[all_classification_results_df['optimizer'] == optimizer]\n",
    "    print(subset_optimizer.sort_values(by=['target', 'roc_auc'], ascending=[True, False]).to_string())\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Визуализация метрик классификации (например, ROC-AUC и F1-score)\n",
    "classification_metrics_to_plot = ['roc_auc', 'f1_score', 'accuracy']\n",
    "\n",
    "for target_class in classification_targets.keys():\n",
    "    for metric in classification_metrics_to_plot:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        subset = all_classification_results_df[all_classification_results_df['target'] == target_class].sort_values(by=metric, ascending=False)\n",
    "        sns.barplot(x='model', y=metric, hue='optimizer', data=subset, palette='viridis')\n",
    "        plt.title(f'Сравнение {metric.upper()} для \"{target_class}\" по методам оптимизации', fontsize=16)\n",
    "        plt.ylabel(metric.upper(), fontsize=12)\n",
    "        plt.xlabel('Модель', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.legend(title='Метод оптимизации', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'classification_{target_class}_{metric}_comparison.png')\n",
    "        plt.close() # Close plot to free memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
