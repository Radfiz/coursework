{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddde29b9-e3eb-4c5c-8dd4-d127058ba0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Data (actual logged targets):\n",
      "   CC50, mM\n",
      "0  5.173221\n",
      "1  1.856738\n",
      "2  5.088474\n",
      "3  4.690023\n",
      "4  4.943576\n",
      "\n",
      "Manual Data (actual logged targets):\n",
      "   CC50, mM\n",
      "0  5.173221\n",
      "1  1.856738\n",
      "2  5.088474\n",
      "3  4.690023\n",
      "4  4.943576\n",
      "\n",
      "Созданные бинарные целевые переменные:\n",
      "PCA - is_CC50_above_median value counts:\n",
      " is_CC50_above_median\n",
      "0    502\n",
      "1    499\n",
      "Name: count, dtype: int64\n",
      "Manual - is_CC50_above_median value counts:\n",
      " is_CC50_above_median\n",
      "0    502\n",
      "1    499\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import uniform, randint\n",
    "import optuna\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Загрузка данных ---\n",
    "file_url_pca = 'https://drive.google.com/uc?export=download&id=1SuUhkpfj-3uJQnxwmUCyDUogfa2TixTe'\n",
    "file_url_manual = 'https://drive.google.com/uc?export=download&id=1p8VYp23oOylSFrfJztQVheNLop-bX40o'\n",
    "\n",
    "df_pca = pd.read_csv(file_url_pca, encoding='utf-8')\n",
    "df_manual = pd.read_csv(file_url_manual, encoding='utf-8')\n",
    "\n",
    "# --- Определяем фактические целевые переменные, которые уже логарифмированы ---\n",
    "# Поскольку вы подтвердили, что 'IC50, mM', 'CC50, mM', 'SI' уже логарифмированы,\n",
    "# мы будем использовать их напрямую как наши \"лог-цели\".\n",
    "TARGETS_ACTUAL_LOGGED = ['CC50, mM']\n",
    "\n",
    "print(\"PCA Data (actual logged targets):\")\n",
    "print(df_pca[TARGETS_ACTUAL_LOGGED].head())\n",
    "print(\"\\nManual Data (actual logged targets):\")\n",
    "print(df_manual[TARGETS_ACTUAL_LOGGED].head())\n",
    "\n",
    "# --- Создание бинарных целевых переменных для классификации ---\n",
    "\n",
    "classification_targets = {}\n",
    "\n",
    "# 2. CC50 > медианы\n",
    "median_cc50_pca = df_pca['CC50, mM'].median()\n",
    "df_pca['is_CC50_above_median'] = (df_pca['CC50, mM'] > median_cc50_pca).astype(int)\n",
    "median_cc50_manual = df_manual['CC50, mM'].median()\n",
    "df_manual['is_CC50_above_median'] = (df_manual['CC50, mM'] > median_cc50_manual).astype(int)\n",
    "classification_targets['is_CC50_above_median'] = 'CC50, mM'\n",
    "\n",
    "\n",
    "print(\"\\nСозданные бинарные целевые переменные:\")\n",
    "print(\"PCA - is_CC50_above_median value counts:\\n\", df_pca['is_CC50_above_median'].value_counts())\n",
    "\n",
    "print(\"Manual - is_CC50_above_median value counts:\\n\", df_manual['is_CC50_above_median'].value_counts())\n",
    "\n",
    "# --- Вспомогательная функция для расчета метрик классификации ---\n",
    "def calculate_classification_metrics(y_true, y_pred, y_pred_proba):\n",
    "    \"\"\"Вычисляет метрики классификации: Accuracy, Precision, Recall, F1, ROC-AUC.\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0) # Добавлено zero_division\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# --- Функции для каждого метода оптимизации (адаптированные для классификации) ---\n",
    "\n",
    "def run_randomized_search_classifier(model_instance, param_distributions, X_train_scaled, y_train, n_iter_search=20):\n",
    "    \"\"\"Выполняет RandomizedSearchCV для подбора гиперпараметров для классификации.\"\"\"\n",
    "    if not param_distributions:\n",
    "        model_instance.fit(X_train_scaled, y_train)\n",
    "        return model_instance, {}\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    random_search = RandomizedSearchCV(model_instance, param_distributions, n_iter=n_iter_search,\n",
    "                                       cv=cv, scoring='roc_auc',\n",
    "                                       n_jobs=-1, verbose=0, random_state=42)\n",
    "    random_search.fit(X_train_scaled, y_train)\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "def run_grid_search_classifier(model_instance, param_grid, X_train_scaled, y_train):\n",
    "    \"\"\"Выполняет GridSearchCV для подбора гиперпараметров для классификации.\"\"\"\n",
    "    if not param_grid:\n",
    "        model_instance.fit(X_train_scaled, y_train)\n",
    "        return model_instance, {}\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(model_instance, param_grid, cv=cv, scoring='roc_auc',\n",
    "                               n_jobs=-1, verbose=0)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def run_optuna_search_classifier(model_class, optuna_search_space, X_train_scaled, y_train, n_trials=20):\n",
    "    \"\"\"Выполняет оптимизацию гиперпараметров с помощью Optuna для классификации.\"\"\"\n",
    "    def objective(trial):\n",
    "        params = optuna_search_space(trial)\n",
    "\n",
    "        # Обработка random_state/random_seed для Optuna\n",
    "        # Random_state может быть не поддерживаем для всех моделей или определенных solvers\n",
    "        # Здесь мы исходим из того, что Optuna space уже определяет правильный параметр ('random_state' или 'random_seed')\n",
    "        if model_class in [LogisticRegression, MLPClassifier] and 'random_state' in params:\n",
    "            model = model_class(**{k: v for k, v in params.items() if k != 'random_state'})\n",
    "        else:\n",
    "            model = model_class(**params)\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = []\n",
    "        for train_idx, val_idx in kf.split(X_train_scaled, y_train):\n",
    "            X_train_fold, X_val_fold = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            try:\n",
    "                if isinstance(model, CatBoostClassifier):\n",
    "                    train_pool = Pool(X_train_fold, y_train_fold)\n",
    "                    val_pool = Pool(X_val_fold, y_val_fold)\n",
    "                    model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=10, verbose=False)\n",
    "                    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "                else:\n",
    "                    model.fit(X_train_fold, y_train_fold)\n",
    "                    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "                roc_auc_fold = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
    "                cv_scores.append(roc_auc_fold)\n",
    "            except Exception as e:\n",
    "                # print(f\"Ошибка при обучении/предсказании в Optuna (фолд): {e}\") # Для дебага\n",
    "                return -float('inf')\n",
    "\n",
    "        return -np.mean(cv_scores)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False, catch=(ValueError, Exception))\n",
    "\n",
    "    best_params = study.best_params\n",
    "    \n",
    "    # Final model instance with best parameters\n",
    "    if model_class in [LogisticRegression, MLPClassifier] and 'random_state' in best_params:\n",
    "        best_model_instance = model_class(**{k: v for k, v in best_params.items() if k != 'random_state'})\n",
    "    else:\n",
    "        best_model_instance = model_class(**best_params)\n",
    "\n",
    "    try:\n",
    "        if isinstance(best_model_instance, CatBoostClassifier):\n",
    "            train_pool_final = Pool(X_train_scaled, y_train)\n",
    "            best_model_instance.fit(train_pool_final, verbose=False)\n",
    "        else:\n",
    "            best_model_instance.fit(X_train_scaled, y_train)\n",
    "    except Exception as e:\n",
    "        # print(f\"Ошибка при окончательном обучении CatBoost: {e}\") # Для дебага\n",
    "        return None, {}\n",
    "\n",
    "    return best_model_instance, best_params\n",
    "\n",
    "# --- Общая функция для оценки моделей с различными оптимизаторами (адаптированная) ---\n",
    "def evaluate_model_with_optimizer_classifier(model_name, model_class, params_config, X, y, target_name, optimizer_type):\n",
    "    \"\"\"Оценивает производительность модели классификации, используя указанный метод оптимизации.\"\"\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    best_model = None\n",
    "    best_params = {}\n",
    "\n",
    "    # Инициализация параметров для воспроизводимости:\n",
    "    model_init_params = {}\n",
    "    if model_name == \"CatBoostClassifier\":\n",
    "        model_init_params['random_seed'] = 42\n",
    "    elif model_name in [\"LogisticRegression\", \"RandomForestClassifier\", \"XGBClassifier\", \"MLPClassifier\"]:\n",
    "        # Эти модели обычно принимают random_state для воспроизводимости\n",
    "        model_init_params['random_state'] = 42\n",
    "\n",
    "    if optimizer_type == 'RandomizedSearchCV':\n",
    "        param_distributions = params_config.get('random_dist', {})\n",
    "        # Для LogisticRegression, если нет dist, используем дефолтный инстанс\n",
    "        if model_name == \"LogisticRegression\" and not param_distributions:\n",
    "             model_instance = model_class(**model_init_params)\n",
    "             model_instance.fit(X_train_scaled, y_train)\n",
    "             best_model, best_params = model_instance, {}\n",
    "        else:\n",
    "            best_model, best_params = run_randomized_search_classifier(model_class(**model_init_params), param_distributions, X_train_scaled, y_train, n_iter_search=20)\n",
    "\n",
    "    elif optimizer_type == 'GridSearchCV':\n",
    "        param_grid = params_config.get('grid_params', {})\n",
    "        if not param_grid:\n",
    "            model_instance = model_class(**model_init_params)\n",
    "            model_instance.fit(X_train_scaled, y_train)\n",
    "            best_model, best_params = model_instance, {}\n",
    "        else:\n",
    "            best_model, best_params = run_grid_search_classifier(model_class(**model_init_params), param_grid, X_train_scaled, y_train)\n",
    "\n",
    "    elif optimizer_type == 'Optuna':\n",
    "        optuna_space = params_config.get('optuna_space')\n",
    "        if optuna_space is None:\n",
    "            model_instance = model_class(**model_init_params)\n",
    "            model_instance.fit(X_train_scaled, y_train)\n",
    "            best_model, best_params = model_instance, {}\n",
    "        else:\n",
    "            # Optuna уже обрабатывает random_state/random_seed в своей objective функции\n",
    "            best_model, best_params = run_optuna_search_classifier(model_class, optuna_space, X_train_scaled, y_train, n_trials=20)\n",
    "    else:\n",
    "        raise ValueError(f\"Неизвестный тип оптимизатора: {optimizer_type}\")\n",
    "\n",
    "    if best_model is None:\n",
    "        return None\n",
    "\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    # predict_proba может отсутствовать для некоторых моделей (например, SVM с probability=False)\n",
    "    # или если модель не была обучена с этой функциональностью.\n",
    "    # Проверяем наличие predict_proba\n",
    "    if hasattr(best_model, \"predict_proba\") and len(best_model.predict_proba(X_test_scaled).shape) > 1:\n",
    "        y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        # Для моделей без predict_proba, ROC-AUC не может быть рассчитан.\n",
    "        # В таком случае, можно либо пропустить ROC-AUC, либо вернуть NaN.\n",
    "        # Для SVM, если probability=True не установлен при инициализации, его не будет.\n",
    "        # Для LogisticRegression и Tree-based моделей predict_proba всегда есть.\n",
    "        print(f\"Warning: Model {model_name} does not have predict_proba or it's not applicable. ROC-AUC will be NaN.\")\n",
    "        y_pred_proba = np.full_like(y_pred, np.nan, dtype=float) # Заполняем NaN для ROC-AUC\n",
    "\n",
    "    accuracy, precision, recall, f1, roc_auc = calculate_classification_metrics(y_test, y_pred, y_pred_proba)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'optimizer': optimizer_type,\n",
    "        'target': target_name,\n",
    "        'best_params': best_params,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "\n",
    "# --- Определение моделей и их гиперпараметров для разных оптимизаторов (адаптированные для классификации) ---\n",
    "models_config_classifier = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"class\": LogisticRegression,\n",
    "        \"random_dist\": {\n",
    "            'C': uniform(loc=0.1, scale=10),\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear']\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear']\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'C': trial.suggest_float('C', 0.1, 10.0, log=True),\n",
    "            'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
    "            'solver': 'liblinear',\n",
    "            'random_state': 42 # Добавлен random_state здесь, чтобы управлять им\n",
    "        }\n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"class\": RandomForestClassifier,\n",
    "        \"random_dist\": {\n",
    "            'n_estimators': randint(50, 200),\n",
    "            'max_depth': [5, 10, None],\n",
    "            'min_samples_split': randint(2, 8)\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'n_estimators': [100, 150],\n",
    "            'max_depth': [5, 10],\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [5, 10, 15, None]),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 8),\n",
    "            'random_state': 42\n",
    "        }\n",
    "    },\n",
    "    \"XGBClassifier\": {\n",
    "        \"class\": XGBClassifier,\n",
    "        \"random_dist\": {\n",
    "            'n_estimators': randint(50, 200),\n",
    "            'learning_rate': uniform(0.01, 0.15),\n",
    "            'max_depth': randint(3, 8),\n",
    "            'subsample': uniform(0.7, 0.3),\n",
    "            'use_label_encoder': [False]\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'n_estimators': [100, 150],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'max_depth': [3, 5],\n",
    "            'use_label_encoder': [False]\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'eval_metric': 'logloss',\n",
    "            'n_jobs': -1,\n",
    "            'random_state': 42,\n",
    "            'use_label_encoder': False\n",
    "        }\n",
    "    },\n",
    "    \"CatBoostClassifier\": {\n",
    "        \"class\": CatBoostClassifier,\n",
    "        \"random_dist\": {\n",
    "            'iterations': randint(50, 200),\n",
    "            'learning_rate': uniform(0.01, 0.15),\n",
    "            'depth': randint(3, 8),\n",
    "            'l2_leaf_reg': uniform(1, 7)\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'iterations': [100, 150],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'depth': [3, 5]\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'iterations': trial.suggest_int('iterations', 50, 200),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15, log=True),\n",
    "            'depth': trial.suggest_int('depth', 3, 8),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 10, log=True),\n",
    "            'verbose': False,\n",
    "            'random_seed': 42, # CatBoost uses random_seed\n",
    "            'thread_count': -1,\n",
    "            'objective': 'Logloss'\n",
    "        }\n",
    "    },\n",
    "    \"MLPClassifier\": {\n",
    "        \"class\": MLPClassifier,\n",
    "        \"random_dist\": {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "            'alpha': uniform(0.0001, 0.005),\n",
    "            'learning_rate_init': uniform(0.0001, 0.005)\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'hidden_layer_sizes': [(50,), (100,)],\n",
    "            'alpha': [0.0001, 0.001]\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50)]),\n",
    "            'alpha': trial.suggest_float('alpha', 1e-5, 1e-2, log=True),\n",
    "            'learning_rate_init': trial.suggest_float('learning_rate_init', 1e-4, 1e-2, log=True),\n",
    "            'max_iter': 2000,\n",
    "            'random_state': 42,\n",
    "            'solver': 'adam'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65441089-d139-4982-9de4-11c9d5367183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем процесс обучения и оценки моделей классификации...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1059148c9c9d42ed9458644439882679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Прогнозирование задач классификации:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Оптимизация для is_CC50_above_median (PCA Aggregated):   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:58:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6457219\ttotal: 141ms\tremaining: 25.4s\n",
      "1:\tlearn: 0.5848056\ttotal: 144ms\tremaining: 12.9s\n",
      "2:\tlearn: 0.5237114\ttotal: 150ms\tremaining: 8.9s\n",
      "3:\tlearn: 0.4753648\ttotal: 154ms\tremaining: 6.8s\n",
      "4:\tlearn: 0.4372109\ttotal: 158ms\tremaining: 5.58s\n",
      "5:\tlearn: 0.3983138\ttotal: 162ms\tremaining: 4.74s\n",
      "6:\tlearn: 0.3842155\ttotal: 166ms\tremaining: 4.12s\n",
      "7:\tlearn: 0.3578239\ttotal: 169ms\tremaining: 3.66s\n",
      "8:\tlearn: 0.3416767\ttotal: 173ms\tremaining: 3.31s\n",
      "9:\tlearn: 0.3224828\ttotal: 178ms\tremaining: 3.05s\n",
      "10:\tlearn: 0.3088873\ttotal: 183ms\tremaining: 2.83s\n",
      "11:\tlearn: 0.3012176\ttotal: 189ms\tremaining: 2.66s\n",
      "12:\tlearn: 0.2876396\ttotal: 192ms\tremaining: 2.48s\n",
      "13:\tlearn: 0.2664275\ttotal: 197ms\tremaining: 2.35s\n",
      "14:\tlearn: 0.2539816\ttotal: 203ms\tremaining: 2.24s\n",
      "15:\tlearn: 0.2438903\ttotal: 206ms\tremaining: 2.13s\n",
      "16:\tlearn: 0.2399028\ttotal: 211ms\tremaining: 2.04s\n",
      "17:\tlearn: 0.2347109\ttotal: 217ms\tremaining: 1.96s\n",
      "18:\tlearn: 0.2307209\ttotal: 221ms\tremaining: 1.89s\n",
      "19:\tlearn: 0.2227009\ttotal: 224ms\tremaining: 1.81s\n",
      "20:\tlearn: 0.2120861\ttotal: 228ms\tremaining: 1.74s\n",
      "21:\tlearn: 0.2064466\ttotal: 232ms\tremaining: 1.68s\n",
      "22:\tlearn: 0.2019867\ttotal: 236ms\tremaining: 1.62s\n",
      "23:\tlearn: 0.1962998\ttotal: 239ms\tremaining: 1.56s\n",
      "24:\tlearn: 0.1945645\ttotal: 244ms\tremaining: 1.52s\n",
      "25:\tlearn: 0.1898015\ttotal: 248ms\tremaining: 1.48s\n",
      "26:\tlearn: 0.1851337\ttotal: 253ms\tremaining: 1.44s\n",
      "27:\tlearn: 0.1829982\ttotal: 255ms\tremaining: 1.4s\n",
      "28:\tlearn: 0.1815498\ttotal: 260ms\tremaining: 1.36s\n",
      "29:\tlearn: 0.1792191\ttotal: 264ms\tremaining: 1.33s\n",
      "30:\tlearn: 0.1779464\ttotal: 267ms\tremaining: 1.29s\n",
      "31:\tlearn: 0.1755218\ttotal: 271ms\tremaining: 1.26s\n",
      "32:\tlearn: 0.1745170\ttotal: 274ms\tremaining: 1.23s\n",
      "33:\tlearn: 0.1689789\ttotal: 277ms\tremaining: 1.2s\n",
      "34:\tlearn: 0.1656143\ttotal: 282ms\tremaining: 1.17s\n",
      "35:\tlearn: 0.1638004\ttotal: 285ms\tremaining: 1.15s\n",
      "36:\tlearn: 0.1630459\ttotal: 288ms\tremaining: 1.12s\n",
      "37:\tlearn: 0.1613494\ttotal: 292ms\tremaining: 1.1s\n",
      "38:\tlearn: 0.1570776\ttotal: 296ms\tremaining: 1.08s\n",
      "39:\tlearn: 0.1562635\ttotal: 300ms\tremaining: 1.06s\n",
      "40:\tlearn: 0.1551525\ttotal: 304ms\tremaining: 1.04s\n",
      "41:\tlearn: 0.1536137\ttotal: 308ms\tremaining: 1.02s\n",
      "42:\tlearn: 0.1521708\ttotal: 312ms\tremaining: 1000ms\n",
      "43:\tlearn: 0.1509554\ttotal: 316ms\tremaining: 983ms\n",
      "44:\tlearn: 0.1477287\ttotal: 319ms\tremaining: 963ms\n",
      "45:\tlearn: 0.1432935\ttotal: 323ms\tremaining: 949ms\n",
      "46:\tlearn: 0.1426087\ttotal: 328ms\tremaining: 935ms\n",
      "47:\tlearn: 0.1421280\ttotal: 332ms\tremaining: 920ms\n",
      "48:\tlearn: 0.1411012\ttotal: 336ms\tremaining: 906ms\n",
      "49:\tlearn: 0.1385888\ttotal: 341ms\tremaining: 892ms\n",
      "50:\tlearn: 0.1351703\ttotal: 345ms\tremaining: 879ms\n",
      "51:\tlearn: 0.1342166\ttotal: 348ms\tremaining: 864ms\n",
      "52:\tlearn: 0.1325194\ttotal: 354ms\tremaining: 854ms\n",
      "53:\tlearn: 0.1284728\ttotal: 357ms\tremaining: 840ms\n",
      "54:\tlearn: 0.1283788\ttotal: 362ms\tremaining: 830ms\n",
      "55:\tlearn: 0.1280626\ttotal: 367ms\tremaining: 819ms\n",
      "56:\tlearn: 0.1276589\ttotal: 371ms\tremaining: 806ms\n",
      "57:\tlearn: 0.1257073\ttotal: 375ms\tremaining: 795ms\n",
      "58:\tlearn: 0.1249162\ttotal: 379ms\tremaining: 784ms\n",
      "59:\tlearn: 0.1243699\ttotal: 384ms\tremaining: 774ms\n",
      "60:\tlearn: 0.1235381\ttotal: 388ms\tremaining: 764ms\n",
      "61:\tlearn: 0.1214551\ttotal: 394ms\tremaining: 756ms\n",
      "62:\tlearn: 0.1204939\ttotal: 397ms\tremaining: 744ms\n",
      "63:\tlearn: 0.1196068\ttotal: 401ms\tremaining: 733ms\n",
      "64:\tlearn: 0.1168096\ttotal: 406ms\tremaining: 725ms\n",
      "65:\tlearn: 0.1140953\ttotal: 412ms\tremaining: 717ms\n",
      "66:\tlearn: 0.1117156\ttotal: 415ms\tremaining: 707ms\n",
      "67:\tlearn: 0.1103744\ttotal: 421ms\tremaining: 700ms\n",
      "68:\tlearn: 0.1092756\ttotal: 427ms\tremaining: 693ms\n",
      "69:\tlearn: 0.1083251\ttotal: 430ms\tremaining: 681ms\n",
      "70:\tlearn: 0.1066498\ttotal: 435ms\tremaining: 673ms\n",
      "71:\tlearn: 0.1056437\ttotal: 440ms\tremaining: 666ms\n",
      "72:\tlearn: 0.1055641\ttotal: 443ms\tremaining: 655ms\n",
      "73:\tlearn: 0.1048314\ttotal: 446ms\tremaining: 645ms\n",
      "74:\tlearn: 0.1044270\ttotal: 452ms\tremaining: 638ms\n",
      "75:\tlearn: 0.1039777\ttotal: 457ms\tremaining: 631ms\n",
      "76:\tlearn: 0.1036059\ttotal: 460ms\tremaining: 621ms\n",
      "77:\tlearn: 0.1030994\ttotal: 465ms\tremaining: 614ms\n",
      "78:\tlearn: 0.1012196\ttotal: 470ms\tremaining: 606ms\n",
      "79:\tlearn: 0.1006457\ttotal: 474ms\tremaining: 598ms\n",
      "80:\tlearn: 0.0994987\ttotal: 478ms\tremaining: 590ms\n",
      "81:\tlearn: 0.0965802\ttotal: 481ms\tremaining: 581ms\n",
      "82:\tlearn: 0.0958381\ttotal: 485ms\tremaining: 572ms\n",
      "83:\tlearn: 0.0942514\ttotal: 488ms\tremaining: 564ms\n",
      "84:\tlearn: 0.0939214\ttotal: 491ms\tremaining: 555ms\n",
      "85:\tlearn: 0.0905132\ttotal: 496ms\tremaining: 548ms\n",
      "86:\tlearn: 0.0876966\ttotal: 499ms\tremaining: 539ms\n",
      "87:\tlearn: 0.0855228\ttotal: 502ms\tremaining: 531ms\n",
      "88:\tlearn: 0.0844717\ttotal: 506ms\tremaining: 523ms\n",
      "89:\tlearn: 0.0842625\ttotal: 511ms\tremaining: 516ms\n",
      "90:\tlearn: 0.0817024\ttotal: 514ms\tremaining: 508ms\n",
      "91:\tlearn: 0.0814229\ttotal: 518ms\tremaining: 501ms\n",
      "92:\tlearn: 0.0803383\ttotal: 521ms\tremaining: 493ms\n",
      "93:\tlearn: 0.0801760\ttotal: 524ms\tremaining: 485ms\n",
      "94:\tlearn: 0.0798763\ttotal: 529ms\tremaining: 479ms\n",
      "95:\tlearn: 0.0781655\ttotal: 534ms\tremaining: 473ms\n",
      "96:\tlearn: 0.0779473\ttotal: 537ms\tremaining: 465ms\n",
      "97:\tlearn: 0.0772459\ttotal: 541ms\tremaining: 458ms\n",
      "98:\tlearn: 0.0763597\ttotal: 546ms\tremaining: 452ms\n",
      "99:\tlearn: 0.0743490\ttotal: 549ms\tremaining: 444ms\n",
      "100:\tlearn: 0.0741453\ttotal: 552ms\tremaining: 437ms\n",
      "101:\tlearn: 0.0727741\ttotal: 555ms\tremaining: 430ms\n",
      "102:\tlearn: 0.0705610\ttotal: 560ms\tremaining: 424ms\n",
      "103:\tlearn: 0.0699719\ttotal: 563ms\tremaining: 417ms\n",
      "104:\tlearn: 0.0696286\ttotal: 566ms\tremaining: 410ms\n",
      "105:\tlearn: 0.0694490\ttotal: 570ms\tremaining: 403ms\n",
      "106:\tlearn: 0.0678882\ttotal: 574ms\tremaining: 397ms\n",
      "107:\tlearn: 0.0676760\ttotal: 578ms\tremaining: 391ms\n",
      "108:\tlearn: 0.0675188\ttotal: 583ms\tremaining: 385ms\n",
      "109:\tlearn: 0.0674093\ttotal: 588ms\tremaining: 380ms\n",
      "110:\tlearn: 0.0656611\ttotal: 593ms\tremaining: 374ms\n",
      "111:\tlearn: 0.0655560\ttotal: 598ms\tremaining: 368ms\n",
      "112:\tlearn: 0.0653653\ttotal: 603ms\tremaining: 363ms\n",
      "113:\tlearn: 0.0650144\ttotal: 607ms\tremaining: 357ms\n",
      "114:\tlearn: 0.0648312\ttotal: 611ms\tremaining: 351ms\n",
      "115:\tlearn: 0.0627772\ttotal: 616ms\tremaining: 345ms\n",
      "116:\tlearn: 0.0611696\ttotal: 620ms\tremaining: 339ms\n",
      "117:\tlearn: 0.0610445\ttotal: 624ms\tremaining: 333ms\n",
      "118:\tlearn: 0.0607944\ttotal: 630ms\tremaining: 328ms\n",
      "119:\tlearn: 0.0607076\ttotal: 634ms\tremaining: 322ms\n",
      "120:\tlearn: 0.0602768\ttotal: 639ms\tremaining: 317ms\n",
      "121:\tlearn: 0.0594009\ttotal: 643ms\tremaining: 311ms\n",
      "122:\tlearn: 0.0582224\ttotal: 647ms\tremaining: 305ms\n",
      "123:\tlearn: 0.0580076\ttotal: 650ms\tremaining: 299ms\n",
      "124:\tlearn: 0.0565762\ttotal: 656ms\tremaining: 294ms\n",
      "125:\tlearn: 0.0559031\ttotal: 659ms\tremaining: 288ms\n",
      "126:\tlearn: 0.0555821\ttotal: 664ms\tremaining: 282ms\n",
      "127:\tlearn: 0.0551007\ttotal: 668ms\tremaining: 277ms\n",
      "128:\tlearn: 0.0550060\ttotal: 672ms\tremaining: 271ms\n",
      "129:\tlearn: 0.0549253\ttotal: 676ms\tremaining: 265ms\n",
      "130:\tlearn: 0.0539519\ttotal: 680ms\tremaining: 260ms\n",
      "131:\tlearn: 0.0527794\ttotal: 685ms\tremaining: 254ms\n",
      "132:\tlearn: 0.0527103\ttotal: 690ms\tremaining: 249ms\n",
      "133:\tlearn: 0.0513198\ttotal: 694ms\tremaining: 244ms\n",
      "134:\tlearn: 0.0512519\ttotal: 700ms\tremaining: 238ms\n",
      "135:\tlearn: 0.0509304\ttotal: 705ms\tremaining: 233ms\n",
      "136:\tlearn: 0.0507424\ttotal: 708ms\tremaining: 228ms\n",
      "137:\tlearn: 0.0494181\ttotal: 713ms\tremaining: 222ms\n",
      "138:\tlearn: 0.0489730\ttotal: 718ms\tremaining: 217ms\n",
      "139:\tlearn: 0.0482888\ttotal: 723ms\tremaining: 212ms\n",
      "140:\tlearn: 0.0479874\ttotal: 738ms\tremaining: 209ms\n",
      "141:\tlearn: 0.0479263\ttotal: 743ms\tremaining: 204ms\n",
      "142:\tlearn: 0.0473780\ttotal: 748ms\tremaining: 199ms\n",
      "143:\tlearn: 0.0471111\ttotal: 752ms\tremaining: 193ms\n",
      "144:\tlearn: 0.0470352\ttotal: 757ms\tremaining: 188ms\n",
      "145:\tlearn: 0.0462289\ttotal: 761ms\tremaining: 182ms\n",
      "146:\tlearn: 0.0461874\ttotal: 765ms\tremaining: 177ms\n",
      "147:\tlearn: 0.0460184\ttotal: 770ms\tremaining: 172ms\n",
      "148:\tlearn: 0.0452977\ttotal: 774ms\tremaining: 166ms\n",
      "149:\tlearn: 0.0452422\ttotal: 779ms\tremaining: 161ms\n",
      "150:\tlearn: 0.0452219\ttotal: 784ms\tremaining: 156ms\n",
      "151:\tlearn: 0.0451299\ttotal: 789ms\tremaining: 150ms\n",
      "152:\tlearn: 0.0450166\ttotal: 793ms\tremaining: 145ms\n",
      "153:\tlearn: 0.0437555\ttotal: 797ms\tremaining: 140ms\n",
      "154:\tlearn: 0.0432455\ttotal: 802ms\tremaining: 135ms\n",
      "155:\tlearn: 0.0431747\ttotal: 807ms\tremaining: 129ms\n",
      "156:\tlearn: 0.0428098\ttotal: 810ms\tremaining: 124ms\n",
      "157:\tlearn: 0.0427311\ttotal: 815ms\tremaining: 119ms\n",
      "158:\tlearn: 0.0427186\ttotal: 819ms\tremaining: 113ms\n",
      "159:\tlearn: 0.0426722\ttotal: 824ms\tremaining: 108ms\n",
      "160:\tlearn: 0.0418245\ttotal: 828ms\tremaining: 103ms\n",
      "161:\tlearn: 0.0417445\ttotal: 832ms\tremaining: 97.5ms\n",
      "162:\tlearn: 0.0413962\ttotal: 836ms\tremaining: 92.3ms\n",
      "163:\tlearn: 0.0413774\ttotal: 841ms\tremaining: 87.1ms\n",
      "164:\tlearn: 0.0413331\ttotal: 846ms\tremaining: 82.1ms\n",
      "165:\tlearn: 0.0412904\ttotal: 851ms\tremaining: 76.9ms\n",
      "166:\tlearn: 0.0411548\ttotal: 854ms\tremaining: 71.6ms\n",
      "167:\tlearn: 0.0411395\ttotal: 858ms\tremaining: 66.4ms\n",
      "168:\tlearn: 0.0400471\ttotal: 862ms\tremaining: 61.2ms\n",
      "169:\tlearn: 0.0394506\ttotal: 866ms\tremaining: 56ms\n",
      "170:\tlearn: 0.0393870\ttotal: 869ms\tremaining: 50.8ms\n",
      "171:\tlearn: 0.0390671\ttotal: 872ms\tremaining: 45.6ms\n",
      "172:\tlearn: 0.0387785\ttotal: 876ms\tremaining: 40.5ms\n",
      "173:\tlearn: 0.0387656\ttotal: 880ms\tremaining: 35.4ms\n",
      "174:\tlearn: 0.0387269\ttotal: 883ms\tremaining: 30.3ms\n",
      "175:\tlearn: 0.0386936\ttotal: 886ms\tremaining: 25.2ms\n",
      "176:\tlearn: 0.0380801\ttotal: 891ms\tremaining: 20.1ms\n",
      "177:\tlearn: 0.0374906\ttotal: 894ms\tremaining: 15.1ms\n",
      "178:\tlearn: 0.0373905\ttotal: 898ms\tremaining: 10ms\n",
      "179:\tlearn: 0.0373573\ttotal: 901ms\tremaining: 5ms\n",
      "180:\tlearn: 0.0363823\ttotal: 904ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:59:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6447402\ttotal: 4.4ms\tremaining: 655ms\n",
      "1:\tlearn: 0.5760917\ttotal: 8.46ms\tremaining: 626ms\n",
      "2:\tlearn: 0.5204385\ttotal: 11.5ms\tremaining: 564ms\n",
      "3:\tlearn: 0.4812310\ttotal: 15.2ms\tremaining: 555ms\n",
      "4:\tlearn: 0.4592584\ttotal: 19.6ms\tremaining: 569ms\n",
      "5:\tlearn: 0.4189346\ttotal: 23.9ms\tremaining: 573ms\n",
      "6:\tlearn: 0.4051198\ttotal: 27ms\tremaining: 551ms\n",
      "7:\tlearn: 0.3820944\ttotal: 30.8ms\tremaining: 547ms\n",
      "8:\tlearn: 0.3538562\ttotal: 33.5ms\tremaining: 524ms\n",
      "9:\tlearn: 0.3359336\ttotal: 36.5ms\tremaining: 510ms\n",
      "10:\tlearn: 0.3163710\ttotal: 38.6ms\tremaining: 488ms\n",
      "11:\tlearn: 0.3100042\ttotal: 40.9ms\tremaining: 470ms\n",
      "12:\tlearn: 0.3032996\ttotal: 43ms\tremaining: 453ms\n",
      "13:\tlearn: 0.2905256\ttotal: 45.6ms\tremaining: 443ms\n",
      "14:\tlearn: 0.2780748\ttotal: 48ms\tremaining: 432ms\n",
      "15:\tlearn: 0.2713448\ttotal: 51ms\tremaining: 427ms\n",
      "16:\tlearn: 0.2672378\ttotal: 54.6ms\tremaining: 427ms\n",
      "17:\tlearn: 0.2619921\ttotal: 57.1ms\tremaining: 419ms\n",
      "18:\tlearn: 0.2561190\ttotal: 61.4ms\tremaining: 423ms\n",
      "19:\tlearn: 0.2530569\ttotal: 63.9ms\tremaining: 415ms\n",
      "20:\tlearn: 0.2497423\ttotal: 67.1ms\tremaining: 412ms\n",
      "21:\tlearn: 0.2461710\ttotal: 70.1ms\tremaining: 408ms\n",
      "22:\tlearn: 0.2417209\ttotal: 72ms\tremaining: 397ms\n",
      "23:\tlearn: 0.2375441\ttotal: 74.2ms\tremaining: 390ms\n",
      "24:\tlearn: 0.2355286\ttotal: 76.5ms\tremaining: 383ms\n",
      "25:\tlearn: 0.2328324\ttotal: 81ms\tremaining: 386ms\n",
      "26:\tlearn: 0.2307439\ttotal: 84.1ms\tremaining: 383ms\n",
      "27:\tlearn: 0.2178349\ttotal: 87ms\tremaining: 379ms\n",
      "28:\tlearn: 0.2147633\ttotal: 91.3ms\tremaining: 381ms\n",
      "29:\tlearn: 0.2128419\ttotal: 95.9ms\tremaining: 384ms\n",
      "30:\tlearn: 0.2073825\ttotal: 99.4ms\tremaining: 382ms\n",
      "31:\tlearn: 0.2010337\ttotal: 102ms\tremaining: 376ms\n",
      "32:\tlearn: 0.1993789\ttotal: 105ms\tremaining: 371ms\n",
      "33:\tlearn: 0.1972797\ttotal: 109ms\tremaining: 372ms\n",
      "34:\tlearn: 0.1953776\ttotal: 113ms\tremaining: 370ms\n",
      "35:\tlearn: 0.1946994\ttotal: 116ms\tremaining: 366ms\n",
      "36:\tlearn: 0.1929622\ttotal: 120ms\tremaining: 366ms\n",
      "37:\tlearn: 0.1884303\ttotal: 124ms\tremaining: 366ms\n",
      "38:\tlearn: 0.1812651\ttotal: 127ms\tremaining: 362ms\n",
      "39:\tlearn: 0.1800990\ttotal: 130ms\tremaining: 358ms\n",
      "40:\tlearn: 0.1789134\ttotal: 134ms\tremaining: 357ms\n",
      "41:\tlearn: 0.1750382\ttotal: 139ms\tremaining: 358ms\n",
      "42:\tlearn: 0.1740233\ttotal: 142ms\tremaining: 354ms\n",
      "43:\tlearn: 0.1683648\ttotal: 146ms\tremaining: 351ms\n",
      "44:\tlearn: 0.1675363\ttotal: 150ms\tremaining: 349ms\n",
      "45:\tlearn: 0.1661874\ttotal: 153ms\tremaining: 346ms\n",
      "46:\tlearn: 0.1659240\ttotal: 156ms\tremaining: 341ms\n",
      "47:\tlearn: 0.1654738\ttotal: 158ms\tremaining: 335ms\n",
      "48:\tlearn: 0.1644166\ttotal: 161ms\tremaining: 332ms\n",
      "49:\tlearn: 0.1599161\ttotal: 166ms\tremaining: 331ms\n",
      "50:\tlearn: 0.1590781\ttotal: 169ms\tremaining: 328ms\n",
      "51:\tlearn: 0.1549844\ttotal: 171ms\tremaining: 323ms\n",
      "52:\tlearn: 0.1495747\ttotal: 174ms\tremaining: 318ms\n",
      "53:\tlearn: 0.1488479\ttotal: 177ms\tremaining: 315ms\n",
      "54:\tlearn: 0.1481941\ttotal: 181ms\tremaining: 312ms\n",
      "55:\tlearn: 0.1474080\ttotal: 184ms\tremaining: 310ms\n",
      "56:\tlearn: 0.1467858\ttotal: 186ms\tremaining: 304ms\n",
      "57:\tlearn: 0.1453543\ttotal: 190ms\tremaining: 301ms\n",
      "58:\tlearn: 0.1447721\ttotal: 194ms\tremaining: 299ms\n",
      "59:\tlearn: 0.1439739\ttotal: 198ms\tremaining: 297ms\n",
      "60:\tlearn: 0.1427536\ttotal: 201ms\tremaining: 294ms\n",
      "61:\tlearn: 0.1419085\ttotal: 204ms\tremaining: 290ms\n",
      "62:\tlearn: 0.1395459\ttotal: 209ms\tremaining: 288ms\n",
      "63:\tlearn: 0.1374818\ttotal: 213ms\tremaining: 286ms\n",
      "64:\tlearn: 0.1347507\ttotal: 216ms\tremaining: 283ms\n",
      "65:\tlearn: 0.1305140\ttotal: 219ms\tremaining: 279ms\n",
      "66:\tlearn: 0.1290991\ttotal: 224ms\tremaining: 277ms\n",
      "67:\tlearn: 0.1266644\ttotal: 228ms\tremaining: 275ms\n",
      "68:\tlearn: 0.1260794\ttotal: 231ms\tremaining: 271ms\n",
      "69:\tlearn: 0.1255828\ttotal: 234ms\tremaining: 267ms\n",
      "70:\tlearn: 0.1234353\ttotal: 238ms\tremaining: 265ms\n",
      "71:\tlearn: 0.1204019\ttotal: 242ms\tremaining: 262ms\n",
      "72:\tlearn: 0.1163703\ttotal: 245ms\tremaining: 259ms\n",
      "73:\tlearn: 0.1132453\ttotal: 249ms\tremaining: 256ms\n",
      "74:\tlearn: 0.1128523\ttotal: 254ms\tremaining: 254ms\n",
      "75:\tlearn: 0.1100008\ttotal: 256ms\tremaining: 250ms\n",
      "76:\tlearn: 0.1072170\ttotal: 259ms\tremaining: 245ms\n",
      "77:\tlearn: 0.1038317\ttotal: 261ms\tremaining: 241ms\n",
      "78:\tlearn: 0.1018244\ttotal: 264ms\tremaining: 237ms\n",
      "79:\tlearn: 0.1011510\ttotal: 267ms\tremaining: 234ms\n",
      "80:\tlearn: 0.1004391\ttotal: 270ms\tremaining: 230ms\n",
      "81:\tlearn: 0.0998240\ttotal: 273ms\tremaining: 226ms\n",
      "82:\tlearn: 0.0988330\ttotal: 276ms\tremaining: 222ms\n",
      "83:\tlearn: 0.0986582\ttotal: 279ms\tremaining: 219ms\n",
      "84:\tlearn: 0.0974367\ttotal: 283ms\tremaining: 217ms\n",
      "85:\tlearn: 0.0972479\ttotal: 288ms\tremaining: 214ms\n",
      "86:\tlearn: 0.0942695\ttotal: 291ms\tremaining: 211ms\n",
      "87:\tlearn: 0.0935982\ttotal: 295ms\tremaining: 208ms\n",
      "88:\tlearn: 0.0925920\ttotal: 299ms\tremaining: 205ms\n",
      "89:\tlearn: 0.0917450\ttotal: 303ms\tremaining: 202ms\n",
      "90:\tlearn: 0.0909390\ttotal: 305ms\tremaining: 198ms\n",
      "91:\tlearn: 0.0895329\ttotal: 307ms\tremaining: 194ms\n",
      "92:\tlearn: 0.0888894\ttotal: 309ms\tremaining: 190ms\n",
      "93:\tlearn: 0.0885646\ttotal: 311ms\tremaining: 186ms\n",
      "94:\tlearn: 0.0877570\ttotal: 315ms\tremaining: 182ms\n",
      "95:\tlearn: 0.0876263\ttotal: 317ms\tremaining: 178ms\n",
      "96:\tlearn: 0.0862263\ttotal: 320ms\tremaining: 175ms\n",
      "97:\tlearn: 0.0843839\ttotal: 323ms\tremaining: 171ms\n",
      "98:\tlearn: 0.0817857\ttotal: 327ms\tremaining: 168ms\n",
      "99:\tlearn: 0.0798875\ttotal: 330ms\tremaining: 165ms\n",
      "100:\tlearn: 0.0790075\ttotal: 334ms\tremaining: 162ms\n",
      "101:\tlearn: 0.0778894\ttotal: 337ms\tremaining: 158ms\n",
      "102:\tlearn: 0.0753801\ttotal: 341ms\tremaining: 156ms\n",
      "103:\tlearn: 0.0747352\ttotal: 343ms\tremaining: 152ms\n",
      "104:\tlearn: 0.0723928\ttotal: 346ms\tremaining: 148ms\n",
      "105:\tlearn: 0.0712391\ttotal: 349ms\tremaining: 145ms\n",
      "106:\tlearn: 0.0707991\ttotal: 353ms\tremaining: 142ms\n",
      "107:\tlearn: 0.0689748\ttotal: 358ms\tremaining: 139ms\n",
      "108:\tlearn: 0.0683966\ttotal: 361ms\tremaining: 136ms\n",
      "109:\tlearn: 0.0663312\ttotal: 364ms\tremaining: 132ms\n",
      "110:\tlearn: 0.0655535\ttotal: 367ms\tremaining: 129ms\n",
      "111:\tlearn: 0.0638886\ttotal: 371ms\tremaining: 126ms\n",
      "112:\tlearn: 0.0628414\ttotal: 374ms\tremaining: 123ms\n",
      "113:\tlearn: 0.0618917\ttotal: 377ms\tremaining: 119ms\n",
      "114:\tlearn: 0.0609149\ttotal: 380ms\tremaining: 116ms\n",
      "115:\tlearn: 0.0607115\ttotal: 385ms\tremaining: 113ms\n",
      "116:\tlearn: 0.0590363\ttotal: 389ms\tremaining: 110ms\n",
      "117:\tlearn: 0.0586349\ttotal: 391ms\tremaining: 106ms\n",
      "118:\tlearn: 0.0584544\ttotal: 394ms\tremaining: 103ms\n",
      "119:\tlearn: 0.0573789\ttotal: 397ms\tremaining: 99.4ms\n",
      "120:\tlearn: 0.0568295\ttotal: 402ms\tremaining: 96.3ms\n",
      "121:\tlearn: 0.0566610\ttotal: 406ms\tremaining: 93.2ms\n",
      "122:\tlearn: 0.0565703\ttotal: 411ms\tremaining: 90.1ms\n",
      "123:\tlearn: 0.0562582\ttotal: 414ms\tremaining: 86.8ms\n",
      "124:\tlearn: 0.0550635\ttotal: 418ms\tremaining: 83.6ms\n",
      "125:\tlearn: 0.0544800\ttotal: 421ms\tremaining: 80.2ms\n",
      "126:\tlearn: 0.0544031\ttotal: 425ms\tremaining: 77ms\n",
      "127:\tlearn: 0.0542556\ttotal: 429ms\tremaining: 73.8ms\n",
      "128:\tlearn: 0.0539681\ttotal: 433ms\tremaining: 70.5ms\n",
      "129:\tlearn: 0.0538320\ttotal: 436ms\tremaining: 67ms\n",
      "130:\tlearn: 0.0535949\ttotal: 438ms\tremaining: 63.5ms\n",
      "131:\tlearn: 0.0532419\ttotal: 440ms\tremaining: 60.1ms\n",
      "132:\tlearn: 0.0531882\ttotal: 442ms\tremaining: 56.5ms\n",
      "133:\tlearn: 0.0531347\ttotal: 446ms\tremaining: 53.3ms\n",
      "134:\tlearn: 0.0522549\ttotal: 450ms\tremaining: 50ms\n",
      "135:\tlearn: 0.0519606\ttotal: 454ms\tremaining: 46.7ms\n",
      "136:\tlearn: 0.0519043\ttotal: 458ms\tremaining: 43.5ms\n",
      "137:\tlearn: 0.0517863\ttotal: 463ms\tremaining: 40.2ms\n",
      "138:\tlearn: 0.0509557\ttotal: 466ms\tremaining: 36.9ms\n",
      "139:\tlearn: 0.0508225\ttotal: 468ms\tremaining: 33.5ms\n",
      "140:\tlearn: 0.0497612\ttotal: 472ms\tremaining: 30.1ms\n",
      "141:\tlearn: 0.0495606\ttotal: 476ms\tremaining: 26.8ms\n",
      "142:\tlearn: 0.0493224\ttotal: 480ms\tremaining: 23.5ms\n",
      "143:\tlearn: 0.0491431\ttotal: 482ms\tremaining: 20.1ms\n",
      "144:\tlearn: 0.0476402\ttotal: 484ms\tremaining: 16.7ms\n",
      "145:\tlearn: 0.0475980\ttotal: 488ms\tremaining: 13.4ms\n",
      "146:\tlearn: 0.0471155\ttotal: 492ms\tremaining: 10ms\n",
      "147:\tlearn: 0.0469371\ttotal: 495ms\tremaining: 6.7ms\n",
      "148:\tlearn: 0.0457816\ttotal: 498ms\tremaining: 3.34ms\n",
      "149:\tlearn: 0.0449945\ttotal: 502ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-06-18 19:59:55,027] A new study created in memory with name: no-name-911443be-79f8-4e55-9864-8f01c2a60be7\n",
      "[I 2025-06-18 19:59:55,202] Trial 0 finished with value: -0.9856870702453507 and parameters: {'C': 0.5611516415334505, 'penalty': 'l1'}. Best is trial 0 with value: -0.9856870702453507.\n",
      "[I 2025-06-18 19:59:55,491] Trial 1 finished with value: -0.9829368846694797 and parameters: {'C': 1.5751320499779735, 'penalty': 'l1'}. Best is trial 0 with value: -0.9856870702453507.\n",
      "[I 2025-06-18 19:59:55,587] Trial 2 finished with value: -0.9846246093139552 and parameters: {'C': 0.13066739238053282, 'penalty': 'l1'}. Best is trial 0 with value: -0.9856870702453507.\n",
      "[I 2025-06-18 19:59:55,893] Trial 3 finished with value: -0.9729052000312549 and parameters: {'C': 2.607024758370768, 'penalty': 'l2'}. Best is trial 0 with value: -0.9856870702453507.\n",
      "[I 2025-06-18 19:59:56,560] Trial 4 finished with value: -0.9755302586341618 and parameters: {'C': 4.622589001020832, 'penalty': 'l1'}. Best is trial 0 with value: -0.9856870702453507.\n",
      "[I 2025-06-18 19:59:56,707] Trial 5 finished with value: -0.9705613328254413 and parameters: {'C': 0.2327067708383781, 'penalty': 'l2'}. Best is trial 0 with value: -0.9856870702453507.\n",
      "[I 2025-06-18 19:59:56,883] Trial 6 finished with value: -0.9739677390998593 and parameters: {'C': 0.7309539835912913, 'penalty': 'l2'}. Best is trial 0 with value: -0.9856870702453507.\n",
      "[I 2025-06-18 19:59:57,010] Trial 7 finished with value: -0.969780043756837 and parameters: {'C': 0.19010245319870356, 'penalty': 'l2'}. Best is trial 0 with value: -0.9856870702453507.\n",
      "[I 2025-06-18 19:59:57,148] Trial 8 finished with value: -0.9851245214095954 and parameters: {'C': 0.8168455894760165, 'penalty': 'l1'}. Best is trial 0 with value: -0.9856870702453507.\n",
      "[I 2025-06-18 19:59:57,281] Trial 9 finished with value: -0.9843744725738397 and parameters: {'C': 1.0677482709481354, 'penalty': 'l1'}. Best is trial 0 with value: -0.9856870702453507.\n",
      "[I 2025-06-18 19:59:57,384] Trial 10 finished with value: -0.9860933690811065 and parameters: {'C': 0.4194601131160366, 'penalty': 'l1'}. Best is trial 10 with value: -0.9860933690811065.\n",
      "[I 2025-06-18 19:59:57,474] Trial 11 finished with value: -0.985843373964682 and parameters: {'C': 0.39469407668392625, 'penalty': 'l1'}. Best is trial 10 with value: -0.9860933690811065.\n",
      "[I 2025-06-18 19:59:57,573] Trial 12 finished with value: -0.9857183300125021 and parameters: {'C': 0.460505719895977, 'penalty': 'l1'}. Best is trial 10 with value: -0.9860933690811065.\n",
      "[I 2025-06-18 19:59:57,659] Trial 13 finished with value: -0.9854684032661354 and parameters: {'C': 0.32228560396509087, 'penalty': 'l1'}. Best is trial 10 with value: -0.9860933690811065.\n",
      "[I 2025-06-18 19:59:58,737] Trial 14 finished with value: -0.9718113572433194 and parameters: {'C': 7.832921114568403, 'penalty': 'l1'}. Best is trial 10 with value: -0.9860933690811065.\n",
      "[I 2025-06-18 19:59:58,807] Trial 15 finished with value: -0.9846558397796532 and parameters: {'C': 0.11364621894822119, 'penalty': 'l1'}. Best is trial 10 with value: -0.9860933690811065.\n",
      "[I 2025-06-18 19:59:58,904] Trial 16 finished with value: -0.9856246581497109 and parameters: {'C': 0.34887662007597126, 'penalty': 'l1'}. Best is trial 10 with value: -0.9860933690811065.\n",
      "[I 2025-06-18 19:59:59,098] Trial 17 finished with value: -0.9837494383888108 and parameters: {'C': 1.2906546031547719, 'penalty': 'l1'}. Best is trial 10 with value: -0.9860933690811065.\n",
      "[I 2025-06-18 19:59:59,308] Trial 18 finished with value: -0.973217709798406 and parameters: {'C': 2.194953351990623, 'penalty': 'l2'}. Best is trial 10 with value: -0.9860933690811065.\n",
      "[I 2025-06-18 19:59:59,392] Trial 19 finished with value: -0.9845933641975307 and parameters: {'C': 0.20576409552301256, 'penalty': 'l1'}. Best is trial 10 with value: -0.9860933690811065.\n",
      "[I 2025-06-18 19:59:59,411] A new study created in memory with name: no-name-961b3cdb-1d41-4885-9566-21b5d3aedb11\n",
      "[I 2025-06-18 20:00:02,109] Trial 0 finished with value: -0.899293412544929 and parameters: {'n_estimators': 106, 'max_depth': 5, 'min_samples_split': 3}. Best is trial 0 with value: -0.899293412544929.\n",
      "[I 2025-06-18 20:00:04,088] Trial 1 finished with value: -0.8974342621894046 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 0 with value: -0.899293412544929.\n",
      "[I 2025-06-18 20:00:09,770] Trial 2 finished with value: -0.9100751362517581 and parameters: {'n_estimators': 175, 'max_depth': None, 'min_samples_split': 5}. Best is trial 2 with value: -0.9100751362517581.\n",
      "[I 2025-06-18 20:00:13,395] Trial 3 finished with value: -0.9066688374160025 and parameters: {'n_estimators': 115, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 2 with value: -0.9100751362517581.\n",
      "[I 2025-06-18 20:00:15,861] Trial 4 finished with value: -0.9006842426551025 and parameters: {'n_estimators': 118, 'max_depth': 5, 'min_samples_split': 2}. Best is trial 2 with value: -0.9100751362517581.\n",
      "[I 2025-06-18 20:00:19,002] Trial 5 finished with value: -0.9140129390334426 and parameters: {'n_estimators': 141, 'max_depth': None, 'min_samples_split': 7}. Best is trial 5 with value: -0.9140129390334426.\n",
      "[I 2025-06-18 20:00:20,712] Trial 6 finished with value: -0.905574906723707 and parameters: {'n_estimators': 95, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 5 with value: -0.9140129390334426.\n",
      "[I 2025-06-18 20:00:21,514] Trial 7 finished with value: -0.8970748871894045 and parameters: {'n_estimators': 55, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 5 with value: -0.9140129390334426.\n",
      "[I 2025-06-18 20:00:23,912] Trial 8 finished with value: -0.9128723726363495 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 5 with value: -0.9140129390334426.\n",
      "[I 2025-06-18 20:00:26,065] Trial 9 finished with value: -0.9033404584700735 and parameters: {'n_estimators': 140, 'max_depth': 5, 'min_samples_split': 4}. Best is trial 5 with value: -0.9140129390334426.\n",
      "[I 2025-06-18 20:00:32,291] Trial 10 finished with value: -0.9161066499648383 and parameters: {'n_estimators': 194, 'max_depth': None, 'min_samples_split': 7}. Best is trial 10 with value: -0.9161066499648383.\n",
      "[I 2025-06-18 20:00:38,268] Trial 11 finished with value: -0.9159503999648383 and parameters: {'n_estimators': 190, 'max_depth': None, 'min_samples_split': 7}. Best is trial 10 with value: -0.9161066499648383.\n",
      "[I 2025-06-18 20:00:45,136] Trial 12 finished with value: -0.9162942769378027 and parameters: {'n_estimators': 198, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 12 with value: -0.9162942769378027.\n",
      "[I 2025-06-18 20:00:51,330] Trial 13 finished with value: -0.9162630269378027 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 12 with value: -0.9162942769378027.\n",
      "[I 2025-06-18 20:00:56,533] Trial 14 finished with value: -0.9112316939170182 and parameters: {'n_estimators': 166, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 12 with value: -0.9162942769378027.\n",
      "[I 2025-06-18 20:01:02,106] Trial 15 finished with value: -0.9110441939170182 and parameters: {'n_estimators': 163, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 12 with value: -0.9162942769378027.\n",
      "[I 2025-06-18 20:01:08,257] Trial 16 finished with value: -0.9127004439170182 and parameters: {'n_estimators': 196, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 12 with value: -0.9162942769378027.\n",
      "[I 2025-06-18 20:01:14,492] Trial 17 finished with value: -0.9133253413619314 and parameters: {'n_estimators': 175, 'max_depth': 15, 'min_samples_split': 8}. Best is trial 12 with value: -0.9162942769378027.\n",
      "[I 2025-06-18 20:01:19,994] Trial 18 finished with value: -0.9132942574035006 and parameters: {'n_estimators': 155, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 12 with value: -0.9162942769378027.\n",
      "[I 2025-06-18 20:01:22,905] Trial 19 finished with value: -0.903418920436787 and parameters: {'n_estimators': 84, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 12 with value: -0.9162942769378027.\n",
      "[I 2025-06-18 20:01:24,553] A new study created in memory with name: no-name-4918ee1b-97b3-4179-b139-cf480e6e830f\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:26,441] Trial 0 finished with value: -0.9938591747734021 and parameters: {'n_estimators': 106, 'learning_rate': 0.13125830316209655, 'max_depth': 7, 'subsample': 0.8795975452591109}. Best is trial 0 with value: -0.9938591747734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:27,348] Trial 1 finished with value: -0.9676553611892482 and parameters: {'n_estimators': 73, 'learning_rate': 0.015256811898068502, 'max_depth': 3, 'subsample': 0.9598528437324805}. Best is trial 0 with value: -0.9938591747734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:28,825] Trial 2 finished with value: -0.9942029443077043 and parameters: {'n_estimators': 140, 'learning_rate': 0.06803900745073706, 'max_depth': 3, 'subsample': 0.9909729556485982}. Best is trial 2 with value: -0.9942029443077043.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:31,693] Trial 3 finished with value: -0.9904996532661354 and parameters: {'n_estimators': 175, 'learning_rate': 0.01777174904859463, 'max_depth': 4, 'subsample': 0.7550213529560301}. Best is trial 2 with value: -0.9942029443077043.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:33,531] Trial 4 finished with value: -0.9939060448898266 and parameters: {'n_estimators': 95, 'learning_rate': 0.04141536110538596, 'max_depth': 5, 'subsample': 0.7873687420594125}. Best is trial 2 with value: -0.9942029443077043.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:35,765] Trial 5 finished with value: -0.986358920827473 and parameters: {'n_estimators': 142, 'learning_rate': 0.01459007452373112, 'max_depth': 4, 'subsample': 0.8099085529881075}. Best is trial 2 with value: -0.9942029443077043.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:37,433] Trial 6 finished with value: -0.993593540006251 and parameters: {'n_estimators': 118, 'learning_rate': 0.0838375512850209, 'max_depth': 4, 'subsample': 0.8542703315240835}. Best is trial 2 with value: -0.9942029443077043.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:40,653] Trial 7 finished with value: -0.9854213915260196 and parameters: {'n_estimators': 139, 'learning_rate': 0.011340440501807348, 'max_depth': 6, 'subsample': 0.7511572371061874}. Best is trial 2 with value: -0.9942029443077043.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:42,153] Trial 8 finished with value: -0.9937966943077043 and parameters: {'n_estimators': 59, 'learning_rate': 0.13060986669773664, 'max_depth': 8, 'subsample': 0.9425192044349383}. Best is trial 2 with value: -0.9942029443077043.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:44,975] Trial 9 finished with value: -0.9829213597827785 and parameters: {'n_estimators': 95, 'learning_rate': 0.01302780710309028, 'max_depth': 7, 'subsample': 0.8320457481218804}. Best is trial 2 with value: -0.9942029443077043.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:47,548] Trial 10 finished with value: -0.9938123486091577 and parameters: {'n_estimators': 194, 'learning_rate': 0.04542131010106151, 'max_depth': 3, 'subsample': 0.9865274840450808}. Best is trial 2 with value: -0.9942029443077043.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:50,275] Trial 11 finished with value: -0.9941248144241287 and parameters: {'n_estimators': 157, 'learning_rate': 0.04114027494631444, 'max_depth': 5, 'subsample': 0.9082219033875295}. Best is trial 2 with value: -0.9942029443077043.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:52,703] Trial 12 finished with value: -0.9942185644241288 and parameters: {'n_estimators': 162, 'learning_rate': 0.0696130364836842, 'max_depth': 5, 'subsample': 0.9091467695020283}. Best is trial 12 with value: -0.9942185644241288.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:55,678] Trial 13 finished with value: -0.9936247900062509 and parameters: {'n_estimators': 166, 'learning_rate': 0.06997365526201772, 'max_depth': 6, 'subsample': 0.9172303829656776}. Best is trial 12 with value: -0.9942185644241288.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:01:58,094] Trial 14 finished with value: -0.9946873437255821 and parameters: {'n_estimators': 199, 'learning_rate': 0.06881579389109171, 'max_depth': 3, 'subsample': 0.9904365912780789}. Best is trial 14 with value: -0.9946873437255821.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:01:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:02:01,434] Trial 15 finished with value: -0.99428107419128 and parameters: {'n_estimators': 194, 'learning_rate': 0.02550053148264153, 'max_depth': 5, 'subsample': 0.8958043600674943}. Best is trial 14 with value: -0.9946873437255821.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:02:04,143] Trial 16 finished with value: -0.9919997021018909 and parameters: {'n_estimators': 199, 'learning_rate': 0.022225129472524915, 'max_depth': 4, 'subsample': 0.8687641102092307}. Best is trial 14 with value: -0.9946873437255821.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:02:08,850] Trial 17 finished with value: -0.9943435644241287 and parameters: {'n_estimators': 180, 'learning_rate': 0.026801662524439673, 'max_depth': 6, 'subsample': 0.7113869133285273}. Best is trial 14 with value: -0.9946873437255821.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:02:14,247] Trial 18 finished with value: -0.9948435790748554 and parameters: {'n_estimators': 181, 'learning_rate': 0.029889222048762723, 'max_depth': 7, 'subsample': 0.710333251865073}. Best is trial 18 with value: -0.9948435790748554.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:02:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:02:18,497] Trial 19 finished with value: -0.9946560693077042 and parameters: {'n_estimators': 181, 'learning_rate': 0.02979594422414887, 'max_depth': 8, 'subsample': 0.7009368899840085}. Best is trial 18 with value: -0.9948435790748554.\n",
      "[I 2025-06-18 20:02:19,520] A new study created in memory with name: no-name-d4b35732-62ed-4362-9a32-8b8a12eb3740\n",
      "[I 2025-06-18 20:02:27,507] Trial 0 finished with value: -0.9898903759376465 and parameters: {'iterations': 106, 'learning_rate': 0.13125830316209655, 'depth': 7, 'l2_leaf_reg': 0.6251373574521749}. Best is trial 0 with value: -0.9898903759376465.\n",
      "[I 2025-06-18 20:02:29,675] Trial 1 finished with value: -0.9671082322433193 and parameters: {'iterations': 73, 'learning_rate': 0.015256811898068502, 'depth': 3, 'l2_leaf_reg': 3.9676050770529883}. Best is trial 0 with value: -0.9898903759376465.\n",
      "[I 2025-06-18 20:02:32,782] Trial 2 finished with value: -0.9914684618690421 and parameters: {'iterations': 140, 'learning_rate': 0.06803900745073706, 'depth': 3, 'l2_leaf_reg': 8.123245085588687}. Best is trial 2 with value: -0.9914684618690421.\n",
      "[I 2025-06-18 20:02:37,311] Trial 3 finished with value: -0.9819367283950617 and parameters: {'iterations': 175, 'learning_rate': 0.01777174904859463, 'depth': 4, 'l2_leaf_reg': 0.03549878832196503}. Best is trial 2 with value: -0.9914684618690421.\n",
      "[I 2025-06-18 20:02:40,637] Trial 4 finished with value: -0.9861088182723863 and parameters: {'iterations': 95, 'learning_rate': 0.04141536110538596, 'depth': 5, 'l2_leaf_reg': 0.07476312062252301}. Best is trial 2 with value: -0.9914684618690421.\n",
      "[I 2025-06-18 20:02:44,345] Trial 5 finished with value: -0.9782334861892483 and parameters: {'iterations': 142, 'learning_rate': 0.01459007452373112, 'depth': 4, 'l2_leaf_reg': 0.1256277350380703}. Best is trial 2 with value: -0.9914684618690421.\n",
      "[I 2025-06-18 20:02:48,033] Trial 6 finished with value: -0.991077758731833 and parameters: {'iterations': 118, 'learning_rate': 0.0838375512850209, 'depth': 4, 'l2_leaf_reg': 0.34890188454913873}. Best is trial 2 with value: -0.9914684618690421.\n",
      "[I 2025-06-18 20:02:54,772] Trial 7 finished with value: -0.9802024022308172 and parameters: {'iterations': 139, 'learning_rate': 0.011340440501807348, 'depth': 6, 'l2_leaf_reg': 0.03247673570627449}. Best is trial 2 with value: -0.9914684618690421.\n",
      "[I 2025-06-18 20:03:01,687] Trial 8 finished with value: -0.9830149510665729 and parameters: {'iterations': 59, 'learning_rate': 0.13060986669773664, 'depth': 8, 'l2_leaf_reg': 2.6619018884890564}. Best is trial 2 with value: -0.9914684618690421.\n",
      "[I 2025-06-18 20:03:08,658] Trial 9 finished with value: -0.9763896580520394 and parameters: {'iterations': 95, 'learning_rate': 0.01302780710309028, 'depth': 7, 'l2_leaf_reg': 0.2091498132903561}. Best is trial 2 with value: -0.9914684618690421.\n",
      "[I 2025-06-18 20:03:12,956] Trial 10 finished with value: -0.9904215282661355 and parameters: {'iterations': 194, 'learning_rate': 0.04542131010106151, 'depth': 3, 'l2_leaf_reg': 7.332884431753993}. Best is trial 2 with value: -0.9914684618690421.\n",
      "[I 2025-06-18 20:03:17,078] Trial 11 finished with value: -0.9925778661704955 and parameters: {'iterations': 157, 'learning_rate': 0.0728296401315956, 'depth': 4, 'l2_leaf_reg': 0.820191502720174}. Best is trial 11 with value: -0.9925778661704955.\n",
      "[I 2025-06-18 20:03:20,728] Trial 12 finished with value: -0.9924528661704954 and parameters: {'iterations': 162, 'learning_rate': 0.0696130364836842, 'depth': 3, 'l2_leaf_reg': 1.234433488463974}. Best is trial 11 with value: -0.9925778661704955.\n",
      "[I 2025-06-18 20:03:26,567] Trial 13 finished with value: -0.9836712645530552 and parameters: {'iterations': 167, 'learning_rate': 0.02659986258001816, 'depth': 5, 'l2_leaf_reg': 1.1052490661711365}. Best is trial 11 with value: -0.9925778661704955.\n",
      "[I 2025-06-18 20:03:30,695] Trial 14 finished with value: -0.9919215771018909 and parameters: {'iterations': 163, 'learning_rate': 0.06881579389109171, 'depth': 4, 'l2_leaf_reg': 1.3034338783160528}. Best is trial 11 with value: -0.9925778661704955.\n",
      "[I 2025-06-18 20:03:34,680] Trial 15 finished with value: -0.9932653905883733 and parameters: {'iterations': 193, 'learning_rate': 0.08982290950094239, 'depth': 3, 'l2_leaf_reg': 1.653733032749862}. Best is trial 15 with value: -0.9932653905883733.\n",
      "[I 2025-06-18 20:03:39,519] Trial 16 finished with value: -0.9922498193077043 and parameters: {'iterations': 199, 'learning_rate': 0.10626914827061004, 'depth': 5, 'l2_leaf_reg': 0.45655940454458455}. Best is trial 15 with value: -0.9932653905883733.\n",
      "[I 2025-06-18 20:03:44,598] Trial 17 finished with value: -0.9913277880332864 and parameters: {'iterations': 188, 'learning_rate': 0.04761340717365335, 'depth': 4, 'l2_leaf_reg': 2.6801197921555326}. Best is trial 15 with value: -0.9932653905883733.\n",
      "[I 2025-06-18 20:03:53,604] Trial 18 finished with value: -0.9851089061767464 and parameters: {'iterations': 182, 'learning_rate': 0.02868563274992415, 'depth': 6, 'l2_leaf_reg': 0.7342859160753961}. Best is trial 15 with value: -0.9932653905883733.\n",
      "[I 2025-06-18 20:03:57,791] Trial 19 finished with value: -0.9925779491912798 and parameters: {'iterations': 152, 'learning_rate': 0.09705769787157263, 'depth': 3, 'l2_leaf_reg': 0.17704937612248448}. Best is trial 15 with value: -0.9932653905883733.\n",
      "[I 2025-06-18 20:03:58,860] A new study created in memory with name: no-name-d7b115c9-821c-46c5-aefa-657e5e4151fb\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:05:48,000] Trial 0 finished with value: -0.9447166940146898 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 2.9380279387035334e-05, 'learning_rate_init': 0.00020511104188433984}. Best is trial 0 with value: -0.9447166940146898.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:05:49,387] Trial 1 finished with value: -0.9438103414596031 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.1527987128232396e-05, 'learning_rate_init': 0.008706020878304856}. Best is trial 0 with value: -0.9447166940146898.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:05:56,996] Trial 2 finished with value: -0.952029125644632 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 8.17949947521167e-05, 'learning_rate_init': 0.0011207606211860567}. Best is trial 2 with value: -0.952029125644632.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:05,579] Trial 3 finished with value: -0.9381540670417253 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 7.52374288453485e-05, 'learning_rate_init': 0.0005404103854647331}. Best is trial 2 with value: -0.952029125644632.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:34,567] Trial 4 finished with value: -0.9355602877402719 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0005987474910461401, 'learning_rate_init': 0.0001238513729886094}. Best is trial 2 with value: -0.952029125644632.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:36,334] Trial 5 finished with value: -0.9445599507735583 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00788671412999049, 'learning_rate_init': 0.004138040112561018}. Best is trial 2 with value: -0.952029125644632.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:41,583] Trial 6 finished with value: -0.944341503555243 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 2.32335035153901e-05, 'learning_rate_init': 0.0009780337016659412}. Best is trial 2 with value: -0.952029125644632.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:48,895] Trial 7 finished with value: -0.9502792575011721 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 8.612579192594876e-05, 'learning_rate_init': 0.001096821720752952}. Best is trial 2 with value: -0.952029125644632.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:50,786] Trial 8 finished with value: -0.9448414986716674 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.006584106160121612, 'learning_rate_init': 0.006161049539380964}. Best is trial 2 with value: -0.952029125644632.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:07:04,467] Trial 9 finished with value: -0.9474664644866385 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.3667272915456215e-05, 'learning_rate_init': 0.0004473636174621269}. Best is trial 2 with value: -0.952029125644632.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:07:08,212] Trial 10 finished with value: -0.9506231149398344 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0007619408233517919, 'learning_rate_init': 0.0024673775376624486}. Best is trial 2 with value: -0.952029125644632.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:07:11,893] Trial 11 finished with value: -0.9451852828566963 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0006733230478395729, 'learning_rate_init': 0.0024015639024822476}. Best is trial 2 with value: -0.952029125644632.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:07:16,166] Trial 12 finished with value: -0.955341835638381 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0017870856762200685, 'learning_rate_init': 0.0023840599245347404}. Best is trial 12 with value: -0.955341835638381.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:07:21,969] Trial 13 finished with value: -0.9496542770354743 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0024860204341552628, 'learning_rate_init': 0.001558994934408997}. Best is trial 12 with value: -0.955341835638381.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:07:36,835] Trial 14 finished with value: -0.9514357809814034 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.00018681916916591775, 'learning_rate_init': 0.0005988751231170377}. Best is trial 12 with value: -0.955341835638381.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:07:40,867] Trial 15 finished with value: -0.9527793649398344 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0018676607536673739, 'learning_rate_init': 0.0031337188565170697}. Best is trial 12 with value: -0.955341835638381.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:07:43,731] Trial 16 finished with value: -0.9419978023909985 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.002374652093757076, 'learning_rate_init': 0.0037317928236298556}. Best is trial 12 with value: -0.955341835638381.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:07:49,321] Trial 17 finished with value: -0.9569359274886701 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.002065344154282732, 'learning_rate_init': 0.002382865858231569}. Best is trial 17 with value: -0.9569359274886701.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:08:37,870] Trial 18 finished with value: -0.9513106442412879 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.003696713587651032, 'learning_rate_init': 0.0015600099204517103}. Best is trial 17 with value: -0.9569359274886701.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:08:40,351] Trial 19 finished with value: -0.9484039742537897 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0012277214111847529, 'learning_rate_init': 0.005706671509436571}. Best is trial 17 with value: -0.9569359274886701.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Оптимизация для is_CC50_above_median (Manual Aggregated):   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:10:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6025484\ttotal: 5.4ms\tremaining: 982ms\n",
      "1:\tlearn: 0.5357384\ttotal: 10.9ms\tremaining: 986ms\n",
      "2:\tlearn: 0.4866905\ttotal: 16.7ms\tremaining: 999ms\n",
      "3:\tlearn: 0.4460188\ttotal: 23.3ms\tremaining: 1.04s\n",
      "4:\tlearn: 0.4203270\ttotal: 28.3ms\tremaining: 1.01s\n",
      "5:\tlearn: 0.4073395\ttotal: 33.4ms\tremaining: 985ms\n",
      "6:\tlearn: 0.3722189\ttotal: 39.8ms\tremaining: 999ms\n",
      "7:\tlearn: 0.3591585\ttotal: 44.3ms\tremaining: 968ms\n",
      "8:\tlearn: 0.3386794\ttotal: 49.7ms\tremaining: 960ms\n",
      "9:\tlearn: 0.3307999\ttotal: 56.8ms\tremaining: 983ms\n",
      "10:\tlearn: 0.3169716\ttotal: 61.2ms\tremaining: 958ms\n",
      "11:\tlearn: 0.3053442\ttotal: 66.4ms\tremaining: 947ms\n",
      "12:\tlearn: 0.2919820\ttotal: 72.8ms\tremaining: 951ms\n",
      "13:\tlearn: 0.2750235\ttotal: 75.9ms\tremaining: 916ms\n",
      "14:\tlearn: 0.2702600\ttotal: 79.2ms\tremaining: 887ms\n",
      "15:\tlearn: 0.2665067\ttotal: 82.9ms\tremaining: 866ms\n",
      "16:\tlearn: 0.2565324\ttotal: 88.8ms\tremaining: 867ms\n",
      "17:\tlearn: 0.2512708\ttotal: 92.8ms\tremaining: 850ms\n",
      "18:\tlearn: 0.2456895\ttotal: 96.6ms\tremaining: 833ms\n",
      "19:\tlearn: 0.2382681\ttotal: 103ms\tremaining: 837ms\n",
      "20:\tlearn: 0.2326615\ttotal: 107ms\tremaining: 829ms\n",
      "21:\tlearn: 0.2314092\ttotal: 113ms\tremaining: 826ms\n",
      "22:\tlearn: 0.2292064\ttotal: 118ms\tremaining: 822ms\n",
      "23:\tlearn: 0.2247042\ttotal: 122ms\tremaining: 811ms\n",
      "24:\tlearn: 0.2165343\ttotal: 127ms\tremaining: 800ms\n",
      "25:\tlearn: 0.2079304\ttotal: 130ms\tremaining: 786ms\n",
      "26:\tlearn: 0.2048332\ttotal: 134ms\tremaining: 775ms\n",
      "27:\tlearn: 0.2029930\ttotal: 139ms\tremaining: 770ms\n",
      "28:\tlearn: 0.2009804\ttotal: 145ms\tremaining: 768ms\n",
      "29:\tlearn: 0.1995498\ttotal: 150ms\tremaining: 763ms\n",
      "30:\tlearn: 0.1974506\ttotal: 155ms\tremaining: 758ms\n",
      "31:\tlearn: 0.1949045\ttotal: 160ms\tremaining: 755ms\n",
      "32:\tlearn: 0.1939893\ttotal: 163ms\tremaining: 742ms\n",
      "33:\tlearn: 0.1924555\ttotal: 169ms\tremaining: 742ms\n",
      "34:\tlearn: 0.1877728\ttotal: 174ms\tremaining: 737ms\n",
      "35:\tlearn: 0.1838391\ttotal: 180ms\tremaining: 735ms\n",
      "36:\tlearn: 0.1829012\ttotal: 187ms\tremaining: 736ms\n",
      "37:\tlearn: 0.1776390\ttotal: 193ms\tremaining: 737ms\n",
      "38:\tlearn: 0.1761729\ttotal: 202ms\tremaining: 744ms\n",
      "39:\tlearn: 0.1746922\ttotal: 207ms\tremaining: 741ms\n",
      "40:\tlearn: 0.1735742\ttotal: 214ms\tremaining: 743ms\n",
      "41:\tlearn: 0.1716194\ttotal: 219ms\tremaining: 736ms\n",
      "42:\tlearn: 0.1655844\ttotal: 225ms\tremaining: 732ms\n",
      "43:\tlearn: 0.1644704\ttotal: 229ms\tremaining: 725ms\n",
      "44:\tlearn: 0.1578136\ttotal: 234ms\tremaining: 718ms\n",
      "45:\tlearn: 0.1545091\ttotal: 238ms\tremaining: 708ms\n",
      "46:\tlearn: 0.1525808\ttotal: 243ms\tremaining: 702ms\n",
      "47:\tlearn: 0.1507377\ttotal: 249ms\tremaining: 701ms\n",
      "48:\tlearn: 0.1476043\ttotal: 255ms\tremaining: 697ms\n",
      "49:\tlearn: 0.1455767\ttotal: 262ms\tremaining: 697ms\n",
      "50:\tlearn: 0.1424547\ttotal: 268ms\tremaining: 693ms\n",
      "51:\tlearn: 0.1420947\ttotal: 273ms\tremaining: 688ms\n",
      "52:\tlearn: 0.1377687\ttotal: 279ms\tremaining: 684ms\n",
      "53:\tlearn: 0.1360827\ttotal: 286ms\tremaining: 684ms\n",
      "54:\tlearn: 0.1314697\ttotal: 291ms\tremaining: 678ms\n",
      "55:\tlearn: 0.1300189\ttotal: 298ms\tremaining: 676ms\n",
      "56:\tlearn: 0.1292289\ttotal: 305ms\tremaining: 674ms\n",
      "57:\tlearn: 0.1286612\ttotal: 312ms\tremaining: 671ms\n",
      "58:\tlearn: 0.1274275\ttotal: 318ms\tremaining: 668ms\n",
      "59:\tlearn: 0.1263742\ttotal: 323ms\tremaining: 663ms\n",
      "60:\tlearn: 0.1242010\ttotal: 330ms\tremaining: 660ms\n",
      "61:\tlearn: 0.1218673\ttotal: 335ms\tremaining: 654ms\n",
      "62:\tlearn: 0.1209558\ttotal: 342ms\tremaining: 651ms\n",
      "63:\tlearn: 0.1175902\ttotal: 348ms\tremaining: 647ms\n",
      "64:\tlearn: 0.1133072\ttotal: 353ms\tremaining: 640ms\n",
      "65:\tlearn: 0.1128909\ttotal: 359ms\tremaining: 637ms\n",
      "66:\tlearn: 0.1085244\ttotal: 363ms\tremaining: 629ms\n",
      "67:\tlearn: 0.1077520\ttotal: 369ms\tremaining: 625ms\n",
      "68:\tlearn: 0.1070439\ttotal: 377ms\tremaining: 622ms\n",
      "69:\tlearn: 0.1048942\ttotal: 383ms\tremaining: 618ms\n",
      "70:\tlearn: 0.1041161\ttotal: 390ms\tremaining: 615ms\n",
      "71:\tlearn: 0.1013410\ttotal: 394ms\tremaining: 607ms\n",
      "72:\tlearn: 0.0984007\ttotal: 400ms\tremaining: 603ms\n",
      "73:\tlearn: 0.0969218\ttotal: 407ms\tremaining: 599ms\n",
      "74:\tlearn: 0.0959288\ttotal: 410ms\tremaining: 591ms\n",
      "75:\tlearn: 0.0916978\ttotal: 416ms\tremaining: 586ms\n",
      "76:\tlearn: 0.0903398\ttotal: 423ms\tremaining: 582ms\n",
      "77:\tlearn: 0.0895918\ttotal: 428ms\tremaining: 576ms\n",
      "78:\tlearn: 0.0885206\ttotal: 434ms\tremaining: 571ms\n",
      "79:\tlearn: 0.0854807\ttotal: 439ms\tremaining: 565ms\n",
      "80:\tlearn: 0.0834836\ttotal: 444ms\tremaining: 559ms\n",
      "81:\tlearn: 0.0819987\ttotal: 450ms\tremaining: 555ms\n",
      "82:\tlearn: 0.0808443\ttotal: 454ms\tremaining: 547ms\n",
      "83:\tlearn: 0.0800633\ttotal: 460ms\tremaining: 542ms\n",
      "84:\tlearn: 0.0773409\ttotal: 466ms\tremaining: 538ms\n",
      "85:\tlearn: 0.0764467\ttotal: 470ms\tremaining: 530ms\n",
      "86:\tlearn: 0.0761837\ttotal: 475ms\tremaining: 524ms\n",
      "87:\tlearn: 0.0738545\ttotal: 481ms\tremaining: 519ms\n",
      "88:\tlearn: 0.0713445\ttotal: 485ms\tremaining: 512ms\n",
      "89:\tlearn: 0.0705834\ttotal: 491ms\tremaining: 507ms\n",
      "90:\tlearn: 0.0692179\ttotal: 497ms\tremaining: 502ms\n",
      "91:\tlearn: 0.0664950\ttotal: 500ms\tremaining: 494ms\n",
      "92:\tlearn: 0.0659863\ttotal: 506ms\tremaining: 489ms\n",
      "93:\tlearn: 0.0652609\ttotal: 511ms\tremaining: 484ms\n",
      "94:\tlearn: 0.0631772\ttotal: 514ms\tremaining: 477ms\n",
      "95:\tlearn: 0.0629383\ttotal: 519ms\tremaining: 471ms\n",
      "96:\tlearn: 0.0609842\ttotal: 525ms\tremaining: 466ms\n",
      "97:\tlearn: 0.0604546\ttotal: 529ms\tremaining: 459ms\n",
      "98:\tlearn: 0.0591789\ttotal: 535ms\tremaining: 454ms\n",
      "99:\tlearn: 0.0588856\ttotal: 541ms\tremaining: 449ms\n",
      "100:\tlearn: 0.0565150\ttotal: 545ms\tremaining: 443ms\n",
      "101:\tlearn: 0.0563155\ttotal: 552ms\tremaining: 438ms\n",
      "102:\tlearn: 0.0549664\ttotal: 557ms\tremaining: 432ms\n",
      "103:\tlearn: 0.0544797\ttotal: 562ms\tremaining: 427ms\n",
      "104:\tlearn: 0.0542539\ttotal: 569ms\tremaining: 423ms\n",
      "105:\tlearn: 0.0536866\ttotal: 573ms\tremaining: 416ms\n",
      "106:\tlearn: 0.0532197\ttotal: 579ms\tremaining: 411ms\n",
      "107:\tlearn: 0.0516032\ttotal: 585ms\tremaining: 406ms\n",
      "108:\tlearn: 0.0515503\ttotal: 589ms\tremaining: 400ms\n",
      "109:\tlearn: 0.0509570\ttotal: 595ms\tremaining: 395ms\n",
      "110:\tlearn: 0.0494561\ttotal: 600ms\tremaining: 389ms\n",
      "111:\tlearn: 0.0486581\ttotal: 604ms\tremaining: 383ms\n",
      "112:\tlearn: 0.0478482\ttotal: 609ms\tremaining: 377ms\n",
      "113:\tlearn: 0.0476048\ttotal: 614ms\tremaining: 372ms\n",
      "114:\tlearn: 0.0472059\ttotal: 619ms\tremaining: 366ms\n",
      "115:\tlearn: 0.0464605\ttotal: 625ms\tremaining: 361ms\n",
      "116:\tlearn: 0.0462075\ttotal: 630ms\tremaining: 356ms\n",
      "117:\tlearn: 0.0461547\ttotal: 636ms\tremaining: 350ms\n",
      "118:\tlearn: 0.0459384\ttotal: 642ms\tremaining: 345ms\n",
      "119:\tlearn: 0.0447085\ttotal: 647ms\tremaining: 339ms\n",
      "120:\tlearn: 0.0432479\ttotal: 652ms\tremaining: 334ms\n",
      "121:\tlearn: 0.0417955\ttotal: 659ms\tremaining: 329ms\n",
      "122:\tlearn: 0.0413700\ttotal: 663ms\tremaining: 324ms\n",
      "123:\tlearn: 0.0396782\ttotal: 670ms\tremaining: 319ms\n",
      "124:\tlearn: 0.0395253\ttotal: 675ms\tremaining: 313ms\n",
      "125:\tlearn: 0.0391689\ttotal: 680ms\tremaining: 307ms\n",
      "126:\tlearn: 0.0391476\ttotal: 686ms\tremaining: 303ms\n",
      "127:\tlearn: 0.0382110\ttotal: 692ms\tremaining: 297ms\n",
      "128:\tlearn: 0.0367475\ttotal: 698ms\tremaining: 292ms\n",
      "129:\tlearn: 0.0366729\ttotal: 704ms\tremaining: 287ms\n",
      "130:\tlearn: 0.0363273\ttotal: 709ms\tremaining: 281ms\n",
      "131:\tlearn: 0.0362327\ttotal: 715ms\tremaining: 276ms\n",
      "132:\tlearn: 0.0347882\ttotal: 720ms\tremaining: 271ms\n",
      "133:\tlearn: 0.0344441\ttotal: 724ms\tremaining: 265ms\n",
      "134:\tlearn: 0.0342974\ttotal: 731ms\tremaining: 260ms\n",
      "135:\tlearn: 0.0341958\ttotal: 735ms\tremaining: 254ms\n",
      "136:\tlearn: 0.0332955\ttotal: 741ms\tremaining: 249ms\n",
      "137:\tlearn: 0.0330384\ttotal: 747ms\tremaining: 244ms\n",
      "138:\tlearn: 0.0328493\ttotal: 752ms\tremaining: 238ms\n",
      "139:\tlearn: 0.0321911\ttotal: 758ms\tremaining: 233ms\n",
      "140:\tlearn: 0.0320153\ttotal: 764ms\tremaining: 228ms\n",
      "141:\tlearn: 0.0318650\ttotal: 768ms\tremaining: 222ms\n",
      "142:\tlearn: 0.0309855\ttotal: 775ms\tremaining: 217ms\n",
      "143:\tlearn: 0.0304257\ttotal: 780ms\tremaining: 211ms\n",
      "144:\tlearn: 0.0303271\ttotal: 785ms\tremaining: 206ms\n",
      "145:\tlearn: 0.0297609\ttotal: 791ms\tremaining: 200ms\n",
      "146:\tlearn: 0.0288201\ttotal: 795ms\tremaining: 195ms\n",
      "147:\tlearn: 0.0284719\ttotal: 801ms\tremaining: 189ms\n",
      "148:\tlearn: 0.0283349\ttotal: 807ms\tremaining: 184ms\n",
      "149:\tlearn: 0.0281262\ttotal: 810ms\tremaining: 178ms\n",
      "150:\tlearn: 0.0280406\ttotal: 815ms\tremaining: 173ms\n",
      "151:\tlearn: 0.0273980\ttotal: 821ms\tremaining: 168ms\n",
      "152:\tlearn: 0.0272932\ttotal: 825ms\tremaining: 162ms\n",
      "153:\tlearn: 0.0265020\ttotal: 831ms\tremaining: 157ms\n",
      "154:\tlearn: 0.0257397\ttotal: 837ms\tremaining: 151ms\n",
      "155:\tlearn: 0.0254984\ttotal: 842ms\tremaining: 146ms\n",
      "156:\tlearn: 0.0247224\ttotal: 848ms\tremaining: 140ms\n",
      "157:\tlearn: 0.0246544\ttotal: 855ms\tremaining: 135ms\n",
      "158:\tlearn: 0.0238623\ttotal: 861ms\tremaining: 130ms\n",
      "159:\tlearn: 0.0237571\ttotal: 867ms\tremaining: 125ms\n",
      "160:\tlearn: 0.0236579\ttotal: 871ms\tremaining: 119ms\n",
      "161:\tlearn: 0.0232470\ttotal: 877ms\tremaining: 114ms\n",
      "162:\tlearn: 0.0228038\ttotal: 883ms\tremaining: 108ms\n",
      "163:\tlearn: 0.0227337\ttotal: 888ms\tremaining: 103ms\n",
      "164:\tlearn: 0.0226310\ttotal: 894ms\tremaining: 97.5ms\n",
      "165:\tlearn: 0.0225271\ttotal: 898ms\tremaining: 92ms\n",
      "166:\tlearn: 0.0224678\ttotal: 903ms\tremaining: 86.5ms\n",
      "167:\tlearn: 0.0221225\ttotal: 909ms\tremaining: 81.2ms\n",
      "168:\tlearn: 0.0220777\ttotal: 913ms\tremaining: 75.6ms\n",
      "169:\tlearn: 0.0214188\ttotal: 918ms\tremaining: 70.2ms\n",
      "170:\tlearn: 0.0212780\ttotal: 924ms\tremaining: 64.8ms\n",
      "171:\tlearn: 0.0211318\ttotal: 929ms\tremaining: 59.4ms\n",
      "172:\tlearn: 0.0208757\ttotal: 935ms\tremaining: 54ms\n",
      "173:\tlearn: 0.0204759\ttotal: 942ms\tremaining: 48.7ms\n",
      "174:\tlearn: 0.0204592\ttotal: 945ms\tremaining: 43.2ms\n",
      "175:\tlearn: 0.0201029\ttotal: 951ms\tremaining: 37.8ms\n",
      "176:\tlearn: 0.0199610\ttotal: 958ms\tremaining: 32.5ms\n",
      "177:\tlearn: 0.0199477\ttotal: 963ms\tremaining: 27ms\n",
      "178:\tlearn: 0.0199209\ttotal: 970ms\tremaining: 21.7ms\n",
      "179:\tlearn: 0.0198011\ttotal: 974ms\tremaining: 16.2ms\n",
      "180:\tlearn: 0.0195702\ttotal: 978ms\tremaining: 10.8ms\n",
      "181:\tlearn: 0.0195301\ttotal: 984ms\tremaining: 5.41ms\n",
      "182:\tlearn: 0.0193644\ttotal: 989ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:15:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6015724\ttotal: 5.21ms\tremaining: 776ms\n",
      "1:\tlearn: 0.5642385\ttotal: 10.8ms\tremaining: 798ms\n",
      "2:\tlearn: 0.5134264\ttotal: 14ms\tremaining: 686ms\n",
      "3:\tlearn: 0.4886564\ttotal: 17.9ms\tremaining: 654ms\n",
      "4:\tlearn: 0.4567461\ttotal: 22.5ms\tremaining: 654ms\n",
      "5:\tlearn: 0.4468541\ttotal: 28.4ms\tremaining: 681ms\n",
      "6:\tlearn: 0.4082446\ttotal: 32.1ms\tremaining: 656ms\n",
      "7:\tlearn: 0.3979180\ttotal: 35.6ms\tremaining: 633ms\n",
      "8:\tlearn: 0.3746062\ttotal: 39.1ms\tremaining: 613ms\n",
      "9:\tlearn: 0.3677118\ttotal: 44.7ms\tremaining: 626ms\n",
      "10:\tlearn: 0.3435497\ttotal: 48.6ms\tremaining: 615ms\n",
      "11:\tlearn: 0.3381786\ttotal: 53.1ms\tremaining: 611ms\n",
      "12:\tlearn: 0.3198582\ttotal: 57.4ms\tremaining: 605ms\n",
      "13:\tlearn: 0.3080691\ttotal: 62.3ms\tremaining: 605ms\n",
      "14:\tlearn: 0.3040418\ttotal: 65.5ms\tremaining: 589ms\n",
      "15:\tlearn: 0.2959649\ttotal: 69.5ms\tremaining: 582ms\n",
      "16:\tlearn: 0.2788510\ttotal: 75.7ms\tremaining: 592ms\n",
      "17:\tlearn: 0.2739593\ttotal: 78.6ms\tremaining: 576ms\n",
      "18:\tlearn: 0.2721010\ttotal: 82.3ms\tremaining: 567ms\n",
      "19:\tlearn: 0.2669930\ttotal: 85.6ms\tremaining: 557ms\n",
      "20:\tlearn: 0.2640534\ttotal: 89.9ms\tremaining: 552ms\n",
      "21:\tlearn: 0.2555112\ttotal: 93.2ms\tremaining: 542ms\n",
      "22:\tlearn: 0.2435141\ttotal: 98.3ms\tremaining: 543ms\n",
      "23:\tlearn: 0.2405462\ttotal: 103ms\tremaining: 539ms\n",
      "24:\tlearn: 0.2350310\ttotal: 106ms\tremaining: 529ms\n",
      "25:\tlearn: 0.2334864\ttotal: 109ms\tremaining: 521ms\n",
      "26:\tlearn: 0.2313048\ttotal: 113ms\tremaining: 513ms\n",
      "27:\tlearn: 0.2252445\ttotal: 116ms\tremaining: 507ms\n",
      "28:\tlearn: 0.2148414\ttotal: 120ms\tremaining: 502ms\n",
      "29:\tlearn: 0.2099796\ttotal: 123ms\tremaining: 494ms\n",
      "30:\tlearn: 0.2078335\ttotal: 128ms\tremaining: 491ms\n",
      "31:\tlearn: 0.2066506\ttotal: 131ms\tremaining: 483ms\n",
      "32:\tlearn: 0.2034928\ttotal: 135ms\tremaining: 478ms\n",
      "33:\tlearn: 0.2015175\ttotal: 138ms\tremaining: 469ms\n",
      "34:\tlearn: 0.1956166\ttotal: 140ms\tremaining: 461ms\n",
      "35:\tlearn: 0.1941690\ttotal: 146ms\tremaining: 461ms\n",
      "36:\tlearn: 0.1879777\ttotal: 150ms\tremaining: 457ms\n",
      "37:\tlearn: 0.1866605\ttotal: 153ms\tremaining: 452ms\n",
      "38:\tlearn: 0.1860973\ttotal: 157ms\tremaining: 447ms\n",
      "39:\tlearn: 0.1839998\ttotal: 162ms\tremaining: 446ms\n",
      "40:\tlearn: 0.1787744\ttotal: 166ms\tremaining: 441ms\n",
      "41:\tlearn: 0.1737267\ttotal: 171ms\tremaining: 439ms\n",
      "42:\tlearn: 0.1729824\ttotal: 176ms\tremaining: 437ms\n",
      "43:\tlearn: 0.1717072\ttotal: 180ms\tremaining: 434ms\n",
      "44:\tlearn: 0.1715934\ttotal: 184ms\tremaining: 429ms\n",
      "45:\tlearn: 0.1669745\ttotal: 188ms\tremaining: 425ms\n",
      "46:\tlearn: 0.1593278\ttotal: 192ms\tremaining: 420ms\n",
      "47:\tlearn: 0.1586459\ttotal: 197ms\tremaining: 419ms\n",
      "48:\tlearn: 0.1577291\ttotal: 202ms\tremaining: 417ms\n",
      "49:\tlearn: 0.1564960\ttotal: 207ms\tremaining: 415ms\n",
      "50:\tlearn: 0.1558722\ttotal: 211ms\tremaining: 410ms\n",
      "51:\tlearn: 0.1547256\ttotal: 219ms\tremaining: 413ms\n",
      "52:\tlearn: 0.1538607\ttotal: 223ms\tremaining: 408ms\n",
      "53:\tlearn: 0.1516199\ttotal: 228ms\tremaining: 406ms\n",
      "54:\tlearn: 0.1508827\ttotal: 232ms\tremaining: 401ms\n",
      "55:\tlearn: 0.1501501\ttotal: 237ms\tremaining: 397ms\n",
      "56:\tlearn: 0.1484561\ttotal: 241ms\tremaining: 393ms\n",
      "57:\tlearn: 0.1473093\ttotal: 245ms\tremaining: 388ms\n",
      "58:\tlearn: 0.1458716\ttotal: 249ms\tremaining: 384ms\n",
      "59:\tlearn: 0.1449708\ttotal: 253ms\tremaining: 380ms\n",
      "60:\tlearn: 0.1410869\ttotal: 257ms\tremaining: 375ms\n",
      "61:\tlearn: 0.1404285\ttotal: 261ms\tremaining: 371ms\n",
      "62:\tlearn: 0.1382413\ttotal: 266ms\tremaining: 367ms\n",
      "63:\tlearn: 0.1348668\ttotal: 269ms\tremaining: 362ms\n",
      "64:\tlearn: 0.1342824\ttotal: 275ms\tremaining: 359ms\n",
      "65:\tlearn: 0.1337591\ttotal: 279ms\tremaining: 355ms\n",
      "66:\tlearn: 0.1293761\ttotal: 284ms\tremaining: 352ms\n",
      "67:\tlearn: 0.1283376\ttotal: 288ms\tremaining: 348ms\n",
      "68:\tlearn: 0.1244196\ttotal: 292ms\tremaining: 343ms\n",
      "69:\tlearn: 0.1218494\ttotal: 295ms\tremaining: 337ms\n",
      "70:\tlearn: 0.1212239\ttotal: 299ms\tremaining: 332ms\n",
      "71:\tlearn: 0.1206441\ttotal: 302ms\tremaining: 327ms\n",
      "72:\tlearn: 0.1159712\ttotal: 306ms\tremaining: 323ms\n",
      "73:\tlearn: 0.1151722\ttotal: 310ms\tremaining: 318ms\n",
      "74:\tlearn: 0.1118903\ttotal: 314ms\tremaining: 314ms\n",
      "75:\tlearn: 0.1114763\ttotal: 318ms\tremaining: 310ms\n",
      "76:\tlearn: 0.1110181\ttotal: 323ms\tremaining: 306ms\n",
      "77:\tlearn: 0.1081926\ttotal: 327ms\tremaining: 302ms\n",
      "78:\tlearn: 0.1065882\ttotal: 332ms\tremaining: 299ms\n",
      "79:\tlearn: 0.1018269\ttotal: 337ms\tremaining: 294ms\n",
      "80:\tlearn: 0.1010908\ttotal: 341ms\tremaining: 290ms\n",
      "81:\tlearn: 0.1004524\ttotal: 347ms\tremaining: 287ms\n",
      "82:\tlearn: 0.0997691\ttotal: 352ms\tremaining: 284ms\n",
      "83:\tlearn: 0.0973701\ttotal: 355ms\tremaining: 279ms\n",
      "84:\tlearn: 0.0936140\ttotal: 359ms\tremaining: 274ms\n",
      "85:\tlearn: 0.0923698\ttotal: 364ms\tremaining: 271ms\n",
      "86:\tlearn: 0.0921453\ttotal: 367ms\tremaining: 266ms\n",
      "87:\tlearn: 0.0909428\ttotal: 372ms\tremaining: 262ms\n",
      "88:\tlearn: 0.0897386\ttotal: 376ms\tremaining: 258ms\n",
      "89:\tlearn: 0.0874169\ttotal: 381ms\tremaining: 254ms\n",
      "90:\tlearn: 0.0850065\ttotal: 385ms\tremaining: 250ms\n",
      "91:\tlearn: 0.0843579\ttotal: 388ms\tremaining: 245ms\n",
      "92:\tlearn: 0.0838924\ttotal: 392ms\tremaining: 240ms\n",
      "93:\tlearn: 0.0818735\ttotal: 397ms\tremaining: 236ms\n",
      "94:\tlearn: 0.0793867\ttotal: 401ms\tremaining: 232ms\n",
      "95:\tlearn: 0.0788543\ttotal: 406ms\tremaining: 228ms\n",
      "96:\tlearn: 0.0778442\ttotal: 409ms\tremaining: 223ms\n",
      "97:\tlearn: 0.0770778\ttotal: 412ms\tremaining: 219ms\n",
      "98:\tlearn: 0.0763163\ttotal: 417ms\tremaining: 215ms\n",
      "99:\tlearn: 0.0749549\ttotal: 422ms\tremaining: 211ms\n",
      "100:\tlearn: 0.0730204\ttotal: 427ms\tremaining: 207ms\n",
      "101:\tlearn: 0.0707441\ttotal: 431ms\tremaining: 203ms\n",
      "102:\tlearn: 0.0701416\ttotal: 437ms\tremaining: 200ms\n",
      "103:\tlearn: 0.0695104\ttotal: 441ms\tremaining: 195ms\n",
      "104:\tlearn: 0.0688498\ttotal: 445ms\tremaining: 191ms\n",
      "105:\tlearn: 0.0678764\ttotal: 450ms\tremaining: 187ms\n",
      "106:\tlearn: 0.0658813\ttotal: 455ms\tremaining: 183ms\n",
      "107:\tlearn: 0.0656042\ttotal: 459ms\tremaining: 178ms\n",
      "108:\tlearn: 0.0651320\ttotal: 463ms\tremaining: 174ms\n",
      "109:\tlearn: 0.0648707\ttotal: 467ms\tremaining: 170ms\n",
      "110:\tlearn: 0.0632968\ttotal: 471ms\tremaining: 166ms\n",
      "111:\tlearn: 0.0627850\ttotal: 474ms\tremaining: 161ms\n",
      "112:\tlearn: 0.0625822\ttotal: 479ms\tremaining: 157ms\n",
      "113:\tlearn: 0.0608574\ttotal: 483ms\tremaining: 153ms\n",
      "114:\tlearn: 0.0606285\ttotal: 487ms\tremaining: 148ms\n",
      "115:\tlearn: 0.0602712\ttotal: 491ms\tremaining: 144ms\n",
      "116:\tlearn: 0.0596802\ttotal: 495ms\tremaining: 140ms\n",
      "117:\tlearn: 0.0593948\ttotal: 501ms\tremaining: 136ms\n",
      "118:\tlearn: 0.0585167\ttotal: 505ms\tremaining: 132ms\n",
      "119:\tlearn: 0.0581081\ttotal: 510ms\tremaining: 127ms\n",
      "120:\tlearn: 0.0572469\ttotal: 514ms\tremaining: 123ms\n",
      "121:\tlearn: 0.0559222\ttotal: 517ms\tremaining: 119ms\n",
      "122:\tlearn: 0.0539982\ttotal: 523ms\tremaining: 115ms\n",
      "123:\tlearn: 0.0521204\ttotal: 527ms\tremaining: 111ms\n",
      "124:\tlearn: 0.0518144\ttotal: 531ms\tremaining: 106ms\n",
      "125:\tlearn: 0.0515579\ttotal: 537ms\tremaining: 102ms\n",
      "126:\tlearn: 0.0501273\ttotal: 542ms\tremaining: 98.2ms\n",
      "127:\tlearn: 0.0491177\ttotal: 546ms\tremaining: 93.8ms\n",
      "128:\tlearn: 0.0488707\ttotal: 549ms\tremaining: 89.4ms\n",
      "129:\tlearn: 0.0486688\ttotal: 555ms\tremaining: 85.3ms\n",
      "130:\tlearn: 0.0483895\ttotal: 559ms\tremaining: 81.1ms\n",
      "131:\tlearn: 0.0482811\ttotal: 563ms\tremaining: 76.8ms\n",
      "132:\tlearn: 0.0479298\ttotal: 567ms\tremaining: 72.5ms\n",
      "133:\tlearn: 0.0477889\ttotal: 572ms\tremaining: 68.3ms\n",
      "134:\tlearn: 0.0473860\ttotal: 576ms\tremaining: 64ms\n",
      "135:\tlearn: 0.0460133\ttotal: 580ms\tremaining: 59.7ms\n",
      "136:\tlearn: 0.0458204\ttotal: 584ms\tremaining: 55.4ms\n",
      "137:\tlearn: 0.0455036\ttotal: 588ms\tremaining: 51.1ms\n",
      "138:\tlearn: 0.0449079\ttotal: 591ms\tremaining: 46.8ms\n",
      "139:\tlearn: 0.0447473\ttotal: 596ms\tremaining: 42.6ms\n",
      "140:\tlearn: 0.0443296\ttotal: 600ms\tremaining: 38.3ms\n",
      "141:\tlearn: 0.0436327\ttotal: 605ms\tremaining: 34.1ms\n",
      "142:\tlearn: 0.0435888\ttotal: 611ms\tremaining: 29.9ms\n",
      "143:\tlearn: 0.0434528\ttotal: 616ms\tremaining: 25.7ms\n",
      "144:\tlearn: 0.0431432\ttotal: 620ms\tremaining: 21.4ms\n",
      "145:\tlearn: 0.0430089\ttotal: 623ms\tremaining: 17.1ms\n",
      "146:\tlearn: 0.0428422\ttotal: 628ms\tremaining: 12.8ms\n",
      "147:\tlearn: 0.0420921\ttotal: 632ms\tremaining: 8.54ms\n",
      "148:\tlearn: 0.0419718\ttotal: 636ms\tremaining: 4.27ms\n",
      "149:\tlearn: 0.0419324\ttotal: 641ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-06-18 20:16:11,856] A new study created in memory with name: no-name-00158753-3d31-418a-be18-bf83f40aa7dd\n",
      "[I 2025-06-18 20:16:12,741] Trial 0 finished with value: -0.9851870848960775 and parameters: {'C': 0.5611516415334505, 'penalty': 'l1'}. Best is trial 0 with value: -0.9851870848960775.\n",
      "[I 2025-06-18 20:16:13,423] Trial 1 finished with value: -0.9828118846694796 and parameters: {'C': 1.5751320499779735, 'penalty': 'l1'}. Best is trial 0 with value: -0.9851870848960775.\n",
      "[I 2025-06-18 20:16:13,602] Trial 2 finished with value: -0.9851558983825598 and parameters: {'C': 0.13066739238053282, 'penalty': 'l1'}. Best is trial 0 with value: -0.9851870848960775.\n",
      "[I 2025-06-18 20:16:14,017] Trial 3 finished with value: -0.9725302049148304 and parameters: {'C': 2.607024758370768, 'penalty': 'l2'}. Best is trial 0 with value: -0.9851870848960775.\n",
      "[I 2025-06-18 20:16:14,916] Trial 4 finished with value: -0.9755927684013127 and parameters: {'C': 4.622589001020832, 'penalty': 'l1'}. Best is trial 0 with value: -0.9851870848960775.\n",
      "[I 2025-06-18 20:16:17,187] Trial 5 finished with value: -0.9696550925925926 and parameters: {'C': 0.2327067708383781, 'penalty': 'l2'}. Best is trial 0 with value: -0.9851870848960775.\n",
      "[I 2025-06-18 20:16:20,287] Trial 6 finished with value: -0.9734364939834348 and parameters: {'C': 0.7309539835912913, 'penalty': 'l2'}. Best is trial 0 with value: -0.9851870848960775.\n",
      "[I 2025-06-18 20:16:20,540] Trial 7 finished with value: -0.9690925632911392 and parameters: {'C': 0.19010245319870356, 'penalty': 'l2'}. Best is trial 0 with value: -0.9851870848960775.\n",
      "[I 2025-06-18 20:16:20,791] Trial 8 finished with value: -0.9846245116424441 and parameters: {'C': 0.8168455894760165, 'penalty': 'l1'}. Best is trial 0 with value: -0.9851870848960775.\n",
      "[I 2025-06-18 20:16:21,058] Trial 9 finished with value: -0.9842807225738397 and parameters: {'C': 1.0677482709481354, 'penalty': 'l1'}. Best is trial 0 with value: -0.9851870848960775.\n",
      "[I 2025-06-18 20:16:21,221] Trial 10 finished with value: -0.9858746434989841 and parameters: {'C': 0.4194601131160366, 'penalty': 'l1'}. Best is trial 10 with value: -0.9858746434989841.\n",
      "[I 2025-06-18 20:16:21,389] Trial 11 finished with value: -0.986093408149711 and parameters: {'C': 0.39469407668392625, 'penalty': 'l1'}. Best is trial 11 with value: -0.986093408149711.\n",
      "[I 2025-06-18 20:16:21,563] Trial 12 finished with value: -0.9855308641975308 and parameters: {'C': 0.460505719895977, 'penalty': 'l1'}. Best is trial 11 with value: -0.986093408149711.\n",
      "[I 2025-06-18 20:16:21,709] Trial 13 finished with value: -0.9863121825675887 and parameters: {'C': 0.32228560396509087, 'penalty': 'l1'}. Best is trial 13 with value: -0.9863121825675887.\n",
      "[I 2025-06-18 20:16:21,876] Trial 14 finished with value: -0.9862184276840132 and parameters: {'C': 0.29294370092324007, 'penalty': 'l1'}. Best is trial 13 with value: -0.9863121825675887.\n",
      "[I 2025-06-18 20:16:21,978] Trial 15 finished with value: -0.9849371239646819 and parameters: {'C': 0.10978834055362822, 'penalty': 'l1'}. Best is trial 13 with value: -0.9863121825675887.\n",
      "[I 2025-06-18 20:16:22,130] Trial 16 finished with value: -0.9861872021018909 and parameters: {'C': 0.24255479178765083, 'penalty': 'l1'}. Best is trial 13 with value: -0.9863121825675887.\n",
      "[I 2025-06-18 20:16:22,316] Trial 17 finished with value: -0.9862184374511642 and parameters: {'C': 0.278147251863215, 'penalty': 'l1'}. Best is trial 13 with value: -0.9863121825675887.\n",
      "[I 2025-06-18 20:16:22,823] Trial 18 finished with value: -0.9697488084075637 and parameters: {'C': 6.779724890130471, 'penalty': 'l2'}. Best is trial 13 with value: -0.9863121825675887.\n",
      "[I 2025-06-18 20:16:23,135] Trial 19 finished with value: -0.9836244237380841 and parameters: {'C': 1.3491290334311543, 'penalty': 'l1'}. Best is trial 13 with value: -0.9863121825675887.\n",
      "[I 2025-06-18 20:16:23,171] A new study created in memory with name: no-name-7bdf2d90-3a4d-4a82-87e0-2fd5e31e956b\n",
      "[I 2025-06-18 20:16:26,605] Trial 0 finished with value: -0.9061064692725426 and parameters: {'n_estimators': 106, 'max_depth': 5, 'min_samples_split': 3}. Best is trial 0 with value: -0.9061064692725426.\n",
      "[I 2025-06-18 20:16:28,384] Trial 1 finished with value: -0.9076065474097514 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 1 with value: -0.9076065474097514.\n",
      "[I 2025-06-18 20:16:34,593] Trial 2 finished with value: -0.913981664615565 and parameters: {'n_estimators': 175, 'max_depth': None, 'min_samples_split': 5}. Best is trial 2 with value: -0.913981664615565.\n",
      "[I 2025-06-18 20:16:38,390] Trial 3 finished with value: -0.9163567427527738 and parameters: {'n_estimators': 115, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 3 with value: -0.9163567427527738.\n",
      "[I 2025-06-18 20:16:40,948] Trial 4 finished with value: -0.9050752778754493 and parameters: {'n_estimators': 118, 'max_depth': 5, 'min_samples_split': 2}. Best is trial 3 with value: -0.9163567427527738.\n",
      "[I 2025-06-18 20:16:44,520] Trial 5 finished with value: -0.9127317574035005 and parameters: {'n_estimators': 141, 'max_depth': None, 'min_samples_split': 7}. Best is trial 3 with value: -0.9163567427527738.\n",
      "[I 2025-06-18 20:16:46,756] Trial 6 finished with value: -0.9152316206633848 and parameters: {'n_estimators': 95, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 3 with value: -0.9163567427527738.\n",
      "[I 2025-06-18 20:16:47,815] Trial 7 finished with value: -0.9102628755469604 and parameters: {'n_estimators': 55, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 3 with value: -0.9163567427527738.\n",
      "[I 2025-06-18 20:16:50,754] Trial 8 finished with value: -0.9143724605407095 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 3 with value: -0.9163567427527738.\n",
      "[I 2025-06-18 20:16:53,030] Trial 9 finished with value: -0.9084814546218158 and parameters: {'n_estimators': 140, 'max_depth': 5, 'min_samples_split': 4}. Best is trial 3 with value: -0.9163567427527738.\n",
      "[I 2025-06-18 20:16:57,063] Trial 10 finished with value: -0.9099346284575714 and parameters: {'n_estimators': 192, 'max_depth': 15, 'min_samples_split': 2}. Best is trial 3 with value: -0.9163567427527738.\n",
      "[I 2025-06-18 20:16:58,994] Trial 11 finished with value: -0.9139660884513205 and parameters: {'n_estimators': 90, 'max_depth': 10, 'min_samples_split': 6}. Best is trial 3 with value: -0.9163567427527738.\n",
      "[I 2025-06-18 20:17:00,977] Trial 12 finished with value: -0.9167941597319894 and parameters: {'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 12 with value: -0.9167941597319894.\n",
      "[I 2025-06-18 20:17:02,651] Trial 13 finished with value: -0.9183723628691982 and parameters: {'n_estimators': 78, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 13 with value: -0.9183723628691982.\n",
      "[I 2025-06-18 20:17:04,285] Trial 14 finished with value: -0.9134192476363495 and parameters: {'n_estimators': 79, 'max_depth': 10, 'min_samples_split': 3}. Best is trial 13 with value: -0.9183723628691982.\n",
      "[I 2025-06-18 20:17:05,801] Trial 15 finished with value: -0.9187630855407095 and parameters: {'n_estimators': 70, 'max_depth': 15, 'min_samples_split': 4}. Best is trial 15 with value: -0.9187630855407095.\n",
      "[I 2025-06-18 20:17:07,311] Trial 16 finished with value: -0.9111064204367871 and parameters: {'n_estimators': 70, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 15 with value: -0.9187630855407095.\n",
      "[I 2025-06-18 20:17:08,441] Trial 17 finished with value: -0.9115910347319893 and parameters: {'n_estimators': 51, 'max_depth': 15, 'min_samples_split': 3}. Best is trial 15 with value: -0.9187630855407095.\n",
      "[I 2025-06-18 20:17:11,883] Trial 18 finished with value: -0.9159191890334428 and parameters: {'n_estimators': 155, 'max_depth': 15, 'min_samples_split': 4}. Best is trial 15 with value: -0.9187630855407095.\n",
      "[I 2025-06-18 20:17:13,547] Trial 19 finished with value: -0.9098563422995781 and parameters: {'n_estimators': 72, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 15 with value: -0.9187630855407095.\n",
      "[I 2025-06-18 20:17:13,995] A new study created in memory with name: no-name-ed089851-3a77-407e-8cce-2db348c93c87\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:15,811] Trial 0 finished with value: -0.9942497997734021 and parameters: {'n_estimators': 106, 'learning_rate': 0.13125830316209655, 'max_depth': 7, 'subsample': 0.8795975452591109}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:16,647] Trial 1 finished with value: -0.9663585130489138 and parameters: {'n_estimators': 73, 'learning_rate': 0.015256811898068502, 'max_depth': 3, 'subsample': 0.9598528437324805}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:18,238] Trial 2 finished with value: -0.993765458958431 and parameters: {'n_estimators': 140, 'learning_rate': 0.06803900745073706, 'max_depth': 3, 'subsample': 0.9909729556485982}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:20,592] Trial 3 finished with value: -0.9900308690811064 and parameters: {'n_estimators': 175, 'learning_rate': 0.01777174904859463, 'max_depth': 4, 'subsample': 0.7550213529560301}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:22,769] Trial 4 finished with value: -0.9934372704719487 and parameters: {'n_estimators': 95, 'learning_rate': 0.04141536110538596, 'max_depth': 5, 'subsample': 0.7873687420594125}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:25,601] Trial 5 finished with value: -0.9861401757110487 and parameters: {'n_estimators': 142, 'learning_rate': 0.01459007452373112, 'max_depth': 4, 'subsample': 0.8099085529881075}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:27,119] Trial 6 finished with value: -0.9934372851226755 and parameters: {'n_estimators': 118, 'learning_rate': 0.0838375512850209, 'max_depth': 4, 'subsample': 0.8542703315240835}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:30,221] Trial 7 finished with value: -0.9852807567588686 and parameters: {'n_estimators': 139, 'learning_rate': 0.011340440501807348, 'max_depth': 6, 'subsample': 0.7511572371061874}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:31,625] Trial 8 finished with value: -0.9942029638420065 and parameters: {'n_estimators': 59, 'learning_rate': 0.13060986669773664, 'max_depth': 8, 'subsample': 0.9425192044349383}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:34,073] Trial 9 finished with value: -0.9830619481559619 and parameters: {'n_estimators': 95, 'learning_rate': 0.01302780710309028, 'max_depth': 7, 'subsample': 0.8320457481218804}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:38,217] Trial 10 finished with value: -0.9941247704719489 and parameters: {'n_estimators': 192, 'learning_rate': 0.036030984219246213, 'max_depth': 8, 'subsample': 0.8919394579380205}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:39,528] Trial 11 finished with value: -0.9942497704719487 and parameters: {'n_estimators': 54, 'learning_rate': 0.11681446704286463, 'max_depth': 8, 'subsample': 0.915028891748686}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:41,115] Trial 12 finished with value: -0.9939997900062509 and parameters: {'n_estimators': 82, 'learning_rate': 0.14828432951660628, 'max_depth': 7, 'subsample': 0.885478855453852}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:42,515] Trial 13 finished with value: -0.9935935546569775 and parameters: {'n_estimators': 57, 'learning_rate': 0.09915097464555107, 'max_depth': 7, 'subsample': 0.9085942971636803}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:45,141] Trial 14 finished with value: -0.9938122997734021 and parameters: {'n_estimators': 114, 'learning_rate': 0.055753892419385366, 'max_depth': 8, 'subsample': 0.9302082947141785}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:48,837] Trial 15 finished with value: -0.9939060253555244 and parameters: {'n_estimators': 169, 'learning_rate': 0.02550159780786631, 'max_depth': 6, 'subsample': 0.8488123936509142}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:50,951] Trial 16 finished with value: -0.9933122558212221 and parameters: {'n_estimators': 102, 'learning_rate': 0.10469335426137871, 'max_depth': 7, 'subsample': 0.9988049595242307}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:52,632] Trial 17 finished with value: -0.9937497753555243 and parameters: {'n_estimators': 75, 'learning_rate': 0.05987239651439145, 'max_depth': 6, 'subsample': 0.8773590748086967}. Best is trial 0 with value: -0.9942497997734021.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:53,957] Trial 18 finished with value: -0.9943435448898266 and parameters: {'n_estimators': 53, 'learning_rate': 0.11793440000481531, 'max_depth': 8, 'subsample': 0.9261897057287642}. Best is trial 18 with value: -0.9943435448898266.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:56,988] Trial 19 finished with value: -0.9933122802390999 and parameters: {'n_estimators': 158, 'learning_rate': 0.0797582538863159, 'max_depth': 7, 'subsample': 0.9638841780179538}. Best is trial 18 with value: -0.9943435448898266.\n",
      "[I 2025-06-18 20:17:57,319] A new study created in memory with name: no-name-cdef471b-87e7-4097-be67-5f7fe8682c8a\n",
      "[I 2025-06-18 20:18:02,810] Trial 0 finished with value: -0.9891872607047976 and parameters: {'iterations': 106, 'learning_rate': 0.13125830316209655, 'depth': 7, 'l2_leaf_reg': 0.6251373574521749}. Best is trial 0 with value: -0.9891872607047976.\n",
      "[I 2025-06-18 20:18:04,879] Trial 1 finished with value: -0.9689989304969526 and parameters: {'iterations': 73, 'learning_rate': 0.015256811898068502, 'depth': 3, 'l2_leaf_reg': 3.9676050770529883}. Best is trial 0 with value: -0.9891872607047976.\n",
      "[I 2025-06-18 20:18:07,862] Trial 2 finished with value: -0.990827836869042 and parameters: {'iterations': 140, 'learning_rate': 0.06803900745073706, 'depth': 3, 'l2_leaf_reg': 8.123245085588687}. Best is trial 2 with value: -0.990827836869042.\n",
      "[I 2025-06-18 20:18:12,006] Trial 3 finished with value: -0.9821868846694797 and parameters: {'iterations': 175, 'learning_rate': 0.01777174904859463, 'depth': 4, 'l2_leaf_reg': 0.03549878832196503}. Best is trial 2 with value: -0.990827836869042.\n",
      "[I 2025-06-18 20:18:15,034] Trial 4 finished with value: -0.9849836766486952 and parameters: {'iterations': 95, 'learning_rate': 0.04141536110538596, 'depth': 5, 'l2_leaf_reg': 0.07476312062252301}. Best is trial 2 with value: -0.990827836869042.\n",
      "[I 2025-06-18 20:18:18,584] Trial 5 finished with value: -0.9795774364158462 and parameters: {'iterations': 142, 'learning_rate': 0.01459007452373112, 'depth': 4, 'l2_leaf_reg': 0.1256277350380703}. Best is trial 2 with value: -0.990827836869042.\n",
      "[I 2025-06-18 20:18:22,298] Trial 6 finished with value: -0.9918903417526176 and parameters: {'iterations': 118, 'learning_rate': 0.0838375512850209, 'depth': 4, 'l2_leaf_reg': 0.34890188454913873}. Best is trial 6 with value: -0.9918903417526176.\n",
      "[I 2025-06-18 20:18:34,116] Trial 7 finished with value: -0.9803586375800906 and parameters: {'iterations': 139, 'learning_rate': 0.011340440501807348, 'depth': 6, 'l2_leaf_reg': 0.03247673570627449}. Best is trial 6 with value: -0.9918903417526176.\n",
      "[I 2025-06-18 20:18:40,136] Trial 8 finished with value: -0.9845775096694795 and parameters: {'iterations': 59, 'learning_rate': 0.13060986669773664, 'depth': 8, 'l2_leaf_reg': 2.6619018884890564}. Best is trial 6 with value: -0.9918903417526176.\n",
      "[I 2025-06-18 20:18:46,132] Trial 9 finished with value: -0.9772960496757307 and parameters: {'iterations': 95, 'learning_rate': 0.01302780710309028, 'depth': 7, 'l2_leaf_reg': 0.2091498132903561}. Best is trial 6 with value: -0.9918903417526176.\n",
      "[I 2025-06-18 20:18:54,481] Trial 10 finished with value: -0.9928279247734022 and parameters: {'iterations': 192, 'learning_rate': 0.06768269073143275, 'depth': 5, 'l2_leaf_reg': 0.8306050731972228}. Best is trial 10 with value: -0.9928279247734022.\n",
      "[I 2025-06-18 20:19:00,433] Trial 11 finished with value: -0.9926403905883732 and parameters: {'iterations': 191, 'learning_rate': 0.06883422377244944, 'depth': 5, 'l2_leaf_reg': 0.7451617972708874}. Best is trial 10 with value: -0.9928279247734022.\n",
      "[I 2025-06-18 20:19:09,264] Trial 12 finished with value: -0.9911715722183153 and parameters: {'iterations': 198, 'learning_rate': 0.04374644112678987, 'depth': 5, 'l2_leaf_reg': 0.9394319614658106}. Best is trial 10 with value: -0.9928279247734022.\n",
      "[I 2025-06-18 20:19:19,423] Trial 13 finished with value: -0.9911716161704953 and parameters: {'iterations': 178, 'learning_rate': 0.06888026550127622, 'depth': 6, 'l2_leaf_reg': 1.1912184401562167}. Best is trial 10 with value: -0.9928279247734022.\n",
      "[I 2025-06-18 20:19:31,117] Trial 14 finished with value: -0.9858588182723864 and parameters: {'iterations': 199, 'learning_rate': 0.026183290877026002, 'depth': 5, 'l2_leaf_reg': 1.9009789458942346}. Best is trial 10 with value: -0.9928279247734022.\n",
      "[I 2025-06-18 20:19:41,528] Trial 15 finished with value: -0.9899526561767464 and parameters: {'iterations': 168, 'learning_rate': 0.08604130823111787, 'depth': 6, 'l2_leaf_reg': 0.3076974779163993}. Best is trial 10 with value: -0.9928279247734022.\n",
      "[I 2025-06-18 20:19:47,887] Trial 16 finished with value: -0.9900465673347398 and parameters: {'iterations': 161, 'learning_rate': 0.05227010210162143, 'depth': 4, 'l2_leaf_reg': 0.45655940454458455}. Best is trial 10 with value: -0.9928279247734022.\n",
      "[I 2025-06-18 20:19:56,988] Trial 17 finished with value: -0.9824524217651195 and parameters: {'iterations': 189, 'learning_rate': 0.029871122812052682, 'depth': 7, 'l2_leaf_reg': 0.016180153184398118}. Best is trial 10 with value: -0.9928279247734022.\n",
      "[I 2025-06-18 20:20:03,451] Trial 18 finished with value: -0.9921716015197687 and parameters: {'iterations': 161, 'learning_rate': 0.10643739208019755, 'depth': 5, 'l2_leaf_reg': 9.604466184865705}. Best is trial 10 with value: -0.9928279247734022.\n",
      "[I 2025-06-18 20:20:13,138] Trial 19 finished with value: -0.9828586864158464 and parameters: {'iterations': 153, 'learning_rate': 0.02938614701390295, 'depth': 6, 'l2_leaf_reg': 1.044582321412846}. Best is trial 10 with value: -0.9928279247734022.\n",
      "[I 2025-06-18 20:20:14,696] A new study created in memory with name: no-name-67defcf7-7058-451f-afa1-dc1d3c4d2c21\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:20:56,315] Trial 0 finished with value: -0.9423104928504454 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 2.9380279387035334e-05, 'learning_rate_init': 0.00020511104188433984}. Best is trial 0 with value: -0.9423104928504454.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:20:57,580] Trial 1 finished with value: -0.9425288326300985 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.1527987128232396e-05, 'learning_rate_init': 0.008706020878304856}. Best is trial 1 with value: -0.9425288326300985.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:21:05,477] Trial 2 finished with value: -0.9471854391311142 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 8.17949947521167e-05, 'learning_rate_init': 0.0011207606211860567}. Best is trial 2 with value: -0.9471854391311142.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:21:14,952] Trial 3 finished with value: -0.9365597896155649 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 7.52374288453485e-05, 'learning_rate_init': 0.0005404103854647331}. Best is trial 2 with value: -0.9471854391311142.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:10,682] Trial 4 finished with value: -0.9402167281997187 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0005987474910461401, 'learning_rate_init': 0.0001238513729886094}. Best is trial 2 with value: -0.9471854391311142.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:12,728] Trial 5 finished with value: -0.9403419577277699 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00788671412999049, 'learning_rate_init': 0.004138040112561018}. Best is trial 2 with value: -0.9471854391311142.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:17,635] Trial 6 finished with value: -0.9364979098296609 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 2.32335035153901e-05, 'learning_rate_init': 0.0009780337016659412}. Best is trial 2 with value: -0.9471854391311142.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:24,684] Trial 7 finished with value: -0.9471854147132364 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 8.612579192594876e-05, 'learning_rate_init': 0.001096821720752952}. Best is trial 2 with value: -0.9471854391311142.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:26,606] Trial 8 finished with value: -0.9406539693702142 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.006584106160121612, 'learning_rate_init': 0.006161049539380964}. Best is trial 2 with value: -0.9471854391311142.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:41,254] Trial 9 finished with value: -0.9484667868026255 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.3667272915456215e-05, 'learning_rate_init': 0.0004473636174621269}. Best is trial 9 with value: -0.9484667868026255.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:53,258] Trial 10 finished with value: -0.9444978121581495 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0006014902816498304, 'learning_rate_init': 0.00033808702271313697}. Best is trial 9 with value: -0.9484667868026255.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:57,732] Trial 11 finished with value: -0.9519043991248634 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0001450772343359886, 'learning_rate_init': 0.001965459961849473}. Best is trial 11 with value: -0.9519043991248634.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:00,784] Trial 12 finished with value: -0.9483107028441944 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0002652517457590181, 'learning_rate_init': 0.0028031544100470982}. Best is trial 11 with value: -0.9519043991248634.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:05,188] Trial 13 finished with value: -0.950029203781841 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0025997602927229544, 'learning_rate_init': 0.0022412869934227203}. Best is trial 11 with value: -0.9519043991248634.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:09,105] Trial 14 finished with value: -0.9524353365760275 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0017308337176320375, 'learning_rate_init': 0.00227570498163851}. Best is trial 14 with value: -0.9524353365760275.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:13,041] Trial 15 finished with value: -0.9517481295905611 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0018333974348397526, 'learning_rate_init': 0.0019922077577323597}. Best is trial 14 with value: -0.9524353365760275.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:14,755] Trial 16 finished with value: -0.948122777973121 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0002464267427220573, 'learning_rate_init': 0.0038277068071634972}. Best is trial 14 with value: -0.9524353365760275.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:19,548] Trial 17 finished with value: -0.9502481491248632 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0018402557157853477, 'learning_rate_init': 0.0018827320434846903}. Best is trial 14 with value: -0.9524353365760275.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:40,909] Trial 18 finished with value: -0.9484670016799498 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0007435925447379895, 'learning_rate_init': 0.0008288598370529125}. Best is trial 14 with value: -0.9524353365760275.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:52,766] Trial 19 finished with value: -0.9449044186591655 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.00015792865511230736, 'learning_rate_init': 0.005584033383616412}. Best is trial 14 with value: -0.9524353365760275.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- Основной цикл оценки с тремя методами оптимизации ---\n",
    "all_classification_results = []\n",
    "optimizers = ['RandomizedSearchCV', 'GridSearchCV', 'Optuna']\n",
    "\n",
    "# Извлекаем признаки, исключая все целевые переменные (теперь просто TARGETS_ACTUAL_LOGGED)\n",
    "# и новые бинарные целевые переменные.\n",
    "columns_to_drop_common = TARGETS_ACTUAL_LOGGED + list(classification_targets.keys())\n",
    "\n",
    "# Добавляем специфические для датасетов столбцы, которые не являются признаками (например, SMILES)\n",
    "if 'SMILES' in df_pca.columns:\n",
    "    columns_to_drop_pca_final = columns_to_drop_common + ['SMILES']\n",
    "else:\n",
    "    columns_to_drop_pca_final = columns_to_drop_common\n",
    "\n",
    "if 'SMILES' in df_manual.columns:\n",
    "    columns_to_drop_manual_final = columns_to_drop_common + ['SMILES']\n",
    "else:\n",
    "    columns_to_drop_manual_final = columns_to_drop_common\n",
    "\n",
    "X_pca_features = df_pca.drop(columns=columns_to_drop_pca_final, errors='ignore')\n",
    "X_manual_features = df_manual.drop(columns=columns_to_drop_manual_final, errors='ignore')\n",
    "\n",
    "\n",
    "print(\"Начинаем процесс обучения и оценки моделей классификации...\")\n",
    "\n",
    "for target_name_classification in tqdm(classification_targets.keys(), desc=\"Прогнозирование задач классификации\"):\n",
    "    for data_source_name, X_data_features, df_data in [(\"PCA Aggregated\", X_pca_features, df_pca), (\"Manual Aggregated\", X_manual_features, df_manual)]:\n",
    "        y_data_classification = df_data[target_name_classification]\n",
    "\n",
    "        num_models_to_run = 0\n",
    "        for model_name, config in models_config_classifier.items():\n",
    "            for optimizer_type in optimizers:\n",
    "                # Уточненная логика для подсчета моделей\n",
    "                if (optimizer_type == 'RandomizedSearchCV' and not config.get('random_dist', {})) and model_name != \"LogisticRegression\":\n",
    "                    continue\n",
    "                if (optimizer_type == 'GridSearchCV' and not config.get('grid_params', {})) and model_name != \"LogisticRegression\":\n",
    "                    continue\n",
    "                if (optimizer_type == 'Optuna' and config.get('optuna_space') is None) and model_name != \"LogisticRegression\":\n",
    "                    continue\n",
    "                num_models_to_run += 1\n",
    "\n",
    "        with tqdm(total=num_models_to_run, desc=f\"Оптимизация для {target_name_classification} ({data_source_name})\", leave=False) as pbar_inner:\n",
    "            for optimizer_type in optimizers:\n",
    "                for model_name, config in models_config_classifier.items():\n",
    "                    # Пропускаем неподходящие комбинации модель-оптимизатор, чтобы избежать ошибок и не тратить время\n",
    "                    if (optimizer_type == 'RandomizedSearchCV' and not config.get('random_dist', {})) and model_name != \"LogisticRegression\":\n",
    "                        pbar_inner.update(1)\n",
    "                        continue\n",
    "                    if (optimizer_type == 'GridSearchCV' and not config.get('grid_params', {})) and model_name != \"LogisticRegression\":\n",
    "                        pbar_inner.update(1)\n",
    "                        continue\n",
    "                    if (optimizer_type == 'Optuna' and config.get('optuna_space') is None) and model_name != \"LogisticRegression\":\n",
    "                        pbar_inner.update(1)\n",
    "                        continue\n",
    "\n",
    "                    model_class = config[\"class\"]\n",
    "                    params_config = config\n",
    "\n",
    "                    pbar_inner.set_description(f\"Оптимизация для {target_name_classification} ({data_source_name}) - {model_name} ({optimizer_type})\")\n",
    "\n",
    "                    result = evaluate_model_with_optimizer_classifier(model_name, model_class, params_config,\n",
    "                                                                      X_data_features, y_data_classification, target_name_classification, optimizer_type)\n",
    "                    if result:\n",
    "                        result['data_source'] = data_source_name\n",
    "                        all_classification_results.append(result)\n",
    "                    pbar_inner.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c4fab20-7400-4d47-86f9-ccb611faebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты классификации сохранены в: classification_results_all_optimizers_50_iter.csv\n",
      "\n",
      "--- Сводка результатов классификации по методам оптимизации ---\n",
      "\n",
      "## Результаты RandomizedSearchCV (Классификация):\n",
      "                     model           optimizer                target                                                                                                                              best_params  accuracy  precision  recall  f1_score   roc_auc        data_source\n",
      "17      CatBoostClassifier  RandomizedSearchCV  is_CC50_above_median                                  {'depth': 4, 'iterations': 183, 'l2_leaf_reg': 2.455591640077322, 'learning_rate': 0.09515504917299872}  0.985075   0.970874    1.00  0.985222  0.997921  Manual Aggregated\n",
      "3       CatBoostClassifier  RandomizedSearchCV  is_CC50_above_median                                   {'depth': 4, 'iterations': 181, 'l2_leaf_reg': 7.59541228979397, 'learning_rate': 0.09449323267683088}  0.980100   0.961538    1.00  0.980392  0.996634     PCA Aggregated\n",
      "16           XGBClassifier  RandomizedSearchCV  is_CC50_above_median  {'learning_rate': 0.15092484123462838, 'max_depth': 6, 'n_estimators': 63, 'subsample': 0.9181815987569262, 'use_label_encoder': False}  0.980100   0.961538    1.00  0.980392  0.996337  Manual Aggregated\n",
      "2            XGBClassifier  RandomizedSearchCV  is_CC50_above_median  {'learning_rate': 0.12209801652060712, 'max_depth': 7, 'n_estimators': 73, 'subsample': 0.8070259980080767, 'use_label_encoder': False}  0.975124   0.961165    0.99  0.975369  0.994752     PCA Aggregated\n",
      "0       LogisticRegression  RandomizedSearchCV  is_CC50_above_median                                                                         {'C': 3.845401188473625, 'penalty': 'l1', 'solver': 'liblinear'}  0.950249   0.950000    0.95  0.950000  0.987525     PCA Aggregated\n",
      "14      LogisticRegression  RandomizedSearchCV  is_CC50_above_median                                                                         {'C': 3.845401188473625, 'penalty': 'l1', 'solver': 'liblinear'}  0.950249   0.950000    0.95  0.950000  0.986040  Manual Aggregated\n",
      "4            MLPClassifier  RandomizedSearchCV  is_CC50_above_median                               {'alpha': 0.00016632480579933264, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.004928160165372797}  0.935323   0.930693    0.94  0.935323  0.980693     PCA Aggregated\n",
      "18           MLPClassifier  RandomizedSearchCV  is_CC50_above_median                                {'alpha': 0.0007101911742238942, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.004265974558680822}  0.925373   0.912621    0.94  0.926108  0.970693  Manual Aggregated\n",
      "1   RandomForestClassifier  RandomizedSearchCV  is_CC50_above_median                                                                           {'max_depth': 10, 'min_samples_split': 6, 'n_estimators': 179}  0.835821   0.819048    0.86  0.839024  0.937921     PCA Aggregated\n",
      "15  RandomForestClassifier  RandomizedSearchCV  is_CC50_above_median                                                                         {'max_depth': None, 'min_samples_split': 4, 'n_estimators': 121}  0.855721   0.838095    0.88  0.858537  0.935644  Manual Aggregated\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "## Результаты GridSearchCV (Классификация):\n",
      "                     model     optimizer                target                                                                              best_params  accuracy  precision  recall  f1_score   roc_auc        data_source\n",
      "22      CatBoostClassifier  GridSearchCV  is_CC50_above_median                                    {'depth': 3, 'iterations': 150, 'learning_rate': 0.1}  0.980100   0.970588    0.99  0.980198  0.997624  Manual Aggregated\n",
      "8       CatBoostClassifier  GridSearchCV  is_CC50_above_median                                    {'depth': 3, 'iterations': 150, 'learning_rate': 0.1}  0.985075   0.980198    0.99  0.985075  0.996832     PCA Aggregated\n",
      "21           XGBClassifier  GridSearchCV  is_CC50_above_median  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150, 'use_label_encoder': False}  0.975124   0.961165    0.99  0.975369  0.994950  Manual Aggregated\n",
      "7            XGBClassifier  GridSearchCV  is_CC50_above_median  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150, 'use_label_encoder': False}  0.975124   0.961165    0.99  0.975369  0.994653     PCA Aggregated\n",
      "19      LogisticRegression  GridSearchCV  is_CC50_above_median                                       {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}  0.965174   0.951456    0.98  0.965517  0.988812  Manual Aggregated\n",
      "5       LogisticRegression  GridSearchCV  is_CC50_above_median                                       {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}  0.970149   0.951923    0.99  0.970588  0.988614     PCA Aggregated\n",
      "9            MLPClassifier  GridSearchCV  is_CC50_above_median                                           {'alpha': 0.001, 'hidden_layer_sizes': (100,)}  0.910448   0.901961    0.92  0.910891  0.963861     PCA Aggregated\n",
      "23           MLPClassifier  GridSearchCV  is_CC50_above_median                                           {'alpha': 0.001, 'hidden_layer_sizes': (100,)}  0.905473   0.893204    0.92  0.906404  0.957327  Manual Aggregated\n",
      "20  RandomForestClassifier  GridSearchCV  is_CC50_above_median                                                   {'max_depth': 10, 'n_estimators': 150}  0.855721   0.831776    0.89  0.859903  0.937624  Manual Aggregated\n",
      "6   RandomForestClassifier  GridSearchCV  is_CC50_above_median                                                   {'max_depth': 10, 'n_estimators': 150}  0.845771   0.828571    0.87  0.848780  0.933762     PCA Aggregated\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "## Результаты Optuna (Классификация):\n",
      "                     model optimizer                target                                                                                                   best_params  accuracy  precision  recall  f1_score   roc_auc        data_source\n",
      "12      CatBoostClassifier    Optuna  is_CC50_above_median       {'iterations': 193, 'learning_rate': 0.08982290950094239, 'depth': 3, 'l2_leaf_reg': 1.653733032749862}  0.985075   0.980198    0.99  0.985075  0.998515     PCA Aggregated\n",
      "25           XGBClassifier    Optuna  is_CC50_above_median   {'n_estimators': 53, 'learning_rate': 0.11793440000481531, 'max_depth': 8, 'subsample': 0.9261897057287642}  0.975124   0.961165    0.99  0.975369  0.997228  Manual Aggregated\n",
      "26      CatBoostClassifier    Optuna  is_CC50_above_median      {'iterations': 192, 'learning_rate': 0.06768269073143275, 'depth': 5, 'l2_leaf_reg': 0.8306050731972228}  0.990050   0.980392    1.00  0.990099  0.996733  Manual Aggregated\n",
      "11           XGBClassifier    Optuna  is_CC50_above_median  {'n_estimators': 181, 'learning_rate': 0.029889222048762723, 'max_depth': 7, 'subsample': 0.710333251865073}  0.975124   0.961165    0.99  0.975369  0.996040     PCA Aggregated\n",
      "13           MLPClassifier    Optuna  is_CC50_above_median      {'hidden_layer_sizes': (50,), 'alpha': 0.002065344154282732, 'learning_rate_init': 0.002382865858231569}  0.915423   0.927835    0.90  0.913706  0.971881     PCA Aggregated\n",
      "27           MLPClassifier    Optuna  is_CC50_above_median      {'hidden_layer_sizes': (50,), 'alpha': 0.0017308337176320375, 'learning_rate_init': 0.00227570498163851}  0.920398   0.920000    0.92  0.920000  0.968614  Manual Aggregated\n",
      "24  RandomForestClassifier    Optuna  is_CC50_above_median                                                 {'n_estimators': 70, 'max_depth': 15, 'min_samples_split': 4}  0.830846   0.811321    0.86  0.834951  0.927822  Manual Aggregated\n",
      "10  RandomForestClassifier    Optuna  is_CC50_above_median                                                {'n_estimators': 198, 'max_depth': 15, 'min_samples_split': 7}  0.820896   0.796296    0.86  0.826923  0.927525     PCA Aggregated\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Сохранение и вывод результатов ---\n",
    "output_classification_file = Path('classification_results_all_optimizers_50_iter.csv')\n",
    "\n",
    "all_classification_results_df = pd.DataFrame(all_classification_results)\n",
    "all_classification_results_df.to_csv(output_classification_file, index=False)\n",
    "print(f\"\\nРезультаты классификации сохранены в: {output_classification_file}\")\n",
    "\n",
    "print(\"\\n--- Сводка результатов классификации по методам оптимизации ---\")\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    print(f\"\\n## Результаты {optimizer} (Классификация):\")\n",
    "    subset_optimizer = all_classification_results_df[all_classification_results_df['optimizer'] == optimizer]\n",
    "    print(subset_optimizer.sort_values(by=['target', 'roc_auc'], ascending=[True, False]).to_string())\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Визуализация метрик классификации (например, ROC-AUC и F1-score)\n",
    "classification_metrics_to_plot = ['roc_auc', 'f1_score', 'accuracy']\n",
    "\n",
    "for target_class in classification_targets.keys():\n",
    "    for metric in classification_metrics_to_plot:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        subset = all_classification_results_df[all_classification_results_df['target'] == target_class].sort_values(by=metric, ascending=False)\n",
    "        sns.barplot(x='model', y=metric, hue='optimizer', data=subset, palette='viridis')\n",
    "        plt.title(f'Сравнение {metric.upper()} для \"{target_class}\" по методам оптимизации', fontsize=16)\n",
    "        plt.ylabel(metric.upper(), fontsize=12)\n",
    "        plt.xlabel('Модель', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.legend(title='Метод оптимизации', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'classification_{target_class}_{metric}_comparison.png')\n",
    "        plt.close() # Close plot to free memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
