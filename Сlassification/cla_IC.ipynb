{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddde29b9-e3eb-4c5c-8dd4-d127058ba0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Data (actual logged targets):\n",
      "   IC50, mM\n",
      "0  1.979535\n",
      "1  0.572014\n",
      "2  5.415250\n",
      "3  0.995333\n",
      "4  4.683348\n",
      "\n",
      "Manual Data (actual logged targets):\n",
      "   IC50, mM\n",
      "0  1.979535\n",
      "1  0.572014\n",
      "2  5.415250\n",
      "3  0.995333\n",
      "4  4.683348\n",
      "\n",
      "Созданные бинарные целевые переменные:\n",
      "PCA - is_IC50_above_median value counts:\n",
      " is_IC50_above_median\n",
      "0    501\n",
      "1    500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Manual - is_IC50_above_median value counts:\n",
      " is_IC50_above_median\n",
      "0    501\n",
      "1    500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import uniform, randint\n",
    "import optuna\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Загрузка данных ---\n",
    "file_url_pca = 'https://drive.google.com/uc?export=download&id=1SuUhkpfj-3uJQnxwmUCyDUogfa2TixTe'\n",
    "file_url_manual = 'https://drive.google.com/uc?export=download&id=1p8VYp23oOylSFrfJztQVheNLop-bX40o'\n",
    "\n",
    "df_pca = pd.read_csv(file_url_pca, encoding='utf-8')\n",
    "df_manual = pd.read_csv(file_url_manual, encoding='utf-8')\n",
    "\n",
    "# --- Определяем фактические целевые переменные, которые уже логарифмированы ---\n",
    "# Поскольку вы подтвердили, что 'IC50, mM', 'CC50, mM', 'SI' уже логарифмированы,\n",
    "# мы будем использовать их напрямую как наши \"лог-цели\".\n",
    "TARGETS_ACTUAL_LOGGED = ['IC50, mM']\n",
    "\n",
    "print(\"PCA Data (actual logged targets):\")\n",
    "print(df_pca[TARGETS_ACTUAL_LOGGED].head())\n",
    "print(\"\\nManual Data (actual logged targets):\")\n",
    "print(df_manual[TARGETS_ACTUAL_LOGGED].head())\n",
    "\n",
    "# --- Создание бинарных целевых переменных для классификации ---\n",
    "\n",
    "classification_targets = {}\n",
    "\n",
    "# 1. IC50 > медианы\n",
    "median_ic50_pca = df_pca['IC50, mM'].median()\n",
    "df_pca['is_IC50_above_median'] = (df_pca['IC50, mM'] > median_ic50_pca).astype(int)\n",
    "median_ic50_manual = df_manual['IC50, mM'].median()\n",
    "df_manual['is_IC50_above_median'] = (df_manual['IC50, mM'] > median_ic50_manual).astype(int)\n",
    "classification_targets['is_IC50_above_median'] = 'IC50, mM' # Указываем, откуда взята целевая\n",
    "\n",
    "\n",
    "print(\"\\nСозданные бинарные целевые переменные:\")\n",
    "print(\"PCA - is_IC50_above_median value counts:\\n\", df_pca['is_IC50_above_median'].value_counts())\n",
    "\n",
    "\n",
    "print(\"\\nManual - is_IC50_above_median value counts:\\n\", df_manual['is_IC50_above_median'].value_counts())\n",
    "\n",
    "\n",
    "# --- Вспомогательная функция для расчета метрик классификации ---\n",
    "def calculate_classification_metrics(y_true, y_pred, y_pred_proba):\n",
    "    \"\"\"Вычисляет метрики классификации: Accuracy, Precision, Recall, F1, ROC-AUC.\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0) # Добавлено zero_division\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# --- Функции для каждого метода оптимизации (адаптированные для классификации) ---\n",
    "\n",
    "def run_randomized_search_classifier(model_instance, param_distributions, X_train_scaled, y_train, n_iter_search=20):\n",
    "    \"\"\"Выполняет RandomizedSearchCV для подбора гиперпараметров для классификации.\"\"\"\n",
    "    if not param_distributions:\n",
    "        model_instance.fit(X_train_scaled, y_train)\n",
    "        return model_instance, {}\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    random_search = RandomizedSearchCV(model_instance, param_distributions, n_iter=n_iter_search,\n",
    "                                       cv=cv, scoring='roc_auc',\n",
    "                                       n_jobs=-1, verbose=0, random_state=42)\n",
    "    random_search.fit(X_train_scaled, y_train)\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "def run_grid_search_classifier(model_instance, param_grid, X_train_scaled, y_train):\n",
    "    \"\"\"Выполняет GridSearchCV для подбора гиперпараметров для классификации.\"\"\"\n",
    "    if not param_grid:\n",
    "        model_instance.fit(X_train_scaled, y_train)\n",
    "        return model_instance, {}\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(model_instance, param_grid, cv=cv, scoring='roc_auc',\n",
    "                               n_jobs=-1, verbose=0)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "def run_optuna_search_classifier(model_class, optuna_search_space, X_train_scaled, y_train, n_trials=20):\n",
    "    \"\"\"Выполняет оптимизацию гиперпараметров с помощью Optuna для классификации.\"\"\"\n",
    "    def objective(trial):\n",
    "        params = optuna_search_space(trial)\n",
    "\n",
    "        # Обработка random_state/random_seed для Optuna\n",
    "        # Random_state может быть не поддерживаем для всех моделей или определенных solvers\n",
    "        # Здесь мы исходим из того, что Optuna space уже определяет правильный параметр ('random_state' или 'random_seed')\n",
    "        if model_class in [LogisticRegression, MLPClassifier] and 'random_state' in params:\n",
    "            model = model_class(**{k: v for k, v in params.items() if k != 'random_state'})\n",
    "        else:\n",
    "            model = model_class(**params)\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_scores = []\n",
    "        for train_idx, val_idx in kf.split(X_train_scaled, y_train):\n",
    "            X_train_fold, X_val_fold = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            try:\n",
    "                if isinstance(model, CatBoostClassifier):\n",
    "                    train_pool = Pool(X_train_fold, y_train_fold)\n",
    "                    val_pool = Pool(X_val_fold, y_val_fold)\n",
    "                    model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=10, verbose=False)\n",
    "                    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "                else:\n",
    "                    model.fit(X_train_fold, y_train_fold)\n",
    "                    y_val_pred_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "                roc_auc_fold = roc_auc_score(y_val_fold, y_val_pred_proba)\n",
    "                cv_scores.append(roc_auc_fold)\n",
    "            except Exception as e:\n",
    "                # print(f\"Ошибка при обучении/предсказании в Optuna (фолд): {e}\") # Для дебага\n",
    "                return -float('inf')\n",
    "\n",
    "        return -np.mean(cv_scores)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False, catch=(ValueError, Exception))\n",
    "\n",
    "    best_params = study.best_params\n",
    "    \n",
    "    # Final model instance with best parameters\n",
    "    if model_class in [LogisticRegression, MLPClassifier] and 'random_state' in best_params:\n",
    "        best_model_instance = model_class(**{k: v for k, v in best_params.items() if k != 'random_state'})\n",
    "    else:\n",
    "        best_model_instance = model_class(**best_params)\n",
    "\n",
    "    try:\n",
    "        if isinstance(best_model_instance, CatBoostClassifier):\n",
    "            train_pool_final = Pool(X_train_scaled, y_train)\n",
    "            best_model_instance.fit(train_pool_final, verbose=False)\n",
    "        else:\n",
    "            best_model_instance.fit(X_train_scaled, y_train)\n",
    "    except Exception as e:\n",
    "        # print(f\"Ошибка при окончательном обучении CatBoost: {e}\") # Для дебага\n",
    "        return None, {}\n",
    "\n",
    "    return best_model_instance, best_params\n",
    "\n",
    "# --- Общая функция для оценки моделей с различными оптимизаторами (адаптированная) ---\n",
    "def evaluate_model_with_optimizer_classifier(model_name, model_class, params_config, X, y, target_name, optimizer_type):\n",
    "    \"\"\"Оценивает производительность модели классификации, используя указанный метод оптимизации.\"\"\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    best_model = None\n",
    "    best_params = {}\n",
    "\n",
    "    # Инициализация параметров для воспроизводимости:\n",
    "    model_init_params = {}\n",
    "    if model_name == \"CatBoostClassifier\":\n",
    "        model_init_params['random_seed'] = 42\n",
    "    elif model_name in [\"LogisticRegression\", \"RandomForestClassifier\", \"XGBClassifier\", \"MLPClassifier\"]:\n",
    "        # Эти модели обычно принимают random_state для воспроизводимости\n",
    "        model_init_params['random_state'] = 42\n",
    "\n",
    "    if optimizer_type == 'RandomizedSearchCV':\n",
    "        param_distributions = params_config.get('random_dist', {})\n",
    "        # Для LogisticRegression, если нет dist, используем дефолтный инстанс\n",
    "        if model_name == \"LogisticRegression\" and not param_distributions:\n",
    "             model_instance = model_class(**model_init_params)\n",
    "             model_instance.fit(X_train_scaled, y_train)\n",
    "             best_model, best_params = model_instance, {}\n",
    "        else:\n",
    "            best_model, best_params = run_randomized_search_classifier(model_class(**model_init_params), param_distributions, X_train_scaled, y_train, n_iter_search=20)\n",
    "\n",
    "    elif optimizer_type == 'GridSearchCV':\n",
    "        param_grid = params_config.get('grid_params', {})\n",
    "        if not param_grid:\n",
    "            model_instance = model_class(**model_init_params)\n",
    "            model_instance.fit(X_train_scaled, y_train)\n",
    "            best_model, best_params = model_instance, {}\n",
    "        else:\n",
    "            best_model, best_params = run_grid_search_classifier(model_class(**model_init_params), param_grid, X_train_scaled, y_train)\n",
    "\n",
    "    elif optimizer_type == 'Optuna':\n",
    "        optuna_space = params_config.get('optuna_space')\n",
    "        if optuna_space is None:\n",
    "            model_instance = model_class(**model_init_params)\n",
    "            model_instance.fit(X_train_scaled, y_train)\n",
    "            best_model, best_params = model_instance, {}\n",
    "        else:\n",
    "            # Optuna уже обрабатывает random_state/random_seed в своей objective функции\n",
    "            best_model, best_params = run_optuna_search_classifier(model_class, optuna_space, X_train_scaled, y_train, n_trials=20)\n",
    "    else:\n",
    "        raise ValueError(f\"Неизвестный тип оптимизатора: {optimizer_type}\")\n",
    "\n",
    "    if best_model is None:\n",
    "        return None\n",
    "\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    # predict_proba может отсутствовать для некоторых моделей (например, SVM с probability=False)\n",
    "    # или если модель не была обучена с этой функциональностью.\n",
    "    # Проверяем наличие predict_proba\n",
    "    if hasattr(best_model, \"predict_proba\") and len(best_model.predict_proba(X_test_scaled).shape) > 1:\n",
    "        y_pred_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        # Для моделей без predict_proba, ROC-AUC не может быть рассчитан.\n",
    "        # В таком случае, можно либо пропустить ROC-AUC, либо вернуть NaN.\n",
    "        # Для SVM, если probability=True не установлен при инициализации, его не будет.\n",
    "        # Для LogisticRegression и Tree-based моделей predict_proba всегда есть.\n",
    "        print(f\"Warning: Model {model_name} does not have predict_proba or it's not applicable. ROC-AUC will be NaN.\")\n",
    "        y_pred_proba = np.full_like(y_pred, np.nan, dtype=float) # Заполняем NaN для ROC-AUC\n",
    "\n",
    "    accuracy, precision, recall, f1, roc_auc = calculate_classification_metrics(y_test, y_pred, y_pred_proba)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'optimizer': optimizer_type,\n",
    "        'target': target_name,\n",
    "        'best_params': best_params,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "\n",
    "# --- Определение моделей и их гиперпараметров для разных оптимизаторов (адаптированные для классификации) ---\n",
    "models_config_classifier = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"class\": LogisticRegression,\n",
    "        \"random_dist\": {\n",
    "            'C': uniform(loc=0.1, scale=10),\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear']\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear']\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'C': trial.suggest_float('C', 0.1, 10.0, log=True),\n",
    "            'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
    "            'solver': 'liblinear',\n",
    "            'random_state': 42 # Добавлен random_state здесь, чтобы управлять им\n",
    "        }\n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"class\": RandomForestClassifier,\n",
    "        \"random_dist\": {\n",
    "            'n_estimators': randint(50, 200),\n",
    "            'max_depth': [5, 10, None],\n",
    "            'min_samples_split': randint(2, 8)\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'n_estimators': [100, 150],\n",
    "            'max_depth': [5, 10],\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [5, 10, 15, None]),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 8),\n",
    "            'random_state': 42\n",
    "        }\n",
    "    },\n",
    "    \"XGBClassifier\": {\n",
    "        \"class\": XGBClassifier,\n",
    "        \"random_dist\": {\n",
    "            'n_estimators': randint(50, 200),\n",
    "            'learning_rate': uniform(0.01, 0.15),\n",
    "            'max_depth': randint(3, 8),\n",
    "            'subsample': uniform(0.7, 0.3),\n",
    "            'use_label_encoder': [False]\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'n_estimators': [100, 150],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'max_depth': [3, 5],\n",
    "            'use_label_encoder': [False]\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'eval_metric': 'logloss',\n",
    "            'n_jobs': -1,\n",
    "            'random_state': 42,\n",
    "            'use_label_encoder': False\n",
    "        }\n",
    "    },\n",
    "    \"CatBoostClassifier\": {\n",
    "        \"class\": CatBoostClassifier,\n",
    "        \"random_dist\": {\n",
    "            'iterations': randint(50, 200),\n",
    "            'learning_rate': uniform(0.01, 0.15),\n",
    "            'depth': randint(3, 8),\n",
    "            'l2_leaf_reg': uniform(1, 7)\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'iterations': [100, 150],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'depth': [3, 5]\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'iterations': trial.suggest_int('iterations', 50, 200),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15, log=True),\n",
    "            'depth': trial.suggest_int('depth', 3, 8),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 10, log=True),\n",
    "            'verbose': False,\n",
    "            'random_seed': 42, # CatBoost uses random_seed\n",
    "            'thread_count': -1,\n",
    "            'objective': 'Logloss'\n",
    "        }\n",
    "    },\n",
    "    \"MLPClassifier\": {\n",
    "        \"class\": MLPClassifier,\n",
    "        \"random_dist\": {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "            'alpha': uniform(0.0001, 0.005),\n",
    "            'learning_rate_init': uniform(0.0001, 0.005)\n",
    "        },\n",
    "        \"grid_params\": {\n",
    "            'hidden_layer_sizes': [(50,), (100,)],\n",
    "            'alpha': [0.0001, 0.001]\n",
    "        },\n",
    "        \"optuna_space\": lambda trial: {\n",
    "            'hidden_layer_sizes': trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50), (100, 50)]),\n",
    "            'alpha': trial.suggest_float('alpha', 1e-5, 1e-2, log=True),\n",
    "            'learning_rate_init': trial.suggest_float('learning_rate_init', 1e-4, 1e-2, log=True),\n",
    "            'max_iter': 2000,\n",
    "            'random_state': 42,\n",
    "            'solver': 'adam'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65441089-d139-4982-9de4-11c9d5367183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем процесс обучения и оценки моделей классификации...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbf65cf8e36478ba5e34b8289451dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Прогнозирование задач классификации:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Оптимизация для is_IC50_above_median (PCA Aggregated):   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:57:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5989250\ttotal: 140ms\tremaining: 21.8s\n",
      "1:\tlearn: 0.5379295\ttotal: 146ms\tremaining: 11.3s\n",
      "2:\tlearn: 0.4912189\ttotal: 150ms\tremaining: 7.71s\n",
      "3:\tlearn: 0.4347807\ttotal: 157ms\tremaining: 6.01s\n",
      "4:\tlearn: 0.4037755\ttotal: 163ms\tremaining: 4.95s\n",
      "5:\tlearn: 0.3735342\ttotal: 169ms\tremaining: 4.24s\n",
      "6:\tlearn: 0.3404111\ttotal: 175ms\tremaining: 3.74s\n",
      "7:\tlearn: 0.3146905\ttotal: 178ms\tremaining: 3.32s\n",
      "8:\tlearn: 0.2850826\ttotal: 185ms\tremaining: 3.04s\n",
      "9:\tlearn: 0.2662469\ttotal: 190ms\tremaining: 2.79s\n",
      "10:\tlearn: 0.2552016\ttotal: 193ms\tremaining: 2.56s\n",
      "11:\tlearn: 0.2420950\ttotal: 197ms\tremaining: 2.38s\n",
      "12:\tlearn: 0.2284264\ttotal: 201ms\tremaining: 2.23s\n",
      "13:\tlearn: 0.2182475\ttotal: 205ms\tremaining: 2.1s\n",
      "14:\tlearn: 0.2108586\ttotal: 208ms\tremaining: 1.97s\n",
      "15:\tlearn: 0.1980042\ttotal: 211ms\tremaining: 1.86s\n",
      "16:\tlearn: 0.1872177\ttotal: 215ms\tremaining: 1.77s\n",
      "17:\tlearn: 0.1829630\ttotal: 217ms\tremaining: 1.68s\n",
      "18:\tlearn: 0.1800573\ttotal: 221ms\tremaining: 1.6s\n",
      "19:\tlearn: 0.1744346\ttotal: 224ms\tremaining: 1.54s\n",
      "20:\tlearn: 0.1636291\ttotal: 236ms\tremaining: 1.53s\n",
      "21:\tlearn: 0.1612365\ttotal: 239ms\tremaining: 1.47s\n",
      "22:\tlearn: 0.1591092\ttotal: 243ms\tremaining: 1.41s\n",
      "23:\tlearn: 0.1534296\ttotal: 246ms\tremaining: 1.36s\n",
      "24:\tlearn: 0.1498962\ttotal: 249ms\tremaining: 1.31s\n",
      "25:\tlearn: 0.1443119\ttotal: 253ms\tremaining: 1.27s\n",
      "26:\tlearn: 0.1389311\ttotal: 256ms\tremaining: 1.23s\n",
      "27:\tlearn: 0.1338263\ttotal: 259ms\tremaining: 1.2s\n",
      "28:\tlearn: 0.1324380\ttotal: 263ms\tremaining: 1.16s\n",
      "29:\tlearn: 0.1295414\ttotal: 266ms\tremaining: 1.13s\n",
      "30:\tlearn: 0.1277216\ttotal: 269ms\tremaining: 1.09s\n",
      "31:\tlearn: 0.1263596\ttotal: 272ms\tremaining: 1.06s\n",
      "32:\tlearn: 0.1249861\ttotal: 276ms\tremaining: 1.04s\n",
      "33:\tlearn: 0.1206869\ttotal: 279ms\tremaining: 1.01s\n",
      "34:\tlearn: 0.1171919\ttotal: 282ms\tremaining: 982ms\n",
      "35:\tlearn: 0.1150019\ttotal: 285ms\tremaining: 958ms\n",
      "36:\tlearn: 0.1132022\ttotal: 288ms\tremaining: 934ms\n",
      "37:\tlearn: 0.1108984\ttotal: 291ms\tremaining: 911ms\n",
      "38:\tlearn: 0.1092734\ttotal: 294ms\tremaining: 890ms\n",
      "39:\tlearn: 0.1090313\ttotal: 298ms\tremaining: 871ms\n",
      "40:\tlearn: 0.1063383\ttotal: 301ms\tremaining: 852ms\n",
      "41:\tlearn: 0.1060736\ttotal: 304ms\tremaining: 833ms\n",
      "42:\tlearn: 0.1019367\ttotal: 308ms\tremaining: 815ms\n",
      "43:\tlearn: 0.1011607\ttotal: 311ms\tremaining: 798ms\n",
      "44:\tlearn: 0.1009654\ttotal: 314ms\tremaining: 781ms\n",
      "45:\tlearn: 0.1002464\ttotal: 317ms\tremaining: 766ms\n",
      "46:\tlearn: 0.0997268\ttotal: 321ms\tremaining: 750ms\n",
      "47:\tlearn: 0.0990971\ttotal: 324ms\tremaining: 736ms\n",
      "48:\tlearn: 0.0984237\ttotal: 328ms\tremaining: 722ms\n",
      "49:\tlearn: 0.0979610\ttotal: 331ms\tremaining: 709ms\n",
      "50:\tlearn: 0.0964838\ttotal: 335ms\tremaining: 696ms\n",
      "51:\tlearn: 0.0956071\ttotal: 338ms\tremaining: 682ms\n",
      "52:\tlearn: 0.0951725\ttotal: 342ms\tremaining: 670ms\n",
      "53:\tlearn: 0.0938239\ttotal: 345ms\tremaining: 658ms\n",
      "54:\tlearn: 0.0936514\ttotal: 348ms\tremaining: 646ms\n",
      "55:\tlearn: 0.0894016\ttotal: 351ms\tremaining: 634ms\n",
      "56:\tlearn: 0.0869934\ttotal: 355ms\tremaining: 622ms\n",
      "57:\tlearn: 0.0868743\ttotal: 358ms\tremaining: 611ms\n",
      "58:\tlearn: 0.0839041\ttotal: 361ms\tremaining: 600ms\n",
      "59:\tlearn: 0.0832797\ttotal: 365ms\tremaining: 590ms\n",
      "60:\tlearn: 0.0814053\ttotal: 368ms\tremaining: 579ms\n",
      "61:\tlearn: 0.0809385\ttotal: 371ms\tremaining: 569ms\n",
      "62:\tlearn: 0.0776073\ttotal: 374ms\tremaining: 558ms\n",
      "63:\tlearn: 0.0754645\ttotal: 377ms\tremaining: 548ms\n",
      "64:\tlearn: 0.0730512\ttotal: 380ms\tremaining: 538ms\n",
      "65:\tlearn: 0.0719572\ttotal: 383ms\tremaining: 529ms\n",
      "66:\tlearn: 0.0715500\ttotal: 386ms\tremaining: 519ms\n",
      "67:\tlearn: 0.0689079\ttotal: 389ms\tremaining: 509ms\n",
      "68:\tlearn: 0.0679511\ttotal: 391ms\tremaining: 499ms\n",
      "69:\tlearn: 0.0678302\ttotal: 394ms\tremaining: 490ms\n",
      "70:\tlearn: 0.0652616\ttotal: 397ms\tremaining: 480ms\n",
      "71:\tlearn: 0.0647436\ttotal: 400ms\tremaining: 472ms\n",
      "72:\tlearn: 0.0630006\ttotal: 402ms\tremaining: 463ms\n",
      "73:\tlearn: 0.0609578\ttotal: 405ms\tremaining: 454ms\n",
      "74:\tlearn: 0.0579547\ttotal: 408ms\tremaining: 446ms\n",
      "75:\tlearn: 0.0578306\ttotal: 411ms\tremaining: 438ms\n",
      "76:\tlearn: 0.0560615\ttotal: 414ms\tremaining: 430ms\n",
      "77:\tlearn: 0.0558615\ttotal: 416ms\tremaining: 422ms\n",
      "78:\tlearn: 0.0556148\ttotal: 419ms\tremaining: 414ms\n",
      "79:\tlearn: 0.0554682\ttotal: 421ms\tremaining: 406ms\n",
      "80:\tlearn: 0.0522459\ttotal: 424ms\tremaining: 398ms\n",
      "81:\tlearn: 0.0500380\ttotal: 427ms\tremaining: 390ms\n",
      "82:\tlearn: 0.0499186\ttotal: 430ms\tremaining: 383ms\n",
      "83:\tlearn: 0.0480664\ttotal: 433ms\tremaining: 376ms\n",
      "84:\tlearn: 0.0460544\ttotal: 436ms\tremaining: 369ms\n",
      "85:\tlearn: 0.0458334\ttotal: 439ms\tremaining: 362ms\n",
      "86:\tlearn: 0.0456997\ttotal: 442ms\tremaining: 355ms\n",
      "87:\tlearn: 0.0442871\ttotal: 444ms\tremaining: 348ms\n",
      "88:\tlearn: 0.0442041\ttotal: 447ms\tremaining: 342ms\n",
      "89:\tlearn: 0.0438011\ttotal: 450ms\tremaining: 335ms\n",
      "90:\tlearn: 0.0437200\ttotal: 453ms\tremaining: 328ms\n",
      "91:\tlearn: 0.0422724\ttotal: 456ms\tremaining: 322ms\n",
      "92:\tlearn: 0.0421891\ttotal: 458ms\tremaining: 315ms\n",
      "93:\tlearn: 0.0420732\ttotal: 461ms\tremaining: 309ms\n",
      "94:\tlearn: 0.0403212\ttotal: 464ms\tremaining: 303ms\n",
      "95:\tlearn: 0.0402370\ttotal: 466ms\tremaining: 296ms\n",
      "96:\tlearn: 0.0401347\ttotal: 469ms\tremaining: 290ms\n",
      "97:\tlearn: 0.0400703\ttotal: 472ms\tremaining: 284ms\n",
      "98:\tlearn: 0.0399508\ttotal: 475ms\tremaining: 278ms\n",
      "99:\tlearn: 0.0379570\ttotal: 478ms\tremaining: 272ms\n",
      "100:\tlearn: 0.0379086\ttotal: 481ms\tremaining: 266ms\n",
      "101:\tlearn: 0.0367193\ttotal: 483ms\tremaining: 261ms\n",
      "102:\tlearn: 0.0355959\ttotal: 487ms\tremaining: 255ms\n",
      "103:\tlearn: 0.0354945\ttotal: 490ms\tremaining: 249ms\n",
      "104:\tlearn: 0.0354429\ttotal: 492ms\tremaining: 244ms\n",
      "105:\tlearn: 0.0353195\ttotal: 495ms\tremaining: 238ms\n",
      "106:\tlearn: 0.0352555\ttotal: 498ms\tremaining: 233ms\n",
      "107:\tlearn: 0.0352072\ttotal: 501ms\tremaining: 227ms\n",
      "108:\tlearn: 0.0351636\ttotal: 503ms\tremaining: 222ms\n",
      "109:\tlearn: 0.0349037\ttotal: 506ms\tremaining: 216ms\n",
      "110:\tlearn: 0.0348653\ttotal: 508ms\tremaining: 211ms\n",
      "111:\tlearn: 0.0339863\ttotal: 511ms\tremaining: 205ms\n",
      "112:\tlearn: 0.0337658\ttotal: 514ms\tremaining: 200ms\n",
      "113:\tlearn: 0.0329697\ttotal: 517ms\tremaining: 195ms\n",
      "114:\tlearn: 0.0329316\ttotal: 520ms\tremaining: 190ms\n",
      "115:\tlearn: 0.0328828\ttotal: 522ms\tremaining: 185ms\n",
      "116:\tlearn: 0.0325841\ttotal: 525ms\tremaining: 180ms\n",
      "117:\tlearn: 0.0325491\ttotal: 528ms\tremaining: 175ms\n",
      "118:\tlearn: 0.0324973\ttotal: 531ms\tremaining: 169ms\n",
      "119:\tlearn: 0.0322637\ttotal: 533ms\tremaining: 164ms\n",
      "120:\tlearn: 0.0322127\ttotal: 536ms\tremaining: 159ms\n",
      "121:\tlearn: 0.0321718\ttotal: 539ms\tremaining: 155ms\n",
      "122:\tlearn: 0.0312752\ttotal: 542ms\tremaining: 150ms\n",
      "123:\tlearn: 0.0312396\ttotal: 544ms\tremaining: 145ms\n",
      "124:\tlearn: 0.0298146\ttotal: 547ms\tremaining: 140ms\n",
      "125:\tlearn: 0.0296665\ttotal: 550ms\tremaining: 135ms\n",
      "126:\tlearn: 0.0296328\ttotal: 553ms\tremaining: 131ms\n",
      "127:\tlearn: 0.0296015\ttotal: 555ms\tremaining: 126ms\n",
      "128:\tlearn: 0.0295781\ttotal: 558ms\tremaining: 121ms\n",
      "129:\tlearn: 0.0292467\ttotal: 561ms\tremaining: 117ms\n",
      "130:\tlearn: 0.0291847\ttotal: 564ms\tremaining: 112ms\n",
      "131:\tlearn: 0.0291442\ttotal: 566ms\tremaining: 107ms\n",
      "132:\tlearn: 0.0290932\ttotal: 569ms\tremaining: 103ms\n",
      "133:\tlearn: 0.0290645\ttotal: 572ms\tremaining: 98.1ms\n",
      "134:\tlearn: 0.0290400\ttotal: 575ms\tremaining: 93.6ms\n",
      "135:\tlearn: 0.0290120\ttotal: 577ms\tremaining: 89.1ms\n",
      "136:\tlearn: 0.0289730\ttotal: 580ms\tremaining: 84.6ms\n",
      "137:\tlearn: 0.0289488\ttotal: 583ms\tremaining: 80.2ms\n",
      "138:\tlearn: 0.0288044\ttotal: 586ms\tremaining: 75.8ms\n",
      "139:\tlearn: 0.0287741\ttotal: 589ms\tremaining: 71.5ms\n",
      "140:\tlearn: 0.0278866\ttotal: 592ms\tremaining: 67.1ms\n",
      "141:\tlearn: 0.0278651\ttotal: 594ms\tremaining: 62.8ms\n",
      "142:\tlearn: 0.0275740\ttotal: 597ms\tremaining: 58.5ms\n",
      "143:\tlearn: 0.0275547\ttotal: 600ms\tremaining: 54.2ms\n",
      "144:\tlearn: 0.0268599\ttotal: 603ms\tremaining: 49.9ms\n",
      "145:\tlearn: 0.0268355\ttotal: 606ms\tremaining: 45.6ms\n",
      "146:\tlearn: 0.0268013\ttotal: 608ms\tremaining: 41.4ms\n",
      "147:\tlearn: 0.0267824\ttotal: 611ms\tremaining: 37.2ms\n",
      "148:\tlearn: 0.0267606\ttotal: 614ms\tremaining: 33ms\n",
      "149:\tlearn: 0.0261921\ttotal: 617ms\tremaining: 28.8ms\n",
      "150:\tlearn: 0.0261697\ttotal: 620ms\tremaining: 24.6ms\n",
      "151:\tlearn: 0.0253770\ttotal: 622ms\tremaining: 20.5ms\n",
      "152:\tlearn: 0.0253394\ttotal: 625ms\tremaining: 16.3ms\n",
      "153:\tlearn: 0.0251038\ttotal: 628ms\tremaining: 12.2ms\n",
      "154:\tlearn: 0.0247138\ttotal: 631ms\tremaining: 8.14ms\n",
      "155:\tlearn: 0.0246982\ttotal: 634ms\tremaining: 4.06ms\n",
      "156:\tlearn: 0.0246730\ttotal: 636ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:58:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5952836\ttotal: 5.79ms\tremaining: 864ms\n",
      "1:\tlearn: 0.4973173\ttotal: 9.04ms\tremaining: 669ms\n",
      "2:\tlearn: 0.4648350\ttotal: 12.3ms\tremaining: 602ms\n",
      "3:\tlearn: 0.4336742\ttotal: 16.8ms\tremaining: 612ms\n",
      "4:\tlearn: 0.3834334\ttotal: 21.2ms\tremaining: 614ms\n",
      "5:\tlearn: 0.3636911\ttotal: 24.8ms\tremaining: 596ms\n",
      "6:\tlearn: 0.3361913\ttotal: 27.5ms\tremaining: 562ms\n",
      "7:\tlearn: 0.3155126\ttotal: 31ms\tremaining: 551ms\n",
      "8:\tlearn: 0.2994630\ttotal: 34.9ms\tremaining: 547ms\n",
      "9:\tlearn: 0.2761333\ttotal: 37.5ms\tremaining: 525ms\n",
      "10:\tlearn: 0.2568029\ttotal: 39.7ms\tremaining: 502ms\n",
      "11:\tlearn: 0.2454663\ttotal: 42.7ms\tremaining: 491ms\n",
      "12:\tlearn: 0.2328277\ttotal: 45.6ms\tremaining: 481ms\n",
      "13:\tlearn: 0.2277298\ttotal: 48.4ms\tremaining: 470ms\n",
      "14:\tlearn: 0.2202275\ttotal: 51.1ms\tremaining: 460ms\n",
      "15:\tlearn: 0.2169881\ttotal: 53.5ms\tremaining: 448ms\n",
      "16:\tlearn: 0.2141215\ttotal: 56.9ms\tremaining: 445ms\n",
      "17:\tlearn: 0.2082727\ttotal: 60.4ms\tremaining: 443ms\n",
      "18:\tlearn: 0.2036231\ttotal: 64ms\tremaining: 441ms\n",
      "19:\tlearn: 0.2007396\ttotal: 66ms\tremaining: 429ms\n",
      "20:\tlearn: 0.1935413\ttotal: 69.1ms\tremaining: 425ms\n",
      "21:\tlearn: 0.1923160\ttotal: 73ms\tremaining: 425ms\n",
      "22:\tlearn: 0.1909475\ttotal: 76.4ms\tremaining: 422ms\n",
      "23:\tlearn: 0.1888006\ttotal: 79.8ms\tremaining: 419ms\n",
      "24:\tlearn: 0.1880167\ttotal: 83.3ms\tremaining: 417ms\n",
      "25:\tlearn: 0.1864559\ttotal: 86.3ms\tremaining: 412ms\n",
      "26:\tlearn: 0.1824398\ttotal: 90.1ms\tremaining: 411ms\n",
      "27:\tlearn: 0.1764723\ttotal: 94.5ms\tremaining: 412ms\n",
      "28:\tlearn: 0.1727295\ttotal: 98.6ms\tremaining: 411ms\n",
      "29:\tlearn: 0.1663560\ttotal: 103ms\tremaining: 411ms\n",
      "30:\tlearn: 0.1647740\ttotal: 105ms\tremaining: 404ms\n",
      "31:\tlearn: 0.1633287\ttotal: 109ms\tremaining: 402ms\n",
      "32:\tlearn: 0.1617339\ttotal: 111ms\tremaining: 395ms\n",
      "33:\tlearn: 0.1591941\ttotal: 115ms\tremaining: 392ms\n",
      "34:\tlearn: 0.1580754\ttotal: 118ms\tremaining: 387ms\n",
      "35:\tlearn: 0.1570325\ttotal: 120ms\tremaining: 379ms\n",
      "36:\tlearn: 0.1560835\ttotal: 123ms\tremaining: 374ms\n",
      "37:\tlearn: 0.1518098\ttotal: 125ms\tremaining: 367ms\n",
      "38:\tlearn: 0.1477931\ttotal: 127ms\tremaining: 361ms\n",
      "39:\tlearn: 0.1473913\ttotal: 129ms\tremaining: 355ms\n",
      "40:\tlearn: 0.1459093\ttotal: 132ms\tremaining: 350ms\n",
      "41:\tlearn: 0.1415825\ttotal: 134ms\tremaining: 345ms\n",
      "42:\tlearn: 0.1410155\ttotal: 137ms\tremaining: 340ms\n",
      "43:\tlearn: 0.1374472\ttotal: 139ms\tremaining: 335ms\n",
      "44:\tlearn: 0.1337679\ttotal: 141ms\tremaining: 330ms\n",
      "45:\tlearn: 0.1330278\ttotal: 144ms\tremaining: 325ms\n",
      "46:\tlearn: 0.1322403\ttotal: 146ms\tremaining: 320ms\n",
      "47:\tlearn: 0.1313075\ttotal: 148ms\tremaining: 315ms\n",
      "48:\tlearn: 0.1306992\ttotal: 150ms\tremaining: 309ms\n",
      "49:\tlearn: 0.1267299\ttotal: 152ms\tremaining: 303ms\n",
      "50:\tlearn: 0.1257482\ttotal: 154ms\tremaining: 298ms\n",
      "51:\tlearn: 0.1250895\ttotal: 156ms\tremaining: 294ms\n",
      "52:\tlearn: 0.1225322\ttotal: 159ms\tremaining: 290ms\n",
      "53:\tlearn: 0.1221967\ttotal: 162ms\tremaining: 288ms\n",
      "54:\tlearn: 0.1214408\ttotal: 166ms\tremaining: 287ms\n",
      "55:\tlearn: 0.1197281\ttotal: 168ms\tremaining: 282ms\n",
      "56:\tlearn: 0.1192920\ttotal: 170ms\tremaining: 277ms\n",
      "57:\tlearn: 0.1185601\ttotal: 172ms\tremaining: 273ms\n",
      "58:\tlearn: 0.1178840\ttotal: 174ms\tremaining: 269ms\n",
      "59:\tlearn: 0.1158389\ttotal: 177ms\tremaining: 265ms\n",
      "60:\tlearn: 0.1157624\ttotal: 179ms\tremaining: 261ms\n",
      "61:\tlearn: 0.1155598\ttotal: 181ms\tremaining: 257ms\n",
      "62:\tlearn: 0.1145613\ttotal: 183ms\tremaining: 253ms\n",
      "63:\tlearn: 0.1120083\ttotal: 186ms\tremaining: 249ms\n",
      "64:\tlearn: 0.1118228\ttotal: 188ms\tremaining: 245ms\n",
      "65:\tlearn: 0.1103590\ttotal: 190ms\tremaining: 242ms\n",
      "66:\tlearn: 0.1095802\ttotal: 192ms\tremaining: 238ms\n",
      "67:\tlearn: 0.1067896\ttotal: 194ms\tremaining: 234ms\n",
      "68:\tlearn: 0.1060431\ttotal: 198ms\tremaining: 232ms\n",
      "69:\tlearn: 0.1031167\ttotal: 201ms\tremaining: 230ms\n",
      "70:\tlearn: 0.0999281\ttotal: 205ms\tremaining: 228ms\n",
      "71:\tlearn: 0.0967396\ttotal: 209ms\tremaining: 226ms\n",
      "72:\tlearn: 0.0938891\ttotal: 212ms\tremaining: 223ms\n",
      "73:\tlearn: 0.0932744\ttotal: 214ms\tremaining: 220ms\n",
      "74:\tlearn: 0.0930098\ttotal: 216ms\tremaining: 216ms\n",
      "75:\tlearn: 0.0917028\ttotal: 219ms\tremaining: 213ms\n",
      "76:\tlearn: 0.0890357\ttotal: 221ms\tremaining: 209ms\n",
      "77:\tlearn: 0.0888267\ttotal: 223ms\tremaining: 206ms\n",
      "78:\tlearn: 0.0859026\ttotal: 225ms\tremaining: 203ms\n",
      "79:\tlearn: 0.0857472\ttotal: 228ms\tremaining: 199ms\n",
      "80:\tlearn: 0.0855554\ttotal: 232ms\tremaining: 198ms\n",
      "81:\tlearn: 0.0842331\ttotal: 235ms\tremaining: 195ms\n",
      "82:\tlearn: 0.0817575\ttotal: 238ms\tremaining: 192ms\n",
      "83:\tlearn: 0.0812163\ttotal: 241ms\tremaining: 189ms\n",
      "84:\tlearn: 0.0787790\ttotal: 244ms\tremaining: 186ms\n",
      "85:\tlearn: 0.0765222\ttotal: 247ms\tremaining: 184ms\n",
      "86:\tlearn: 0.0750049\ttotal: 251ms\tremaining: 182ms\n",
      "87:\tlearn: 0.0748219\ttotal: 255ms\tremaining: 180ms\n",
      "88:\tlearn: 0.0726443\ttotal: 259ms\tremaining: 178ms\n",
      "89:\tlearn: 0.0725441\ttotal: 263ms\tremaining: 175ms\n",
      "90:\tlearn: 0.0719809\ttotal: 266ms\tremaining: 172ms\n",
      "91:\tlearn: 0.0718935\ttotal: 284ms\tremaining: 179ms\n",
      "92:\tlearn: 0.0697155\ttotal: 286ms\tremaining: 175ms\n",
      "93:\tlearn: 0.0691082\ttotal: 289ms\tremaining: 172ms\n",
      "94:\tlearn: 0.0660472\ttotal: 291ms\tremaining: 168ms\n",
      "95:\tlearn: 0.0654353\ttotal: 294ms\tremaining: 165ms\n",
      "96:\tlearn: 0.0650494\ttotal: 298ms\tremaining: 163ms\n",
      "97:\tlearn: 0.0633531\ttotal: 301ms\tremaining: 160ms\n",
      "98:\tlearn: 0.0632048\ttotal: 303ms\tremaining: 156ms\n",
      "99:\tlearn: 0.0630674\ttotal: 307ms\tremaining: 153ms\n",
      "100:\tlearn: 0.0626862\ttotal: 310ms\tremaining: 150ms\n",
      "101:\tlearn: 0.0625401\ttotal: 312ms\tremaining: 147ms\n",
      "102:\tlearn: 0.0616063\ttotal: 314ms\tremaining: 143ms\n",
      "103:\tlearn: 0.0610539\ttotal: 317ms\tremaining: 140ms\n",
      "104:\tlearn: 0.0609631\ttotal: 319ms\tremaining: 137ms\n",
      "105:\tlearn: 0.0600080\ttotal: 322ms\tremaining: 134ms\n",
      "106:\tlearn: 0.0582873\ttotal: 325ms\tremaining: 131ms\n",
      "107:\tlearn: 0.0581703\ttotal: 328ms\tremaining: 128ms\n",
      "108:\tlearn: 0.0567106\ttotal: 331ms\tremaining: 124ms\n",
      "109:\tlearn: 0.0566107\ttotal: 333ms\tremaining: 121ms\n",
      "110:\tlearn: 0.0565151\ttotal: 336ms\tremaining: 118ms\n",
      "111:\tlearn: 0.0563551\ttotal: 338ms\tremaining: 115ms\n",
      "112:\tlearn: 0.0562766\ttotal: 342ms\tremaining: 112ms\n",
      "113:\tlearn: 0.0557241\ttotal: 344ms\tremaining: 109ms\n",
      "114:\tlearn: 0.0556355\ttotal: 347ms\tremaining: 106ms\n",
      "115:\tlearn: 0.0548780\ttotal: 352ms\tremaining: 103ms\n",
      "116:\tlearn: 0.0547894\ttotal: 354ms\tremaining: 100ms\n",
      "117:\tlearn: 0.0547148\ttotal: 357ms\tremaining: 96.7ms\n",
      "118:\tlearn: 0.0541439\ttotal: 360ms\tremaining: 93.8ms\n",
      "119:\tlearn: 0.0540840\ttotal: 363ms\tremaining: 90.8ms\n",
      "120:\tlearn: 0.0540352\ttotal: 366ms\tremaining: 87.8ms\n",
      "121:\tlearn: 0.0539358\ttotal: 371ms\tremaining: 85.1ms\n",
      "122:\tlearn: 0.0523509\ttotal: 373ms\tremaining: 81.9ms\n",
      "123:\tlearn: 0.0522990\ttotal: 375ms\tremaining: 78.6ms\n",
      "124:\tlearn: 0.0522332\ttotal: 378ms\tremaining: 75.7ms\n",
      "125:\tlearn: 0.0520699\ttotal: 382ms\tremaining: 72.8ms\n",
      "126:\tlearn: 0.0505573\ttotal: 386ms\tremaining: 69.9ms\n",
      "127:\tlearn: 0.0501038\ttotal: 389ms\tremaining: 66.9ms\n",
      "128:\tlearn: 0.0500228\ttotal: 392ms\tremaining: 63.8ms\n",
      "129:\tlearn: 0.0494829\ttotal: 394ms\tremaining: 60.6ms\n",
      "130:\tlearn: 0.0480696\ttotal: 397ms\tremaining: 57.6ms\n",
      "131:\tlearn: 0.0479822\ttotal: 400ms\tremaining: 54.6ms\n",
      "132:\tlearn: 0.0479332\ttotal: 402ms\tremaining: 51.4ms\n",
      "133:\tlearn: 0.0465379\ttotal: 405ms\tremaining: 48.3ms\n",
      "134:\tlearn: 0.0453945\ttotal: 407ms\tremaining: 45.2ms\n",
      "135:\tlearn: 0.0453505\ttotal: 409ms\tremaining: 42.1ms\n",
      "136:\tlearn: 0.0451471\ttotal: 412ms\tremaining: 39.1ms\n",
      "137:\tlearn: 0.0451098\ttotal: 423ms\tremaining: 36.8ms\n",
      "138:\tlearn: 0.0450636\ttotal: 430ms\tremaining: 34ms\n",
      "139:\tlearn: 0.0435139\ttotal: 435ms\tremaining: 31ms\n",
      "140:\tlearn: 0.0432296\ttotal: 440ms\tremaining: 28.1ms\n",
      "141:\tlearn: 0.0419710\ttotal: 443ms\tremaining: 25ms\n",
      "142:\tlearn: 0.0419356\ttotal: 447ms\tremaining: 21.9ms\n",
      "143:\tlearn: 0.0418891\ttotal: 450ms\tremaining: 18.7ms\n",
      "144:\tlearn: 0.0409485\ttotal: 454ms\tremaining: 15.7ms\n",
      "145:\tlearn: 0.0409052\ttotal: 457ms\tremaining: 12.5ms\n",
      "146:\tlearn: 0.0408693\ttotal: 460ms\tremaining: 9.38ms\n",
      "147:\tlearn: 0.0405581\ttotal: 463ms\tremaining: 6.26ms\n",
      "148:\tlearn: 0.0404958\ttotal: 466ms\tremaining: 3.13ms\n",
      "149:\tlearn: 0.0395982\ttotal: 469ms\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-06-18 19:58:31,741] A new study created in memory with name: no-name-6d45e91c-5996-46cb-8291-d44de7120e80\n",
      "[I 2025-06-18 19:58:31,854] Trial 0 finished with value: -0.9919687500000001 and parameters: {'C': 0.5611516415334505, 'penalty': 'l1'}. Best is trial 0 with value: -0.9919687500000001.\n",
      "[I 2025-06-18 19:58:32,122] Trial 1 finished with value: -0.98903125 and parameters: {'C': 1.5751320499779735, 'penalty': 'l1'}. Best is trial 0 with value: -0.9919687500000001.\n",
      "[I 2025-06-18 19:58:32,222] Trial 2 finished with value: -0.9942812499999999 and parameters: {'C': 0.13066739238053282, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:32,586] Trial 3 finished with value: -0.9751875 and parameters: {'C': 2.607024758370768, 'penalty': 'l2'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:33,179] Trial 4 finished with value: -0.9791874999999999 and parameters: {'C': 4.622589001020832, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:33,354] Trial 5 finished with value: -0.9745312500000001 and parameters: {'C': 0.2327067708383781, 'penalty': 'l2'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:33,578] Trial 6 finished with value: -0.9764375 and parameters: {'C': 0.7309539835912913, 'penalty': 'l2'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:33,766] Trial 7 finished with value: -0.97365625 and parameters: {'C': 0.19010245319870356, 'penalty': 'l2'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:33,926] Trial 8 finished with value: -0.9911562500000001 and parameters: {'C': 0.8168455894760165, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:34,112] Trial 9 finished with value: -0.99040625 and parameters: {'C': 1.0677482709481354, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:34,201] Trial 10 finished with value: -0.9942499999999999 and parameters: {'C': 0.10991587445851024, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:34,304] Trial 11 finished with value: -0.9942187499999999 and parameters: {'C': 0.10353677627159782, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:34,395] Trial 12 finished with value: -0.9942499999999999 and parameters: {'C': 0.10691887002123487, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:34,514] Trial 13 finished with value: -0.9933750000000001 and parameters: {'C': 0.31386613240444206, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:34,667] Trial 14 finished with value: -0.9933125 and parameters: {'C': 0.3231096964640978, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:39,970] Trial 15 finished with value: -0.9758749999999999 and parameters: {'C': 8.611382274356343, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942812499999999.\n",
      "[I 2025-06-18 19:58:40,079] Trial 16 finished with value: -0.99428125 and parameters: {'C': 0.1588471280716395, 'penalty': 'l1'}. Best is trial 16 with value: -0.99428125.\n",
      "[I 2025-06-18 19:58:40,204] Trial 17 finished with value: -0.9921562500000001 and parameters: {'C': 0.48420803007295715, 'penalty': 'l1'}. Best is trial 16 with value: -0.99428125.\n",
      "[I 2025-06-18 19:58:40,403] Trial 18 finished with value: -0.9733437500000001 and parameters: {'C': 0.1736216698299393, 'penalty': 'l2'}. Best is trial 16 with value: -0.99428125.\n",
      "[I 2025-06-18 19:58:40,527] Trial 19 finished with value: -0.993125 and parameters: {'C': 0.34196538382062763, 'penalty': 'l1'}. Best is trial 16 with value: -0.99428125.\n",
      "[I 2025-06-18 19:58:40,549] A new study created in memory with name: no-name-98b056dc-3f42-4710-940b-c5cdbbb95b2e\n",
      "[I 2025-06-18 19:58:43,576] Trial 0 finished with value: -0.9311250000000001 and parameters: {'n_estimators': 106, 'max_depth': 5, 'min_samples_split': 3}. Best is trial 0 with value: -0.9311250000000001.\n",
      "[I 2025-06-18 19:58:45,968] Trial 1 finished with value: -0.9267656250000001 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 0 with value: -0.9311250000000001.\n",
      "[I 2025-06-18 19:58:51,791] Trial 2 finished with value: -0.9491406249999998 and parameters: {'n_estimators': 175, 'max_depth': None, 'min_samples_split': 5}. Best is trial 2 with value: -0.9491406249999998.\n",
      "[I 2025-06-18 19:58:55,624] Trial 3 finished with value: -0.9442968749999998 and parameters: {'n_estimators': 115, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 2 with value: -0.9491406249999998.\n",
      "[I 2025-06-18 19:58:58,885] Trial 4 finished with value: -0.9309218749999999 and parameters: {'n_estimators': 118, 'max_depth': 5, 'min_samples_split': 2}. Best is trial 2 with value: -0.9491406249999998.\n",
      "[I 2025-06-18 19:59:03,620] Trial 5 finished with value: -0.9442343750000001 and parameters: {'n_estimators': 141, 'max_depth': None, 'min_samples_split': 7}. Best is trial 2 with value: -0.9491406249999998.\n",
      "[I 2025-06-18 19:59:06,621] Trial 6 finished with value: -0.9458437499999999 and parameters: {'n_estimators': 95, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 2 with value: -0.9491406249999998.\n",
      "[I 2025-06-18 19:59:08,053] Trial 7 finished with value: -0.9275625 and parameters: {'n_estimators': 55, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 2 with value: -0.9491406249999998.\n",
      "[I 2025-06-18 19:59:12,335] Trial 8 finished with value: -0.9453125 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 2 with value: -0.9491406249999998.\n",
      "[I 2025-06-18 19:59:16,925] Trial 9 finished with value: -0.9303125 and parameters: {'n_estimators': 140, 'max_depth': 5, 'min_samples_split': 4}. Best is trial 2 with value: -0.9491406249999998.\n",
      "[I 2025-06-18 19:59:23,517] Trial 10 finished with value: -0.9514687500000001 and parameters: {'n_estimators': 197, 'max_depth': None, 'min_samples_split': 6}. Best is trial 10 with value: -0.9514687500000001.\n",
      "[I 2025-06-18 19:59:30,101] Trial 11 finished with value: -0.9518125 and parameters: {'n_estimators': 193, 'max_depth': None, 'min_samples_split': 6}. Best is trial 11 with value: -0.9518125.\n",
      "[I 2025-06-18 19:59:37,309] Trial 12 finished with value: -0.947859375 and parameters: {'n_estimators': 198, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 11 with value: -0.9518125.\n",
      "[I 2025-06-18 19:59:44,257] Trial 13 finished with value: -0.95178125 and parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_split': 6}. Best is trial 11 with value: -0.9518125.\n",
      "[I 2025-06-18 19:59:48,768] Trial 14 finished with value: -0.9504843749999999 and parameters: {'n_estimators': 170, 'max_depth': None, 'min_samples_split': 6}. Best is trial 11 with value: -0.9518125.\n",
      "[I 2025-06-18 19:59:54,897] Trial 15 finished with value: -0.949984375 and parameters: {'n_estimators': 168, 'max_depth': None, 'min_samples_split': 6}. Best is trial 11 with value: -0.9518125.\n",
      "[I 2025-06-18 19:59:59,356] Trial 16 finished with value: -0.948140625 and parameters: {'n_estimators': 183, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 11 with value: -0.9518125.\n",
      "[I 2025-06-18 20:00:04,997] Trial 17 finished with value: -0.9454531249999999 and parameters: {'n_estimators': 154, 'max_depth': None, 'min_samples_split': 4}. Best is trial 11 with value: -0.9518125.\n",
      "[I 2025-06-18 20:00:10,863] Trial 18 finished with value: -0.9514999999999999 and parameters: {'n_estimators': 188, 'max_depth': None, 'min_samples_split': 6}. Best is trial 11 with value: -0.9518125.\n",
      "[I 2025-06-18 20:00:15,389] Trial 19 finished with value: -0.944953125 and parameters: {'n_estimators': 157, 'max_depth': None, 'min_samples_split': 7}. Best is trial 11 with value: -0.9518125.\n",
      "[I 2025-06-18 20:00:17,009] A new study created in memory with name: no-name-d1a07c9c-49a8-440f-9ea9-3bde86113c5b\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:17,641] Trial 0 finished with value: -0.996453125 and parameters: {'n_estimators': 106, 'learning_rate': 0.13125830316209655, 'max_depth': 7, 'subsample': 0.8795975452591109}. Best is trial 0 with value: -0.996453125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:17,976] Trial 1 finished with value: -0.98615625 and parameters: {'n_estimators': 73, 'learning_rate': 0.015256811898068502, 'max_depth': 3, 'subsample': 0.9598528437324805}. Best is trial 0 with value: -0.996453125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:18,523] Trial 2 finished with value: -0.9965625000000001 and parameters: {'n_estimators': 140, 'learning_rate': 0.06803900745073706, 'max_depth': 3, 'subsample': 0.9909729556485982}. Best is trial 2 with value: -0.9965625000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:19,497] Trial 3 finished with value: -0.996875 and parameters: {'n_estimators': 175, 'learning_rate': 0.01777174904859463, 'max_depth': 4, 'subsample': 0.7550213529560301}. Best is trial 3 with value: -0.996875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:20,153] Trial 4 finished with value: -0.9969531249999999 and parameters: {'n_estimators': 95, 'learning_rate': 0.04141536110538596, 'max_depth': 5, 'subsample': 0.7873687420594125}. Best is trial 4 with value: -0.9969531249999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:20,965] Trial 5 finished with value: -0.9957968749999999 and parameters: {'n_estimators': 142, 'learning_rate': 0.01459007452373112, 'max_depth': 4, 'subsample': 0.8099085529881075}. Best is trial 4 with value: -0.9969531249999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:21,549] Trial 6 finished with value: -0.996984375 and parameters: {'n_estimators': 118, 'learning_rate': 0.0838375512850209, 'max_depth': 4, 'subsample': 0.8542703315240835}. Best is trial 6 with value: -0.996984375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:22,672] Trial 7 finished with value: -0.9948750000000001 and parameters: {'n_estimators': 139, 'learning_rate': 0.011340440501807348, 'max_depth': 6, 'subsample': 0.7511572371061874}. Best is trial 6 with value: -0.996984375.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:23,128] Trial 8 finished with value: -0.99746875 and parameters: {'n_estimators': 59, 'learning_rate': 0.13060986669773664, 'max_depth': 8, 'subsample': 0.9425192044349383}. Best is trial 8 with value: -0.99746875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:23,992] Trial 9 finished with value: -0.993515625 and parameters: {'n_estimators': 95, 'learning_rate': 0.01302780710309028, 'max_depth': 7, 'subsample': 0.8320457481218804}. Best is trial 8 with value: -0.99746875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:24,536] Trial 10 finished with value: -0.994765625 and parameters: {'n_estimators': 53, 'learning_rate': 0.036030984219246213, 'max_depth': 8, 'subsample': 0.9128919539143554}. Best is trial 8 with value: -0.99746875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:25,423] Trial 11 finished with value: -0.996296875 and parameters: {'n_estimators': 193, 'learning_rate': 0.12417469486607885, 'max_depth': 5, 'subsample': 0.9065810606649454}. Best is trial 8 with value: -0.99746875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:26,016] Trial 12 finished with value: -0.9966875 and parameters: {'n_estimators': 61, 'learning_rate': 0.07652586248387556, 'max_depth': 8, 'subsample': 0.9327155113866203}. Best is trial 8 with value: -0.99746875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:27,134] Trial 13 finished with value: -0.9969531249999999 and parameters: {'n_estimators': 119, 'learning_rate': 0.08403594179220691, 'max_depth': 4, 'subsample': 0.8625449249209266}. Best is trial 8 with value: -0.99746875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:28,035] Trial 14 finished with value: -0.996859375 and parameters: {'n_estimators': 74, 'learning_rate': 0.14952897442121932, 'max_depth': 6, 'subsample': 0.9835971013569577}. Best is trial 8 with value: -0.99746875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:29,986] Trial 15 finished with value: -0.99728125 and parameters: {'n_estimators': 167, 'learning_rate': 0.04811828140117263, 'max_depth': 7, 'subsample': 0.8665400645377788}. Best is trial 8 with value: -0.99746875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:32,242] Trial 16 finished with value: -0.9970937500000001 and parameters: {'n_estimators': 166, 'learning_rate': 0.030589038012642903, 'max_depth': 7, 'subsample': 0.9418390726283843}. Best is trial 8 with value: -0.99746875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:34,275] Trial 17 finished with value: -0.9967656250000001 and parameters: {'n_estimators': 197, 'learning_rate': 0.051251660676620375, 'max_depth': 8, 'subsample': 0.7125575477446221}. Best is trial 8 with value: -0.99746875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:36,631] Trial 18 finished with value: -0.9970000000000001 and parameters: {'n_estimators': 170, 'learning_rate': 0.024478897732470608, 'max_depth': 7, 'subsample': 0.8898724237440068}. Best is trial 8 with value: -0.99746875.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:00:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:00:38,418] Trial 19 finished with value: -0.9969687500000001 and parameters: {'n_estimators': 155, 'learning_rate': 0.05584140934408378, 'max_depth': 8, 'subsample': 0.8248094400752194}. Best is trial 8 with value: -0.99746875.\n",
      "[I 2025-06-18 20:00:38,651] A new study created in memory with name: no-name-67907986-4b78-461c-b889-6b0b44683911\n",
      "[I 2025-06-18 20:00:44,663] Trial 0 finished with value: -0.9945468749999999 and parameters: {'iterations': 106, 'learning_rate': 0.13125830316209655, 'depth': 7, 'l2_leaf_reg': 0.6251373574521749}. Best is trial 0 with value: -0.9945468749999999.\n",
      "[I 2025-06-18 20:00:46,693] Trial 1 finished with value: -0.97946875 and parameters: {'iterations': 73, 'learning_rate': 0.015256811898068502, 'depth': 3, 'l2_leaf_reg': 3.9676050770529883}. Best is trial 0 with value: -0.9945468749999999.\n",
      "[I 2025-06-18 20:00:49,631] Trial 2 finished with value: -0.99490625 and parameters: {'iterations': 140, 'learning_rate': 0.06803900745073706, 'depth': 3, 'l2_leaf_reg': 8.123245085588687}. Best is trial 2 with value: -0.99490625.\n",
      "[I 2025-06-18 20:00:53,946] Trial 3 finished with value: -0.9897500000000001 and parameters: {'iterations': 175, 'learning_rate': 0.01777174904859463, 'depth': 4, 'l2_leaf_reg': 0.03549878832196503}. Best is trial 2 with value: -0.99490625.\n",
      "[I 2025-06-18 20:00:57,380] Trial 4 finished with value: -0.9917812500000001 and parameters: {'iterations': 95, 'learning_rate': 0.04141536110538596, 'depth': 5, 'l2_leaf_reg': 0.07476312062252301}. Best is trial 2 with value: -0.99490625.\n",
      "[I 2025-06-18 20:01:01,102] Trial 5 finished with value: -0.9876093750000001 and parameters: {'iterations': 142, 'learning_rate': 0.01459007452373112, 'depth': 4, 'l2_leaf_reg': 0.1256277350380703}. Best is trial 2 with value: -0.99490625.\n",
      "[I 2025-06-18 20:01:04,110] Trial 6 finished with value: -0.995671875 and parameters: {'iterations': 118, 'learning_rate': 0.0838375512850209, 'depth': 4, 'l2_leaf_reg': 0.34890188454913873}. Best is trial 6 with value: -0.995671875.\n",
      "[I 2025-06-18 20:01:09,945] Trial 7 finished with value: -0.98859375 and parameters: {'iterations': 139, 'learning_rate': 0.011340440501807348, 'depth': 6, 'l2_leaf_reg': 0.03247673570627449}. Best is trial 6 with value: -0.995671875.\n",
      "[I 2025-06-18 20:01:16,767] Trial 8 finished with value: -0.993375 and parameters: {'iterations': 59, 'learning_rate': 0.13060986669773664, 'depth': 8, 'l2_leaf_reg': 2.6619018884890564}. Best is trial 6 with value: -0.995671875.\n",
      "[I 2025-06-18 20:01:23,121] Trial 9 finished with value: -0.9881562500000001 and parameters: {'iterations': 95, 'learning_rate': 0.01302780710309028, 'depth': 7, 'l2_leaf_reg': 0.2091498132903561}. Best is trial 6 with value: -0.995671875.\n",
      "[I 2025-06-18 20:01:28,676] Trial 10 finished with value: -0.99634375 and parameters: {'iterations': 192, 'learning_rate': 0.06768269073143275, 'depth': 5, 'l2_leaf_reg': 0.8306050731972228}. Best is trial 10 with value: -0.99634375.\n",
      "[I 2025-06-18 20:01:34,397] Trial 11 finished with value: -0.9959999999999999 and parameters: {'iterations': 191, 'learning_rate': 0.06883422377244944, 'depth': 5, 'l2_leaf_reg': 0.7451617972708874}. Best is trial 10 with value: -0.99634375.\n",
      "[I 2025-06-18 20:01:40,741] Trial 12 finished with value: -0.99521875 and parameters: {'iterations': 198, 'learning_rate': 0.04374644112678987, 'depth': 5, 'l2_leaf_reg': 0.9394319614658106}. Best is trial 10 with value: -0.99634375.\n",
      "[I 2025-06-18 20:01:47,951] Trial 13 finished with value: -0.99565625 and parameters: {'iterations': 178, 'learning_rate': 0.06888026550127622, 'depth': 6, 'l2_leaf_reg': 1.1912184401562167}. Best is trial 10 with value: -0.99634375.\n",
      "[I 2025-06-18 20:01:54,072] Trial 14 finished with value: -0.9919062499999999 and parameters: {'iterations': 199, 'learning_rate': 0.026183290877026002, 'depth': 5, 'l2_leaf_reg': 1.9009789458942346}. Best is trial 10 with value: -0.99634375.\n",
      "[I 2025-06-18 20:01:59,997] Trial 15 finished with value: -0.9956250000000001 and parameters: {'iterations': 168, 'learning_rate': 0.08604130823111787, 'depth': 6, 'l2_leaf_reg': 0.3076974779163993}. Best is trial 10 with value: -0.99634375.\n",
      "[I 2025-06-18 20:02:04,399] Trial 16 finished with value: -0.99546875 and parameters: {'iterations': 161, 'learning_rate': 0.05227010210162143, 'depth': 4, 'l2_leaf_reg': 0.45655940454458455}. Best is trial 10 with value: -0.99634375.\n",
      "[I 2025-06-18 20:02:14,107] Trial 17 finished with value: -0.99084375 and parameters: {'iterations': 189, 'learning_rate': 0.029871122812052682, 'depth': 7, 'l2_leaf_reg': 0.016180153184398118}. Best is trial 10 with value: -0.99634375.\n",
      "[I 2025-06-18 20:02:19,622] Trial 18 finished with value: -0.99690625 and parameters: {'iterations': 161, 'learning_rate': 0.10643739208019755, 'depth': 5, 'l2_leaf_reg': 9.604466184865705}. Best is trial 18 with value: -0.99690625.\n",
      "[I 2025-06-18 20:02:28,167] Trial 19 finished with value: -0.9968124999999999 and parameters: {'iterations': 153, 'learning_rate': 0.10858551418200046, 'depth': 6, 'l2_leaf_reg': 9.728613904848126}. Best is trial 18 with value: -0.99690625.\n",
      "[I 2025-06-18 20:02:29,151] A new study created in memory with name: no-name-757d5caa-78d8-4b19-860c-47764004f691\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:02:59,090] Trial 0 finished with value: -0.9524374999999999 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 2.9380279387035334e-05, 'learning_rate_init': 0.00020511104188433984}. Best is trial 0 with value: -0.9524374999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:03:01,956] Trial 1 finished with value: -0.9480625 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.1527987128232396e-05, 'learning_rate_init': 0.008706020878304856}. Best is trial 0 with value: -0.9524374999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:03:11,706] Trial 2 finished with value: -0.9516875 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 8.17949947521167e-05, 'learning_rate_init': 0.0011207606211860567}. Best is trial 0 with value: -0.9524374999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:03:21,130] Trial 3 finished with value: -0.9444687500000001 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 7.52374288453485e-05, 'learning_rate_init': 0.0005404103854647331}. Best is trial 0 with value: -0.9524374999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:05:22,461] Trial 4 finished with value: -0.9441875 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0005987474910461401, 'learning_rate_init': 0.0001238513729886094}. Best is trial 0 with value: -0.9524374999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:05:25,390] Trial 5 finished with value: -0.9535625 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00788671412999049, 'learning_rate_init': 0.004138040112561018}. Best is trial 5 with value: -0.9535625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:05:37,312] Trial 6 finished with value: -0.9488125000000001 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 2.32335035153901e-05, 'learning_rate_init': 0.0009780337016659412}. Best is trial 5 with value: -0.9535625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:05:44,065] Trial 7 finished with value: -0.9534375 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 8.612579192594876e-05, 'learning_rate_init': 0.001096821720752952}. Best is trial 5 with value: -0.9535625.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:05:45,726] Trial 8 finished with value: -0.9545 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.006584106160121612, 'learning_rate_init': 0.006161049539380964}. Best is trial 8 with value: -0.9545.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:00,208] Trial 9 finished with value: -0.9568750000000001 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.3667272915456215e-05, 'learning_rate_init': 0.0004473636174621269}. Best is trial 9 with value: -0.9568750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:10,788] Trial 10 finished with value: -0.9510625000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0006014902816498304, 'learning_rate_init': 0.00033808702271313697}. Best is trial 9 with value: -0.9568750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:13,170] Trial 11 finished with value: -0.9502812500000001 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.008945871352431137, 'learning_rate_init': 0.002926824547308428}. Best is trial 9 with value: -0.9568750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:15,713] Trial 12 finished with value: -0.95040625 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0025168145109706035, 'learning_rate_init': 0.003085473344630515}. Best is trial 9 with value: -0.9568750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:17,358] Trial 13 finished with value: -0.9522187500000001 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.0019872654239216168, 'learning_rate_init': 0.007791470666172783}. Best is trial 9 with value: -0.9568750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:29,668] Trial 14 finished with value: -0.9518125000000002 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0002783993944853351, 'learning_rate_init': 0.0005110020964799216}. Best is trial 9 with value: -0.9568750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:32,538] Trial 15 finished with value: -0.9483124999999999 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.0019736655646175076, 'learning_rate_init': 0.0018882488237491014}. Best is trial 9 with value: -0.9568750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:06:48,807] Trial 16 finished with value: -0.95465625 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0002090089871732001, 'learning_rate_init': 0.00027955064538545774}. Best is trial 9 with value: -0.9568750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:07:04,802] Trial 17 finished with value: -0.9516249999999999 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.00025475085875100665, 'learning_rate_init': 0.000240351573906346}. Best is trial 9 with value: -0.9568750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:07:31,829] Trial 18 finished with value: -0.9427187499999998 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 1.261123605460073e-05, 'learning_rate_init': 0.0001034292709763673}. Best is trial 9 with value: -0.9568750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:07:45,592] Trial 19 finished with value: -0.9553125 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 4.1067868659421945e-05, 'learning_rate_init': 0.0005216219346854688}. Best is trial 9 with value: -0.9568750000000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Оптимизация для is_IC50_above_median (Manual Aggregated):   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:08:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5443723\ttotal: 20.1ms\tremaining: 3.89s\n",
      "1:\tlearn: 0.4674532\ttotal: 36.6ms\tremaining: 3.53s\n",
      "2:\tlearn: 0.4108495\ttotal: 52ms\tremaining: 3.33s\n",
      "3:\tlearn: 0.3504593\ttotal: 65.6ms\tremaining: 3.13s\n",
      "4:\tlearn: 0.2943133\ttotal: 82.6ms\tremaining: 3.14s\n",
      "5:\tlearn: 0.2692165\ttotal: 99.1ms\tremaining: 3.12s\n",
      "6:\tlearn: 0.2407492\ttotal: 117ms\tremaining: 3.13s\n",
      "7:\tlearn: 0.2133430\ttotal: 131ms\tremaining: 3.05s\n",
      "8:\tlearn: 0.1915312\ttotal: 148ms\tremaining: 3.07s\n",
      "9:\tlearn: 0.1773700\ttotal: 166ms\tremaining: 3.08s\n",
      "10:\tlearn: 0.1702044\ttotal: 182ms\tremaining: 3.05s\n",
      "11:\tlearn: 0.1583185\ttotal: 197ms\tremaining: 3s\n",
      "12:\tlearn: 0.1454622\ttotal: 212ms\tremaining: 2.96s\n",
      "13:\tlearn: 0.1385104\ttotal: 229ms\tremaining: 2.96s\n",
      "14:\tlearn: 0.1367946\ttotal: 244ms\tremaining: 2.92s\n",
      "15:\tlearn: 0.1279835\ttotal: 261ms\tremaining: 2.92s\n",
      "16:\tlearn: 0.1223797\ttotal: 280ms\tremaining: 2.93s\n",
      "17:\tlearn: 0.1190101\ttotal: 295ms\tremaining: 2.9s\n",
      "18:\tlearn: 0.1169887\ttotal: 312ms\tremaining: 2.89s\n",
      "19:\tlearn: 0.1108294\ttotal: 329ms\tremaining: 2.88s\n",
      "20:\tlearn: 0.1060164\ttotal: 346ms\tremaining: 2.86s\n",
      "21:\tlearn: 0.1028599\ttotal: 366ms\tremaining: 2.88s\n",
      "22:\tlearn: 0.0986333\ttotal: 382ms\tremaining: 2.85s\n",
      "23:\tlearn: 0.0959485\ttotal: 398ms\tremaining: 2.83s\n",
      "24:\tlearn: 0.0913932\ttotal: 415ms\tremaining: 2.82s\n",
      "25:\tlearn: 0.0873005\ttotal: 433ms\tremaining: 2.81s\n",
      "26:\tlearn: 0.0831770\ttotal: 452ms\tremaining: 2.81s\n",
      "27:\tlearn: 0.0793435\ttotal: 471ms\tremaining: 2.81s\n",
      "28:\tlearn: 0.0790334\ttotal: 487ms\tremaining: 2.79s\n",
      "29:\tlearn: 0.0781112\ttotal: 503ms\tremaining: 2.76s\n",
      "30:\tlearn: 0.0767506\ttotal: 523ms\tremaining: 2.77s\n",
      "31:\tlearn: 0.0745320\ttotal: 559ms\tremaining: 2.85s\n",
      "32:\tlearn: 0.0744448\ttotal: 580ms\tremaining: 2.85s\n",
      "33:\tlearn: 0.0728162\ttotal: 604ms\tremaining: 2.86s\n",
      "34:\tlearn: 0.0719841\ttotal: 621ms\tremaining: 2.84s\n",
      "35:\tlearn: 0.0706839\ttotal: 639ms\tremaining: 2.82s\n",
      "36:\tlearn: 0.0683086\ttotal: 666ms\tremaining: 2.84s\n",
      "37:\tlearn: 0.0677457\ttotal: 685ms\tremaining: 2.83s\n",
      "38:\tlearn: 0.0661466\ttotal: 704ms\tremaining: 2.82s\n",
      "39:\tlearn: 0.0641760\ttotal: 721ms\tremaining: 2.79s\n",
      "40:\tlearn: 0.0637394\ttotal: 740ms\tremaining: 2.78s\n",
      "41:\tlearn: 0.0615923\ttotal: 759ms\tremaining: 2.76s\n",
      "42:\tlearn: 0.0598585\ttotal: 775ms\tremaining: 2.74s\n",
      "43:\tlearn: 0.0572679\ttotal: 792ms\tremaining: 2.72s\n",
      "44:\tlearn: 0.0559823\ttotal: 808ms\tremaining: 2.69s\n",
      "45:\tlearn: 0.0532288\ttotal: 825ms\tremaining: 2.67s\n",
      "46:\tlearn: 0.0504821\ttotal: 841ms\tremaining: 2.65s\n",
      "47:\tlearn: 0.0503342\ttotal: 858ms\tremaining: 2.63s\n",
      "48:\tlearn: 0.0501938\ttotal: 875ms\tremaining: 2.61s\n",
      "49:\tlearn: 0.0486666\ttotal: 891ms\tremaining: 2.58s\n",
      "50:\tlearn: 0.0484073\ttotal: 907ms\tremaining: 2.56s\n",
      "51:\tlearn: 0.0481588\ttotal: 924ms\tremaining: 2.54s\n",
      "52:\tlearn: 0.0480401\ttotal: 943ms\tremaining: 2.53s\n",
      "53:\tlearn: 0.0478995\ttotal: 959ms\tremaining: 2.5s\n",
      "54:\tlearn: 0.0450544\ttotal: 976ms\tremaining: 2.48s\n",
      "55:\tlearn: 0.0426794\ttotal: 993ms\tremaining: 2.46s\n",
      "56:\tlearn: 0.0423287\ttotal: 1.01s\tremaining: 2.45s\n",
      "57:\tlearn: 0.0383509\ttotal: 1.03s\tremaining: 2.43s\n",
      "58:\tlearn: 0.0382324\ttotal: 1.04s\tremaining: 2.41s\n",
      "59:\tlearn: 0.0381002\ttotal: 1.06s\tremaining: 2.39s\n",
      "60:\tlearn: 0.0357363\ttotal: 1.08s\tremaining: 2.37s\n",
      "61:\tlearn: 0.0336272\ttotal: 1.09s\tremaining: 2.35s\n",
      "62:\tlearn: 0.0334279\ttotal: 1.11s\tremaining: 2.33s\n",
      "63:\tlearn: 0.0333520\ttotal: 1.13s\tremaining: 2.3s\n",
      "64:\tlearn: 0.0332641\ttotal: 1.14s\tremaining: 2.28s\n",
      "65:\tlearn: 0.0331707\ttotal: 1.15s\tremaining: 2.26s\n",
      "66:\tlearn: 0.0331051\ttotal: 1.16s\tremaining: 2.22s\n",
      "67:\tlearn: 0.0308879\ttotal: 1.18s\tremaining: 2.21s\n",
      "68:\tlearn: 0.0292556\ttotal: 1.2s\tremaining: 2.19s\n",
      "69:\tlearn: 0.0291293\ttotal: 1.21s\tremaining: 2.17s\n",
      "70:\tlearn: 0.0290691\ttotal: 1.23s\tremaining: 2.15s\n",
      "71:\tlearn: 0.0290106\ttotal: 1.25s\tremaining: 2.13s\n",
      "72:\tlearn: 0.0289601\ttotal: 1.26s\tremaining: 2.11s\n",
      "73:\tlearn: 0.0288715\ttotal: 1.28s\tremaining: 2.09s\n",
      "74:\tlearn: 0.0274451\ttotal: 1.3s\tremaining: 2.07s\n",
      "75:\tlearn: 0.0273958\ttotal: 1.31s\tremaining: 2.06s\n",
      "76:\tlearn: 0.0273392\ttotal: 1.33s\tremaining: 2.04s\n",
      "77:\tlearn: 0.0259323\ttotal: 1.35s\tremaining: 2.02s\n",
      "78:\tlearn: 0.0247322\ttotal: 1.37s\tremaining: 2.01s\n",
      "79:\tlearn: 0.0246852\ttotal: 1.39s\tremaining: 1.99s\n",
      "80:\tlearn: 0.0246430\ttotal: 1.4s\tremaining: 1.97s\n",
      "81:\tlearn: 0.0246050\ttotal: 1.42s\tremaining: 1.96s\n",
      "82:\tlearn: 0.0245639\ttotal: 1.44s\tremaining: 1.94s\n",
      "83:\tlearn: 0.0242157\ttotal: 1.46s\tremaining: 1.92s\n",
      "84:\tlearn: 0.0241744\ttotal: 1.47s\tremaining: 1.9s\n",
      "85:\tlearn: 0.0234578\ttotal: 1.49s\tremaining: 1.89s\n",
      "86:\tlearn: 0.0234222\ttotal: 1.5s\tremaining: 1.87s\n",
      "87:\tlearn: 0.0223990\ttotal: 1.52s\tremaining: 1.85s\n",
      "88:\tlearn: 0.0223690\ttotal: 1.53s\tremaining: 1.83s\n",
      "89:\tlearn: 0.0223374\ttotal: 1.55s\tremaining: 1.81s\n",
      "90:\tlearn: 0.0216506\ttotal: 1.56s\tremaining: 1.79s\n",
      "91:\tlearn: 0.0216193\ttotal: 1.58s\tremaining: 1.77s\n",
      "92:\tlearn: 0.0213127\ttotal: 1.6s\tremaining: 1.75s\n",
      "93:\tlearn: 0.0200005\ttotal: 1.62s\tremaining: 1.74s\n",
      "94:\tlearn: 0.0197927\ttotal: 1.64s\tremaining: 1.73s\n",
      "95:\tlearn: 0.0197629\ttotal: 1.66s\tremaining: 1.71s\n",
      "96:\tlearn: 0.0186015\ttotal: 1.67s\tremaining: 1.69s\n",
      "97:\tlearn: 0.0185575\ttotal: 1.69s\tremaining: 1.67s\n",
      "98:\tlearn: 0.0185353\ttotal: 1.7s\tremaining: 1.65s\n",
      "99:\tlearn: 0.0185136\ttotal: 1.72s\tremaining: 1.63s\n",
      "100:\tlearn: 0.0175803\ttotal: 1.73s\tremaining: 1.61s\n",
      "101:\tlearn: 0.0175584\ttotal: 1.74s\tremaining: 1.59s\n",
      "102:\tlearn: 0.0175359\ttotal: 1.75s\tremaining: 1.56s\n",
      "103:\tlearn: 0.0165558\ttotal: 1.76s\tremaining: 1.54s\n",
      "104:\tlearn: 0.0159825\ttotal: 1.77s\tremaining: 1.52s\n",
      "105:\tlearn: 0.0159725\ttotal: 1.78s\tremaining: 1.5s\n",
      "106:\tlearn: 0.0156112\ttotal: 1.79s\tremaining: 1.48s\n",
      "107:\tlearn: 0.0156058\ttotal: 1.8s\tremaining: 1.45s\n",
      "108:\tlearn: 0.0155915\ttotal: 1.82s\tremaining: 1.43s\n",
      "109:\tlearn: 0.0149060\ttotal: 1.83s\tremaining: 1.41s\n",
      "110:\tlearn: 0.0146478\ttotal: 1.84s\tremaining: 1.39s\n",
      "111:\tlearn: 0.0142321\ttotal: 1.85s\tremaining: 1.37s\n",
      "112:\tlearn: 0.0142276\ttotal: 1.86s\tremaining: 1.35s\n",
      "113:\tlearn: 0.0142149\ttotal: 1.87s\tremaining: 1.33s\n",
      "114:\tlearn: 0.0137880\ttotal: 1.88s\tremaining: 1.31s\n",
      "115:\tlearn: 0.0136515\ttotal: 1.89s\tremaining: 1.29s\n",
      "116:\tlearn: 0.0136325\ttotal: 1.9s\tremaining: 1.27s\n",
      "117:\tlearn: 0.0132883\ttotal: 1.91s\tremaining: 1.25s\n",
      "118:\tlearn: 0.0132752\ttotal: 1.93s\tremaining: 1.23s\n",
      "119:\tlearn: 0.0132627\ttotal: 1.94s\tremaining: 1.21s\n",
      "120:\tlearn: 0.0132507\ttotal: 1.95s\tremaining: 1.19s\n",
      "121:\tlearn: 0.0129014\ttotal: 1.96s\tremaining: 1.17s\n",
      "122:\tlearn: 0.0128885\ttotal: 1.97s\tremaining: 1.15s\n",
      "123:\tlearn: 0.0128770\ttotal: 1.98s\tremaining: 1.13s\n",
      "124:\tlearn: 0.0128661\ttotal: 1.99s\tremaining: 1.11s\n",
      "125:\tlearn: 0.0124805\ttotal: 2s\tremaining: 1.09s\n",
      "126:\tlearn: 0.0124683\ttotal: 2.01s\tremaining: 1.08s\n",
      "127:\tlearn: 0.0124578\ttotal: 2.02s\tremaining: 1.06s\n",
      "128:\tlearn: 0.0124471\ttotal: 2.04s\tremaining: 1.04s\n",
      "129:\tlearn: 0.0124361\ttotal: 2.05s\tremaining: 1.03s\n",
      "130:\tlearn: 0.0124250\ttotal: 2.06s\tremaining: 1.01s\n",
      "131:\tlearn: 0.0124145\ttotal: 2.08s\tremaining: 991ms\n",
      "132:\tlearn: 0.0122191\ttotal: 2.09s\tremaining: 975ms\n",
      "133:\tlearn: 0.0119645\ttotal: 2.1s\tremaining: 958ms\n",
      "134:\tlearn: 0.0119543\ttotal: 2.12s\tremaining: 942ms\n",
      "135:\tlearn: 0.0116518\ttotal: 2.13s\tremaining: 925ms\n",
      "136:\tlearn: 0.0116516\ttotal: 2.15s\tremaining: 908ms\n",
      "137:\tlearn: 0.0114697\ttotal: 2.16s\tremaining: 891ms\n",
      "138:\tlearn: 0.0114615\ttotal: 2.17s\tremaining: 873ms\n",
      "139:\tlearn: 0.0110319\ttotal: 2.18s\tremaining: 856ms\n",
      "140:\tlearn: 0.0110091\ttotal: 2.19s\tremaining: 839ms\n",
      "141:\tlearn: 0.0109962\ttotal: 2.2s\tremaining: 822ms\n",
      "142:\tlearn: 0.0105586\ttotal: 2.21s\tremaining: 806ms\n",
      "143:\tlearn: 0.0101279\ttotal: 2.23s\tremaining: 789ms\n",
      "144:\tlearn: 0.0100933\ttotal: 2.24s\tremaining: 772ms\n",
      "145:\tlearn: 0.0100917\ttotal: 2.25s\tremaining: 755ms\n",
      "146:\tlearn: 0.0100706\ttotal: 2.26s\tremaining: 738ms\n",
      "147:\tlearn: 0.0098542\ttotal: 2.27s\tremaining: 722ms\n",
      "148:\tlearn: 0.0097748\ttotal: 2.29s\tremaining: 706ms\n",
      "149:\tlearn: 0.0095419\ttotal: 2.3s\tremaining: 690ms\n",
      "150:\tlearn: 0.0095420\ttotal: 2.31s\tremaining: 673ms\n",
      "151:\tlearn: 0.0095418\ttotal: 2.32s\tremaining: 657ms\n",
      "152:\tlearn: 0.0095353\ttotal: 2.33s\tremaining: 641ms\n",
      "153:\tlearn: 0.0095350\ttotal: 2.35s\tremaining: 624ms\n",
      "154:\tlearn: 0.0095278\ttotal: 2.35s\tremaining: 608ms\n",
      "155:\tlearn: 0.0094260\ttotal: 2.37s\tremaining: 592ms\n",
      "156:\tlearn: 0.0094259\ttotal: 2.38s\tremaining: 576ms\n",
      "157:\tlearn: 0.0094206\ttotal: 2.39s\tremaining: 561ms\n",
      "158:\tlearn: 0.0094109\ttotal: 2.41s\tremaining: 545ms\n",
      "159:\tlearn: 0.0091948\ttotal: 2.42s\tremaining: 530ms\n",
      "160:\tlearn: 0.0090084\ttotal: 2.43s\tremaining: 514ms\n",
      "161:\tlearn: 0.0089644\ttotal: 2.44s\tremaining: 498ms\n",
      "162:\tlearn: 0.0088526\ttotal: 2.46s\tremaining: 483ms\n",
      "163:\tlearn: 0.0088525\ttotal: 2.47s\tremaining: 467ms\n",
      "164:\tlearn: 0.0088447\ttotal: 2.48s\tremaining: 451ms\n",
      "165:\tlearn: 0.0088402\ttotal: 2.5s\tremaining: 436ms\n",
      "166:\tlearn: 0.0088402\ttotal: 2.51s\tremaining: 420ms\n",
      "167:\tlearn: 0.0088402\ttotal: 2.52s\tremaining: 405ms\n",
      "168:\tlearn: 0.0088402\ttotal: 2.54s\tremaining: 390ms\n",
      "169:\tlearn: 0.0088401\ttotal: 2.55s\tremaining: 375ms\n",
      "170:\tlearn: 0.0088400\ttotal: 2.56s\tremaining: 360ms\n",
      "171:\tlearn: 0.0088334\ttotal: 2.58s\tremaining: 345ms\n",
      "172:\tlearn: 0.0088333\ttotal: 2.59s\tremaining: 329ms\n",
      "173:\tlearn: 0.0088259\ttotal: 2.6s\tremaining: 314ms\n",
      "174:\tlearn: 0.0086501\ttotal: 2.64s\tremaining: 302ms\n",
      "175:\tlearn: 0.0086501\ttotal: 2.65s\tremaining: 286ms\n",
      "176:\tlearn: 0.0086501\ttotal: 2.66s\tremaining: 271ms\n",
      "177:\tlearn: 0.0086423\ttotal: 2.67s\tremaining: 256ms\n",
      "178:\tlearn: 0.0084390\ttotal: 2.69s\tremaining: 240ms\n",
      "179:\tlearn: 0.0083510\ttotal: 2.7s\tremaining: 225ms\n",
      "180:\tlearn: 0.0083510\ttotal: 2.71s\tremaining: 210ms\n",
      "181:\tlearn: 0.0082849\ttotal: 2.73s\tremaining: 195ms\n",
      "182:\tlearn: 0.0082843\ttotal: 2.74s\tremaining: 180ms\n",
      "183:\tlearn: 0.0082842\ttotal: 2.75s\tremaining: 164ms\n",
      "184:\tlearn: 0.0082842\ttotal: 2.76s\tremaining: 149ms\n",
      "185:\tlearn: 0.0082840\ttotal: 2.77s\tremaining: 134ms\n",
      "186:\tlearn: 0.0082841\ttotal: 2.78s\tremaining: 119ms\n",
      "187:\tlearn: 0.0082840\ttotal: 2.8s\tremaining: 104ms\n",
      "188:\tlearn: 0.0082839\ttotal: 2.82s\tremaining: 89.4ms\n",
      "189:\tlearn: 0.0082839\ttotal: 2.83s\tremaining: 74.5ms\n",
      "190:\tlearn: 0.0082840\ttotal: 2.84s\tremaining: 59.5ms\n",
      "191:\tlearn: 0.0082840\ttotal: 2.85s\tremaining: 44.6ms\n",
      "192:\tlearn: 0.0082771\ttotal: 2.87s\tremaining: 29.7ms\n",
      "193:\tlearn: 0.0082757\ttotal: 2.88s\tremaining: 14.8ms\n",
      "194:\tlearn: 0.0082693\ttotal: 2.89s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:12:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5742767\ttotal: 35.1ms\tremaining: 5.22s\n",
      "1:\tlearn: 0.5126453\ttotal: 56.5ms\tremaining: 4.18s\n",
      "2:\tlearn: 0.4702074\ttotal: 91.9ms\tremaining: 4.5s\n",
      "3:\tlearn: 0.4224930\ttotal: 143ms\tremaining: 5.22s\n",
      "4:\tlearn: 0.3794949\ttotal: 183ms\tremaining: 5.31s\n",
      "5:\tlearn: 0.3351379\ttotal: 202ms\tremaining: 4.85s\n",
      "6:\tlearn: 0.3054938\ttotal: 218ms\tremaining: 4.46s\n",
      "7:\tlearn: 0.2758303\ttotal: 236ms\tremaining: 4.2s\n",
      "8:\tlearn: 0.2557748\ttotal: 246ms\tremaining: 3.85s\n",
      "9:\tlearn: 0.2450757\ttotal: 259ms\tremaining: 3.63s\n",
      "10:\tlearn: 0.2285643\ttotal: 271ms\tremaining: 3.43s\n",
      "11:\tlearn: 0.2167755\ttotal: 283ms\tremaining: 3.26s\n",
      "12:\tlearn: 0.2096851\ttotal: 297ms\tremaining: 3.13s\n",
      "13:\tlearn: 0.1957363\ttotal: 305ms\tremaining: 2.96s\n",
      "14:\tlearn: 0.1869194\ttotal: 316ms\tremaining: 2.85s\n",
      "15:\tlearn: 0.1791269\ttotal: 323ms\tremaining: 2.7s\n",
      "16:\tlearn: 0.1724016\ttotal: 335ms\tremaining: 2.62s\n",
      "17:\tlearn: 0.1686875\ttotal: 348ms\tremaining: 2.55s\n",
      "18:\tlearn: 0.1612928\ttotal: 356ms\tremaining: 2.45s\n",
      "19:\tlearn: 0.1526980\ttotal: 366ms\tremaining: 2.38s\n",
      "20:\tlearn: 0.1507518\ttotal: 381ms\tremaining: 2.34s\n",
      "21:\tlearn: 0.1433709\ttotal: 394ms\tremaining: 2.29s\n",
      "22:\tlearn: 0.1417406\ttotal: 409ms\tremaining: 2.25s\n",
      "23:\tlearn: 0.1396515\ttotal: 418ms\tremaining: 2.2s\n",
      "24:\tlearn: 0.1378956\ttotal: 431ms\tremaining: 2.15s\n",
      "25:\tlearn: 0.1367004\ttotal: 446ms\tremaining: 2.13s\n",
      "26:\tlearn: 0.1361187\ttotal: 458ms\tremaining: 2.09s\n",
      "27:\tlearn: 0.1349066\ttotal: 471ms\tremaining: 2.05s\n",
      "28:\tlearn: 0.1322519\ttotal: 487ms\tremaining: 2.03s\n",
      "29:\tlearn: 0.1267042\ttotal: 503ms\tremaining: 2.01s\n",
      "30:\tlearn: 0.1249661\ttotal: 512ms\tremaining: 1.97s\n",
      "31:\tlearn: 0.1236613\ttotal: 524ms\tremaining: 1.93s\n",
      "32:\tlearn: 0.1226306\ttotal: 540ms\tremaining: 1.91s\n",
      "33:\tlearn: 0.1205874\ttotal: 550ms\tremaining: 1.88s\n",
      "34:\tlearn: 0.1182829\ttotal: 563ms\tremaining: 1.85s\n",
      "35:\tlearn: 0.1143277\ttotal: 576ms\tremaining: 1.82s\n",
      "36:\tlearn: 0.1138944\ttotal: 583ms\tremaining: 1.78s\n",
      "37:\tlearn: 0.1133520\ttotal: 598ms\tremaining: 1.76s\n",
      "38:\tlearn: 0.1108457\ttotal: 608ms\tremaining: 1.73s\n",
      "39:\tlearn: 0.1096464\ttotal: 617ms\tremaining: 1.7s\n",
      "40:\tlearn: 0.1067461\ttotal: 631ms\tremaining: 1.68s\n",
      "41:\tlearn: 0.1061303\ttotal: 639ms\tremaining: 1.64s\n",
      "42:\tlearn: 0.1046607\ttotal: 649ms\tremaining: 1.61s\n",
      "43:\tlearn: 0.1033991\ttotal: 660ms\tremaining: 1.59s\n",
      "44:\tlearn: 0.1030966\ttotal: 670ms\tremaining: 1.56s\n",
      "45:\tlearn: 0.0978983\ttotal: 677ms\tremaining: 1.53s\n",
      "46:\tlearn: 0.0951177\ttotal: 687ms\tremaining: 1.5s\n",
      "47:\tlearn: 0.0935867\ttotal: 696ms\tremaining: 1.48s\n",
      "48:\tlearn: 0.0921129\ttotal: 704ms\tremaining: 1.45s\n",
      "49:\tlearn: 0.0915696\ttotal: 713ms\tremaining: 1.43s\n",
      "50:\tlearn: 0.0882779\ttotal: 725ms\tremaining: 1.41s\n",
      "51:\tlearn: 0.0881075\ttotal: 733ms\tremaining: 1.38s\n",
      "52:\tlearn: 0.0837379\ttotal: 741ms\tremaining: 1.35s\n",
      "53:\tlearn: 0.0835220\ttotal: 750ms\tremaining: 1.33s\n",
      "54:\tlearn: 0.0809745\ttotal: 757ms\tremaining: 1.31s\n",
      "55:\tlearn: 0.0801453\ttotal: 764ms\tremaining: 1.28s\n",
      "56:\tlearn: 0.0797026\ttotal: 775ms\tremaining: 1.26s\n",
      "57:\tlearn: 0.0772823\ttotal: 781ms\tremaining: 1.24s\n",
      "58:\tlearn: 0.0754735\ttotal: 794ms\tremaining: 1.23s\n",
      "59:\tlearn: 0.0727954\ttotal: 804ms\tremaining: 1.21s\n",
      "60:\tlearn: 0.0718230\ttotal: 812ms\tremaining: 1.18s\n",
      "61:\tlearn: 0.0702862\ttotal: 822ms\tremaining: 1.17s\n",
      "62:\tlearn: 0.0665955\ttotal: 829ms\tremaining: 1.14s\n",
      "63:\tlearn: 0.0662979\ttotal: 841ms\tremaining: 1.13s\n",
      "64:\tlearn: 0.0652585\ttotal: 850ms\tremaining: 1.11s\n",
      "65:\tlearn: 0.0650648\ttotal: 858ms\tremaining: 1.09s\n",
      "66:\tlearn: 0.0636792\ttotal: 870ms\tremaining: 1.08s\n",
      "67:\tlearn: 0.0612074\ttotal: 875ms\tremaining: 1.05s\n",
      "68:\tlearn: 0.0607325\ttotal: 884ms\tremaining: 1.04s\n",
      "69:\tlearn: 0.0605748\ttotal: 897ms\tremaining: 1.02s\n",
      "70:\tlearn: 0.0603649\ttotal: 908ms\tremaining: 1.01s\n",
      "71:\tlearn: 0.0575633\ttotal: 916ms\tremaining: 992ms\n",
      "72:\tlearn: 0.0559224\ttotal: 928ms\tremaining: 979ms\n",
      "73:\tlearn: 0.0545042\ttotal: 936ms\tremaining: 962ms\n",
      "74:\tlearn: 0.0524952\ttotal: 949ms\tremaining: 949ms\n",
      "75:\tlearn: 0.0523194\ttotal: 958ms\tremaining: 933ms\n",
      "76:\tlearn: 0.0507817\ttotal: 969ms\tremaining: 919ms\n",
      "77:\tlearn: 0.0483107\ttotal: 979ms\tremaining: 904ms\n",
      "78:\tlearn: 0.0481388\ttotal: 984ms\tremaining: 885ms\n",
      "79:\tlearn: 0.0476364\ttotal: 993ms\tremaining: 869ms\n",
      "80:\tlearn: 0.0474953\ttotal: 1s\tremaining: 853ms\n",
      "81:\tlearn: 0.0473630\ttotal: 1.01s\tremaining: 838ms\n",
      "82:\tlearn: 0.0472451\ttotal: 1.02s\tremaining: 824ms\n",
      "83:\tlearn: 0.0453785\ttotal: 1.03s\tremaining: 808ms\n",
      "84:\tlearn: 0.0432183\ttotal: 1.04s\tremaining: 795ms\n",
      "85:\tlearn: 0.0430853\ttotal: 1.05s\tremaining: 781ms\n",
      "86:\tlearn: 0.0429781\ttotal: 1.06s\tremaining: 771ms\n",
      "87:\tlearn: 0.0414540\ttotal: 1.07s\tremaining: 756ms\n",
      "88:\tlearn: 0.0413782\ttotal: 1.09s\tremaining: 746ms\n",
      "89:\tlearn: 0.0412958\ttotal: 1.1s\tremaining: 734ms\n",
      "90:\tlearn: 0.0412084\ttotal: 1.11s\tremaining: 722ms\n",
      "91:\tlearn: 0.0411319\ttotal: 1.12s\tremaining: 709ms\n",
      "92:\tlearn: 0.0410311\ttotal: 1.14s\tremaining: 699ms\n",
      "93:\tlearn: 0.0400314\ttotal: 1.16s\tremaining: 688ms\n",
      "94:\tlearn: 0.0399831\ttotal: 1.17s\tremaining: 676ms\n",
      "95:\tlearn: 0.0383156\ttotal: 1.18s\tremaining: 664ms\n",
      "96:\tlearn: 0.0382482\ttotal: 1.2s\tremaining: 654ms\n",
      "97:\tlearn: 0.0359601\ttotal: 1.21s\tremaining: 642ms\n",
      "98:\tlearn: 0.0345317\ttotal: 1.22s\tremaining: 627ms\n",
      "99:\tlearn: 0.0329350\ttotal: 1.23s\tremaining: 616ms\n",
      "100:\tlearn: 0.0326349\ttotal: 1.25s\tremaining: 606ms\n",
      "101:\tlearn: 0.0325315\ttotal: 1.26s\tremaining: 592ms\n",
      "102:\tlearn: 0.0324661\ttotal: 1.27s\tremaining: 580ms\n",
      "103:\tlearn: 0.0323716\ttotal: 1.28s\tremaining: 568ms\n",
      "104:\tlearn: 0.0309455\ttotal: 1.29s\tremaining: 553ms\n",
      "105:\tlearn: 0.0308996\ttotal: 1.3s\tremaining: 541ms\n",
      "106:\tlearn: 0.0308348\ttotal: 1.31s\tremaining: 527ms\n",
      "107:\tlearn: 0.0295524\ttotal: 1.32s\tremaining: 514ms\n",
      "108:\tlearn: 0.0294969\ttotal: 1.33s\tremaining: 501ms\n",
      "109:\tlearn: 0.0294426\ttotal: 1.34s\tremaining: 489ms\n",
      "110:\tlearn: 0.0293721\ttotal: 1.35s\tremaining: 475ms\n",
      "111:\tlearn: 0.0291489\ttotal: 1.36s\tremaining: 462ms\n",
      "112:\tlearn: 0.0281495\ttotal: 1.38s\tremaining: 450ms\n",
      "113:\tlearn: 0.0281067\ttotal: 1.39s\tremaining: 438ms\n",
      "114:\tlearn: 0.0269447\ttotal: 1.39s\tremaining: 424ms\n",
      "115:\tlearn: 0.0265532\ttotal: 1.41s\tremaining: 412ms\n",
      "116:\tlearn: 0.0259929\ttotal: 1.42s\tremaining: 400ms\n",
      "117:\tlearn: 0.0259517\ttotal: 1.43s\tremaining: 387ms\n",
      "118:\tlearn: 0.0259153\ttotal: 1.44s\tremaining: 376ms\n",
      "119:\tlearn: 0.0249456\ttotal: 1.46s\tremaining: 365ms\n",
      "120:\tlearn: 0.0249067\ttotal: 1.47s\tremaining: 353ms\n",
      "121:\tlearn: 0.0240235\ttotal: 1.48s\tremaining: 340ms\n",
      "122:\tlearn: 0.0237920\ttotal: 1.49s\tremaining: 328ms\n",
      "123:\tlearn: 0.0237676\ttotal: 1.5s\tremaining: 315ms\n",
      "124:\tlearn: 0.0237254\ttotal: 1.51s\tremaining: 303ms\n",
      "125:\tlearn: 0.0236864\ttotal: 1.52s\tremaining: 290ms\n",
      "126:\tlearn: 0.0229022\ttotal: 1.53s\tremaining: 278ms\n",
      "127:\tlearn: 0.0228751\ttotal: 1.55s\tremaining: 266ms\n",
      "128:\tlearn: 0.0228472\ttotal: 1.56s\tremaining: 254ms\n",
      "129:\tlearn: 0.0228119\ttotal: 1.57s\tremaining: 241ms\n",
      "130:\tlearn: 0.0218020\ttotal: 1.58s\tremaining: 229ms\n",
      "131:\tlearn: 0.0215975\ttotal: 1.59s\tremaining: 217ms\n",
      "132:\tlearn: 0.0208204\ttotal: 1.59s\tremaining: 204ms\n",
      "133:\tlearn: 0.0207908\ttotal: 1.6s\tremaining: 191ms\n",
      "134:\tlearn: 0.0207597\ttotal: 1.61s\tremaining: 179ms\n",
      "135:\tlearn: 0.0207234\ttotal: 1.62s\tremaining: 167ms\n",
      "136:\tlearn: 0.0205921\ttotal: 1.64s\tremaining: 155ms\n",
      "137:\tlearn: 0.0204588\ttotal: 1.64s\tremaining: 143ms\n",
      "138:\tlearn: 0.0204228\ttotal: 1.65s\tremaining: 131ms\n",
      "139:\tlearn: 0.0203837\ttotal: 1.66s\tremaining: 119ms\n",
      "140:\tlearn: 0.0203207\ttotal: 1.67s\tremaining: 107ms\n",
      "141:\tlearn: 0.0200313\ttotal: 1.69s\tremaining: 95ms\n",
      "142:\tlearn: 0.0200072\ttotal: 1.7s\tremaining: 83.2ms\n",
      "143:\tlearn: 0.0199427\ttotal: 1.71s\tremaining: 71.2ms\n",
      "144:\tlearn: 0.0197761\ttotal: 1.72s\tremaining: 59.3ms\n",
      "145:\tlearn: 0.0197507\ttotal: 1.73s\tremaining: 47.5ms\n",
      "146:\tlearn: 0.0191214\ttotal: 1.74s\tremaining: 35.5ms\n",
      "147:\tlearn: 0.0190930\ttotal: 1.75s\tremaining: 23.7ms\n",
      "148:\tlearn: 0.0190557\ttotal: 1.76s\tremaining: 11.8ms\n",
      "149:\tlearn: 0.0188867\ttotal: 1.77s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2025-06-18 20:16:08,219] A new study created in memory with name: no-name-6b780bee-387e-4bf6-8820-888ad859dba9\n",
      "[I 2025-06-18 20:16:08,394] Trial 0 finished with value: -0.9918437500000001 and parameters: {'C': 0.5611516415334505, 'penalty': 'l1'}. Best is trial 0 with value: -0.9918437500000001.\n",
      "[I 2025-06-18 20:16:08,662] Trial 1 finished with value: -0.98840625 and parameters: {'C': 1.5751320499779735, 'penalty': 'l1'}. Best is trial 0 with value: -0.9918437500000001.\n",
      "[I 2025-06-18 20:16:08,929] Trial 2 finished with value: -0.9942499999999999 and parameters: {'C': 0.13066739238053282, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:09,798] Trial 3 finished with value: -0.9749062500000001 and parameters: {'C': 2.607024758370768, 'penalty': 'l2'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:10,447] Trial 4 finished with value: -0.9782187500000001 and parameters: {'C': 4.622589001020832, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:10,677] Trial 5 finished with value: -0.97425 and parameters: {'C': 0.2327067708383781, 'penalty': 'l2'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:10,968] Trial 6 finished with value: -0.9760312500000001 and parameters: {'C': 0.7309539835912913, 'penalty': 'l2'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:11,128] Trial 7 finished with value: -0.9729999999999999 and parameters: {'C': 0.19010245319870356, 'penalty': 'l2'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:11,358] Trial 8 finished with value: -0.9909062500000001 and parameters: {'C': 0.8168455894760165, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:11,590] Trial 9 finished with value: -0.9901250000000001 and parameters: {'C': 1.0677482709481354, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:11,706] Trial 10 finished with value: -0.9942499999999999 and parameters: {'C': 0.10991587445851024, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:11,815] Trial 11 finished with value: -0.9942187499999999 and parameters: {'C': 0.10353677627159782, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:11,914] Trial 12 finished with value: -0.9942499999999999 and parameters: {'C': 0.10691887002123487, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:12,781] Trial 13 finished with value: -0.99334375 and parameters: {'C': 0.31386613240444206, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:13,229] Trial 14 finished with value: -0.9932187499999999 and parameters: {'C': 0.3231096964640978, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:14,181] Trial 15 finished with value: -0.9741250000000001 and parameters: {'C': 8.611382274356343, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:14,294] Trial 16 finished with value: -0.9942187499999999 and parameters: {'C': 0.1588471280716395, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:14,433] Trial 17 finished with value: -0.9924062499999999 and parameters: {'C': 0.4069740832946609, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:14,645] Trial 18 finished with value: -0.9728125000000001 and parameters: {'C': 0.1736216698299393, 'penalty': 'l2'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:16,864] Trial 19 finished with value: -0.9942187499999999 and parameters: {'C': 0.1036451998177247, 'penalty': 'l1'}. Best is trial 2 with value: -0.9942499999999999.\n",
      "[I 2025-06-18 20:16:16,885] A new study created in memory with name: no-name-c59d8785-5146-4ba1-968e-0ed3f475af60\n",
      "[I 2025-06-18 20:16:19,833] Trial 0 finished with value: -0.9341250000000001 and parameters: {'n_estimators': 106, 'max_depth': 5, 'min_samples_split': 3}. Best is trial 0 with value: -0.9341250000000001.\n",
      "[I 2025-06-18 20:16:21,668] Trial 1 finished with value: -0.9324843749999999 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 0 with value: -0.9341250000000001.\n",
      "[I 2025-06-18 20:16:28,509] Trial 2 finished with value: -0.9513749999999999 and parameters: {'n_estimators': 175, 'max_depth': None, 'min_samples_split': 5}. Best is trial 2 with value: -0.9513749999999999.\n",
      "[I 2025-06-18 20:16:32,392] Trial 3 finished with value: -0.9528125 and parameters: {'n_estimators': 115, 'max_depth': 10, 'min_samples_split': 4}. Best is trial 3 with value: -0.9528125.\n",
      "[I 2025-06-18 20:16:35,583] Trial 4 finished with value: -0.93809375 and parameters: {'n_estimators': 118, 'max_depth': 5, 'min_samples_split': 2}. Best is trial 3 with value: -0.9528125.\n",
      "[I 2025-06-18 20:16:40,264] Trial 5 finished with value: -0.9551562499999999 and parameters: {'n_estimators': 141, 'max_depth': None, 'min_samples_split': 7}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:16:42,652] Trial 6 finished with value: -0.9483750000000001 and parameters: {'n_estimators': 95, 'max_depth': 10, 'min_samples_split': 5}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:16:43,780] Trial 7 finished with value: -0.93590625 and parameters: {'n_estimators': 55, 'max_depth': 5, 'min_samples_split': 5}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:16:46,878] Trial 8 finished with value: -0.951953125 and parameters: {'n_estimators': 132, 'max_depth': 10, 'min_samples_split': 8}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:16:49,443] Trial 9 finished with value: -0.9393125000000001 and parameters: {'n_estimators': 140, 'max_depth': 5, 'min_samples_split': 4}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:16:53,515] Trial 10 finished with value: -0.9524687499999999 and parameters: {'n_estimators': 194, 'max_depth': None, 'min_samples_split': 7}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:16:56,616] Trial 11 finished with value: -0.9521875000000002 and parameters: {'n_estimators': 155, 'max_depth': 15, 'min_samples_split': 6}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:16:58,496] Trial 12 finished with value: -0.9513124999999999 and parameters: {'n_estimators': 88, 'max_depth': 10, 'min_samples_split': 6}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:17:02,119] Trial 13 finished with value: -0.9475624999999999 and parameters: {'n_estimators': 160, 'max_depth': None, 'min_samples_split': 3}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:17:03,800] Trial 14 finished with value: -0.95103125 and parameters: {'n_estimators': 79, 'max_depth': 15, 'min_samples_split': 7}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:17:06,396] Trial 15 finished with value: -0.951359375 and parameters: {'n_estimators': 123, 'max_depth': None, 'min_samples_split': 4}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:17:09,411] Trial 16 finished with value: -0.95325 and parameters: {'n_estimators': 147, 'max_depth': 10, 'min_samples_split': 6}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:17:12,631] Trial 17 finished with value: -0.9544062499999999 and parameters: {'n_estimators': 149, 'max_depth': None, 'min_samples_split': 7}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:17:16,881] Trial 18 finished with value: -0.9518125 and parameters: {'n_estimators': 180, 'max_depth': None, 'min_samples_split': 7}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:17:20,939] Trial 19 finished with value: -0.95234375 and parameters: {'n_estimators': 171, 'max_depth': None, 'min_samples_split': 8}. Best is trial 5 with value: -0.9551562499999999.\n",
      "[I 2025-06-18 20:17:21,793] A new study created in memory with name: no-name-eb9e413b-f038-4ef7-9e61-f6b177c8f3c8\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:24,215] Trial 0 finished with value: -0.996703125 and parameters: {'n_estimators': 106, 'learning_rate': 0.13125830316209655, 'max_depth': 7, 'subsample': 0.8795975452591109}. Best is trial 0 with value: -0.996703125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:25,468] Trial 1 finished with value: -0.98590625 and parameters: {'n_estimators': 73, 'learning_rate': 0.015256811898068502, 'max_depth': 3, 'subsample': 0.9598528437324805}. Best is trial 0 with value: -0.996703125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:26,917] Trial 2 finished with value: -0.9966250000000001 and parameters: {'n_estimators': 140, 'learning_rate': 0.06803900745073706, 'max_depth': 3, 'subsample': 0.9909729556485982}. Best is trial 0 with value: -0.996703125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:29,546] Trial 3 finished with value: -0.99703125 and parameters: {'n_estimators': 175, 'learning_rate': 0.01777174904859463, 'max_depth': 4, 'subsample': 0.7550213529560301}. Best is trial 3 with value: -0.99703125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:31,361] Trial 4 finished with value: -0.9972031250000001 and parameters: {'n_estimators': 95, 'learning_rate': 0.04141536110538596, 'max_depth': 5, 'subsample': 0.7873687420594125}. Best is trial 4 with value: -0.9972031250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:33,586] Trial 5 finished with value: -0.995703125 and parameters: {'n_estimators': 142, 'learning_rate': 0.01459007452373112, 'max_depth': 4, 'subsample': 0.8099085529881075}. Best is trial 4 with value: -0.9972031250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:35,162] Trial 6 finished with value: -0.997109375 and parameters: {'n_estimators': 118, 'learning_rate': 0.0838375512850209, 'max_depth': 4, 'subsample': 0.8542703315240835}. Best is trial 4 with value: -0.9972031250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:37,994] Trial 7 finished with value: -0.99484375 and parameters: {'n_estimators': 139, 'learning_rate': 0.011340440501807348, 'max_depth': 6, 'subsample': 0.7511572371061874}. Best is trial 4 with value: -0.9972031250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:39,146] Trial 8 finished with value: -0.99709375 and parameters: {'n_estimators': 59, 'learning_rate': 0.13060986669773664, 'max_depth': 8, 'subsample': 0.9425192044349383}. Best is trial 4 with value: -0.9972031250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:41,203] Trial 9 finished with value: -0.9936093750000001 and parameters: {'n_estimators': 95, 'learning_rate': 0.01302780710309028, 'max_depth': 7, 'subsample': 0.8320457481218804}. Best is trial 4 with value: -0.9972031250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:44,471] Trial 10 finished with value: -0.997453125 and parameters: {'n_estimators': 192, 'learning_rate': 0.028825693577590687, 'max_depth': 5, 'subsample': 0.7053885626844458}. Best is trial 10 with value: -0.997453125.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:47,861] Trial 11 finished with value: -0.9975781250000001 and parameters: {'n_estimators': 191, 'learning_rate': 0.03223498404215344, 'max_depth': 5, 'subsample': 0.7054367296359227}. Best is trial 11 with value: -0.9975781250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:51,350] Trial 12 finished with value: -0.99728125 and parameters: {'n_estimators': 198, 'learning_rate': 0.027954339326293067, 'max_depth': 5, 'subsample': 0.7014481884937426}. Best is trial 11 with value: -0.9975781250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:54,706] Trial 13 finished with value: -0.9975156249999999 and parameters: {'n_estimators': 178, 'learning_rate': 0.03242221000947164, 'max_depth': 6, 'subsample': 0.7060063846342731}. Best is trial 11 with value: -0.9975781250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:17:58,333] Trial 14 finished with value: -0.99753125 and parameters: {'n_estimators': 168, 'learning_rate': 0.04363242575820887, 'max_depth': 6, 'subsample': 0.7432273803164781}. Best is trial 11 with value: -0.9975781250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:03,490] Trial 15 finished with value: -0.99725 and parameters: {'n_estimators': 164, 'learning_rate': 0.04860274753231523, 'max_depth': 7, 'subsample': 0.760922886777417}. Best is trial 11 with value: -0.9975781250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:07,132] Trial 16 finished with value: -0.9973124999999999 and parameters: {'n_estimators': 160, 'learning_rate': 0.020972639647908343, 'max_depth': 6, 'subsample': 0.7408415462126681}. Best is trial 11 with value: -0.9975781250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:10,605] Trial 17 finished with value: -0.9973593749999999 and parameters: {'n_estimators': 179, 'learning_rate': 0.05987239651439145, 'max_depth': 8, 'subsample': 0.7867374784881606}. Best is trial 11 with value: -0.9975781250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:14,201] Trial 18 finished with value: -0.99715625 and parameters: {'n_estimators': 152, 'learning_rate': 0.024478897732470608, 'max_depth': 5, 'subsample': 0.8934021055804257}. Best is trial 11 with value: -0.9975781250000001.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:18:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-18 20:18:18,540] Trial 19 finished with value: -0.9973437500000001 and parameters: {'n_estimators': 199, 'learning_rate': 0.03992698470813971, 'max_depth': 6, 'subsample': 0.7308677128248431}. Best is trial 11 with value: -0.9975781250000001.\n",
      "[I 2025-06-18 20:18:19,382] A new study created in memory with name: no-name-dd49729a-0ead-47a6-916b-19df290589df\n",
      "[I 2025-06-18 20:18:25,717] Trial 0 finished with value: -0.99578125 and parameters: {'iterations': 106, 'learning_rate': 0.13125830316209655, 'depth': 7, 'l2_leaf_reg': 0.6251373574521749}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:18:38,667] Trial 1 finished with value: -0.980453125 and parameters: {'iterations': 73, 'learning_rate': 0.015256811898068502, 'depth': 3, 'l2_leaf_reg': 3.9676050770529883}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:18:42,468] Trial 2 finished with value: -0.9946250000000001 and parameters: {'iterations': 140, 'learning_rate': 0.06803900745073706, 'depth': 3, 'l2_leaf_reg': 8.123245085588687}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:18:48,086] Trial 3 finished with value: -0.9883749999999999 and parameters: {'iterations': 175, 'learning_rate': 0.01777174904859463, 'depth': 4, 'l2_leaf_reg': 0.03549878832196503}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:18:52,626] Trial 4 finished with value: -0.9897499999999999 and parameters: {'iterations': 95, 'learning_rate': 0.04141536110538596, 'depth': 5, 'l2_leaf_reg': 0.07476312062252301}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:18:56,976] Trial 5 finished with value: -0.98890625 and parameters: {'iterations': 142, 'learning_rate': 0.01459007452373112, 'depth': 4, 'l2_leaf_reg': 0.1256277350380703}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:19:00,412] Trial 6 finished with value: -0.9949999999999999 and parameters: {'iterations': 118, 'learning_rate': 0.0838375512850209, 'depth': 4, 'l2_leaf_reg': 0.34890188454913873}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:19:07,168] Trial 7 finished with value: -0.9893124999999999 and parameters: {'iterations': 139, 'learning_rate': 0.011340440501807348, 'depth': 6, 'l2_leaf_reg': 0.03247673570627449}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:19:14,986] Trial 8 finished with value: -0.9919062499999999 and parameters: {'iterations': 59, 'learning_rate': 0.13060986669773664, 'depth': 8, 'l2_leaf_reg': 2.6619018884890564}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:19:21,922] Trial 9 finished with value: -0.98753125 and parameters: {'iterations': 95, 'learning_rate': 0.01302780710309028, 'depth': 7, 'l2_leaf_reg': 0.2091498132903561}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:19:44,918] Trial 10 finished with value: -0.99175 and parameters: {'iterations': 192, 'learning_rate': 0.036030984219246213, 'depth': 8, 'l2_leaf_reg': 0.8306050731972228}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:19:51,231] Trial 11 finished with value: -0.9953750000000001 and parameters: {'iterations': 109, 'learning_rate': 0.11681446704286463, 'depth': 6, 'l2_leaf_reg': 0.681165744715909}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:19:57,616] Trial 12 finished with value: -0.99475 and parameters: {'iterations': 107, 'learning_rate': 0.14828432951660628, 'depth': 6, 'l2_leaf_reg': 0.8746681211258789}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:20:03,428] Trial 13 finished with value: -0.9932187499999999 and parameters: {'iterations': 80, 'learning_rate': 0.09915097464555107, 'depth': 7, 'l2_leaf_reg': 0.7519157479251137}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:20:15,068] Trial 14 finished with value: -0.9946875000000002 and parameters: {'iterations': 162, 'learning_rate': 0.055753892419385366, 'depth': 7, 'l2_leaf_reg': 1.5478228691219225}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:20:20,338] Trial 15 finished with value: -0.9904999999999999 and parameters: {'iterations': 119, 'learning_rate': 0.02550159780786631, 'depth': 6, 'l2_leaf_reg': 0.3076974779163993}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:20:23,723] Trial 16 finished with value: -0.9944999999999998 and parameters: {'iterations': 95, 'learning_rate': 0.10469335426137871, 'depth': 5, 'l2_leaf_reg': 0.45655940454458455}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:20:28,176] Trial 17 finished with value: -0.98928125 and parameters: {'iterations': 61, 'learning_rate': 0.05987239651439145, 'depth': 7, 'l2_leaf_reg': 0.015551112346959566}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:20:38,444] Trial 18 finished with value: -0.9944375000000001 and parameters: {'iterations': 127, 'learning_rate': 0.11793440000481531, 'depth': 8, 'l2_leaf_reg': 2.021191663542717}. Best is trial 0 with value: -0.99578125.\n",
      "[I 2025-06-18 20:20:44,456] Trial 19 finished with value: -0.9958750000000001 and parameters: {'iterations': 160, 'learning_rate': 0.0797582538863159, 'depth': 5, 'l2_leaf_reg': 9.728613904848126}. Best is trial 19 with value: -0.9958750000000001.\n",
      "[I 2025-06-18 20:20:45,368] A new study created in memory with name: no-name-6f0db41e-1587-4be0-93e1-68242734ee05\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:21:08,407] Trial 0 finished with value: -0.9488749999999999 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 2.9380279387035334e-05, 'learning_rate_init': 0.00020511104188433984}. Best is trial 0 with value: -0.9488749999999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:21:10,001] Trial 1 finished with value: -0.9605937499999999 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.1527987128232396e-05, 'learning_rate_init': 0.008706020878304856}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:21:28,673] Trial 2 finished with value: -0.9553125 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 8.17949947521167e-05, 'learning_rate_init': 0.0011207606211860567}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:22:42,683] Trial 3 finished with value: -0.9421875 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 7.52374288453485e-05, 'learning_rate_init': 0.0005404103854647331}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:16,757] Trial 4 finished with value: -0.94675 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.0005987474910461401, 'learning_rate_init': 0.0001238513729886094}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:18,960] Trial 5 finished with value: -0.95490625 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00788671412999049, 'learning_rate_init': 0.004138040112561018}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:23,595] Trial 6 finished with value: -0.9447812499999999 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 2.32335035153901e-05, 'learning_rate_init': 0.0009780337016659412}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:29,953] Trial 7 finished with value: -0.9572499999999999 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 8.612579192594876e-05, 'learning_rate_init': 0.001096821720752952}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:31,583] Trial 8 finished with value: -0.9545625000000001 and parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.006584106160121612, 'learning_rate_init': 0.006161049539380964}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:44,983] Trial 9 finished with value: -0.9561875000000001 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 1.3667272915456215e-05, 'learning_rate_init': 0.0004473636174621269}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:46,903] Trial 10 finished with value: -0.9598437499999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0006446437100534851, 'learning_rate_init': 0.008691089486124973}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:48,970] Trial 11 finished with value: -0.94959375 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0008322724281704743, 'learning_rate_init': 0.0032630616334052716}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:50,699] Trial 12 finished with value: -0.9583125000000001 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0013141513949245947, 'learning_rate_init': 0.009237992574561581}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:54,260] Trial 13 finished with value: -0.95865625 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.0024138827155249917, 'learning_rate_init': 0.002479201332659864}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:55,656] Trial 14 finished with value: -0.9514375000000002 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.00022784259374269346, 'learning_rate_init': 0.009841513366747656}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:23:59,138] Trial 15 finished with value: -0.9563750000000001 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 0.00028674015157718663, 'learning_rate_init': 0.0021527183465656838}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:00,907] Trial 16 finished with value: -0.95840625 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0032549670694108387, 'learning_rate_init': 0.005867338877439117}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:02,836] Trial 17 finished with value: -0.9553437499999999 and parameters: {'hidden_layer_sizes': (50,), 'alpha': 0.00019981948166734924, 'learning_rate_init': 0.005541681730529245}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:05,524] Trial 18 finished with value: -0.9477812499999999 and parameters: {'hidden_layer_sizes': (100, 50), 'alpha': 0.0008408288483823167, 'learning_rate_init': 0.001642144528610345}. Best is trial 1 with value: -0.9605937499999999.\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100,) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (50, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:515: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (100, 50) which is of type tuple.\n",
      "  warnings.warn(message)\n",
      "[I 2025-06-18 20:24:08,671] Trial 19 finished with value: -0.9597187500000001 and parameters: {'hidden_layer_sizes': (100,), 'alpha': 3.9275041412979375e-05, 'learning_rate_init': 0.0036283791821892833}. Best is trial 1 with value: -0.9605937499999999.\n"
     ]
    }
   ],
   "source": [
    "# --- Основной цикл оценки с тремя методами оптимизации ---\n",
    "all_classification_results = []\n",
    "optimizers = ['RandomizedSearchCV', 'GridSearchCV', 'Optuna']\n",
    "\n",
    "# Извлекаем признаки, исключая все целевые переменные (теперь просто TARGETS_ACTUAL_LOGGED)\n",
    "# и новые бинарные целевые переменные.\n",
    "columns_to_drop_common = TARGETS_ACTUAL_LOGGED + list(classification_targets.keys())\n",
    "\n",
    "# Добавляем специфические для датасетов столбцы, которые не являются признаками (например, SMILES)\n",
    "if 'SMILES' in df_pca.columns:\n",
    "    columns_to_drop_pca_final = columns_to_drop_common + ['SMILES']\n",
    "else:\n",
    "    columns_to_drop_pca_final = columns_to_drop_common\n",
    "\n",
    "if 'SMILES' in df_manual.columns:\n",
    "    columns_to_drop_manual_final = columns_to_drop_common + ['SMILES']\n",
    "else:\n",
    "    columns_to_drop_manual_final = columns_to_drop_common\n",
    "\n",
    "X_pca_features = df_pca.drop(columns=columns_to_drop_pca_final, errors='ignore')\n",
    "X_manual_features = df_manual.drop(columns=columns_to_drop_manual_final, errors='ignore')\n",
    "\n",
    "\n",
    "print(\"Начинаем процесс обучения и оценки моделей классификации...\")\n",
    "\n",
    "for target_name_classification in tqdm(classification_targets.keys(), desc=\"Прогнозирование задач классификации\"):\n",
    "    for data_source_name, X_data_features, df_data in [(\"PCA Aggregated\", X_pca_features, df_pca), (\"Manual Aggregated\", X_manual_features, df_manual)]:\n",
    "        y_data_classification = df_data[target_name_classification]\n",
    "\n",
    "        num_models_to_run = 0\n",
    "        for model_name, config in models_config_classifier.items():\n",
    "            for optimizer_type in optimizers:\n",
    "                # Уточненная логика для подсчета моделей\n",
    "                if (optimizer_type == 'RandomizedSearchCV' and not config.get('random_dist', {})) and model_name != \"LogisticRegression\":\n",
    "                    continue\n",
    "                if (optimizer_type == 'GridSearchCV' and not config.get('grid_params', {})) and model_name != \"LogisticRegression\":\n",
    "                    continue\n",
    "                if (optimizer_type == 'Optuna' and config.get('optuna_space') is None) and model_name != \"LogisticRegression\":\n",
    "                    continue\n",
    "                num_models_to_run += 1\n",
    "\n",
    "        with tqdm(total=num_models_to_run, desc=f\"Оптимизация для {target_name_classification} ({data_source_name})\", leave=False) as pbar_inner:\n",
    "            for optimizer_type in optimizers:\n",
    "                for model_name, config in models_config_classifier.items():\n",
    "                    # Пропускаем неподходящие комбинации модель-оптимизатор, чтобы избежать ошибок и не тратить время\n",
    "                    if (optimizer_type == 'RandomizedSearchCV' and not config.get('random_dist', {})) and model_name != \"LogisticRegression\":\n",
    "                        pbar_inner.update(1)\n",
    "                        continue\n",
    "                    if (optimizer_type == 'GridSearchCV' and not config.get('grid_params', {})) and model_name != \"LogisticRegression\":\n",
    "                        pbar_inner.update(1)\n",
    "                        continue\n",
    "                    if (optimizer_type == 'Optuna' and config.get('optuna_space') is None) and model_name != \"LogisticRegression\":\n",
    "                        pbar_inner.update(1)\n",
    "                        continue\n",
    "\n",
    "                    model_class = config[\"class\"]\n",
    "                    params_config = config\n",
    "\n",
    "                    pbar_inner.set_description(f\"Оптимизация для {target_name_classification} ({data_source_name}) - {model_name} ({optimizer_type})\")\n",
    "\n",
    "                    result = evaluate_model_with_optimizer_classifier(model_name, model_class, params_config,\n",
    "                                                                      X_data_features, y_data_classification, target_name_classification, optimizer_type)\n",
    "                    if result:\n",
    "                        result['data_source'] = data_source_name\n",
    "                        all_classification_results.append(result)\n",
    "                    pbar_inner.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c4fab20-7400-4d47-86f9-ccb611faebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты классификации сохранены в: classification_results_all_optimizers_50_iter.csv\n",
      "\n",
      "--- Сводка результатов классификации по методам оптимизации ---\n",
      "\n",
      "## Результаты RandomizedSearchCV (Классификация):\n",
      "                     model           optimizer                target                                                                                                                               best_params  accuracy  precision  recall  f1_score   roc_auc        data_source\n",
      "2            XGBClassifier  RandomizedSearchCV  is_IC50_above_median  {'learning_rate': 0.06923222772633546, 'max_depth': 5, 'n_estimators': 130, 'subsample': 0.9134025858245949, 'use_label_encoder': False}  0.980100   0.970588    0.99  0.980198  0.999109     PCA Aggregated\n",
      "16           XGBClassifier  RandomizedSearchCV  is_IC50_above_median  {'learning_rate': 0.04463407384332235, 'max_depth': 6, 'n_estimators': 160, 'subsample': 0.9049790556476374, 'use_label_encoder': False}  0.985075   0.970874    1.00  0.985222  0.998812  Manual Aggregated\n",
      "3       CatBoostClassifier  RandomizedSearchCV  is_IC50_above_median                                   {'depth': 5, 'iterations': 157, 'l2_leaf_reg': 4.599641068895281, 'learning_rate': 0.09886218532930637}  0.980100   0.961538    1.00  0.980392  0.997327     PCA Aggregated\n",
      "17      CatBoostClassifier  RandomizedSearchCV  is_IC50_above_median                                   {'depth': 7, 'iterations': 195, 'l2_leaf_reg': 6.425929763527802, 'learning_rate': 0.15092484123462838}  0.975124   0.961165    0.99  0.975369  0.996931  Manual Aggregated\n",
      "0       LogisticRegression  RandomizedSearchCV  is_IC50_above_median                                                                          {'C': 3.845401188473625, 'penalty': 'l1', 'solver': 'liblinear'}  0.950249   0.950000    0.95  0.950000  0.992871     PCA Aggregated\n",
      "14      LogisticRegression  RandomizedSearchCV  is_IC50_above_median                                                                          {'C': 3.845401188473625, 'penalty': 'l1', 'solver': 'liblinear'}  0.950249   0.950000    0.95  0.950000  0.992475  Manual Aggregated\n",
      "4            MLPClassifier  RandomizedSearchCV  is_IC50_above_median                                {'alpha': 0.0034126114217699097, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.002225779372456223}  0.890547   0.882353    0.90  0.891089  0.964455     PCA Aggregated\n",
      "18           MLPClassifier  RandomizedSearchCV  is_IC50_above_median                                 {'alpha': 0.0007101911742238942, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.004265974558680822}  0.895522   0.883495    0.91  0.896552  0.953960  Manual Aggregated\n",
      "15  RandomForestClassifier  RandomizedSearchCV  is_IC50_above_median                                                                            {'max_depth': 10, 'min_samples_split': 4, 'n_estimators': 124}  0.855721   0.831776    0.89  0.859903  0.937921  Manual Aggregated\n",
      "1   RandomForestClassifier  RandomizedSearchCV  is_IC50_above_median                                                                            {'max_depth': 10, 'min_samples_split': 6, 'n_estimators': 179}  0.855721   0.831776    0.89  0.859903  0.929307     PCA Aggregated\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "## Результаты GridSearchCV (Классификация):\n",
      "                     model     optimizer                target                                                                               best_params  accuracy  precision  recall  f1_score   roc_auc        data_source\n",
      "5       LogisticRegression  GridSearchCV  is_IC50_above_median                                        {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}  0.985075   0.980198    0.99  0.985075  0.999208     PCA Aggregated\n",
      "19      LogisticRegression  GridSearchCV  is_IC50_above_median                                        {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}  0.985075   0.980198    0.99  0.985075  0.999208  Manual Aggregated\n",
      "7            XGBClassifier  GridSearchCV  is_IC50_above_median  {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 150, 'use_label_encoder': False}  0.980100   0.970588    0.99  0.980198  0.998911     PCA Aggregated\n",
      "21           XGBClassifier  GridSearchCV  is_IC50_above_median  {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 150, 'use_label_encoder': False}  0.985075   0.970874    1.00  0.985222  0.998614  Manual Aggregated\n",
      "8       CatBoostClassifier  GridSearchCV  is_IC50_above_median                                     {'depth': 3, 'iterations': 150, 'learning_rate': 0.1}  0.965174   0.960396    0.97  0.965174  0.997228     PCA Aggregated\n",
      "22      CatBoostClassifier  GridSearchCV  is_IC50_above_median                                     {'depth': 5, 'iterations': 150, 'learning_rate': 0.1}  0.970149   0.960784    0.98  0.970297  0.996733  Manual Aggregated\n",
      "9            MLPClassifier  GridSearchCV  is_IC50_above_median                                            {'alpha': 0.001, 'hidden_layer_sizes': (100,)}  0.875622   0.857143    0.90  0.878049  0.959604     PCA Aggregated\n",
      "23           MLPClassifier  GridSearchCV  is_IC50_above_median                                            {'alpha': 0.001, 'hidden_layer_sizes': (100,)}  0.880597   0.880000    0.88  0.880000  0.953960  Manual Aggregated\n",
      "20  RandomForestClassifier  GridSearchCV  is_IC50_above_median                                                    {'max_depth': 10, 'n_estimators': 150}  0.850746   0.830189    0.88  0.854369  0.934653  Manual Aggregated\n",
      "6   RandomForestClassifier  GridSearchCV  is_IC50_above_median                                                    {'max_depth': 10, 'n_estimators': 150}  0.850746   0.830189    0.88  0.854369  0.919703     PCA Aggregated\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "## Результаты Optuna (Классификация):\n",
      "                     model optimizer                target                                                                                                   best_params  accuracy  precision  recall  f1_score   roc_auc        data_source\n",
      "25           XGBClassifier    Optuna  is_IC50_above_median  {'n_estimators': 191, 'learning_rate': 0.03223498404215344, 'max_depth': 5, 'subsample': 0.7054367296359227}  0.985075   0.970874    1.00  0.985222  0.998713  Manual Aggregated\n",
      "11           XGBClassifier    Optuna  is_IC50_above_median   {'n_estimators': 59, 'learning_rate': 0.13060986669773664, 'max_depth': 8, 'subsample': 0.9425192044349383}  0.985075   0.970874    1.00  0.985222  0.998416     PCA Aggregated\n",
      "26      CatBoostClassifier    Optuna  is_IC50_above_median        {'iterations': 160, 'learning_rate': 0.0797582538863159, 'depth': 5, 'l2_leaf_reg': 9.728613904848126}  0.975124   0.961165    0.99  0.975369  0.998119  Manual Aggregated\n",
      "12      CatBoostClassifier    Optuna  is_IC50_above_median       {'iterations': 161, 'learning_rate': 0.10643739208019755, 'depth': 5, 'l2_leaf_reg': 9.604466184865705}  0.955224   0.950495    0.96  0.955224  0.997030     PCA Aggregated\n",
      "27           MLPClassifier    Optuna  is_IC50_above_median   {'hidden_layer_sizes': (100,), 'alpha': 1.1527987128232396e-05, 'learning_rate_init': 0.008706020878304856}  0.895522   0.891089    0.90  0.895522  0.962673  Manual Aggregated\n",
      "24  RandomForestClassifier    Optuna  is_IC50_above_median                                              {'n_estimators': 141, 'max_depth': None, 'min_samples_split': 7}  0.855721   0.844660    0.87  0.857143  0.936931  Manual Aggregated\n",
      "13           MLPClassifier    Optuna  is_IC50_above_median  {'hidden_layer_sizes': (100,), 'alpha': 1.3667272915456215e-05, 'learning_rate_init': 0.0004473636174621269}  0.875622   0.886598    0.86  0.873096  0.932574     PCA Aggregated\n",
      "10  RandomForestClassifier    Optuna  is_IC50_above_median                                              {'n_estimators': 193, 'max_depth': None, 'min_samples_split': 6}  0.855721   0.831776    0.89  0.859903  0.927723     PCA Aggregated\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Сохранение и вывод результатов ---\n",
    "output_classification_file = Path('classification_results_all_optimizers_50_iter.csv')\n",
    "\n",
    "all_classification_results_df = pd.DataFrame(all_classification_results)\n",
    "all_classification_results_df.to_csv(output_classification_file, index=False)\n",
    "print(f\"\\nРезультаты классификации сохранены в: {output_classification_file}\")\n",
    "\n",
    "print(\"\\n--- Сводка результатов классификации по методам оптимизации ---\")\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    print(f\"\\n## Результаты {optimizer} (Классификация):\")\n",
    "    subset_optimizer = all_classification_results_df[all_classification_results_df['optimizer'] == optimizer]\n",
    "    print(subset_optimizer.sort_values(by=['target', 'roc_auc'], ascending=[True, False]).to_string())\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Визуализация метрик классификации (например, ROC-AUC и F1-score)\n",
    "classification_metrics_to_plot = ['roc_auc', 'f1_score', 'accuracy']\n",
    "\n",
    "for target_class in classification_targets.keys():\n",
    "    for metric in classification_metrics_to_plot:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        subset = all_classification_results_df[all_classification_results_df['target'] == target_class].sort_values(by=metric, ascending=False)\n",
    "        sns.barplot(x='model', y=metric, hue='optimizer', data=subset, palette='viridis')\n",
    "        plt.title(f'Сравнение {metric.upper()} для \"{target_class}\" по методам оптимизации', fontsize=16)\n",
    "        plt.ylabel(metric.upper(), fontsize=12)\n",
    "        plt.xlabel('Модель', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.legend(title='Метод оптимизации', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'classification_{target_class}_{metric}_comparison.png')\n",
    "        plt.close() # Close plot to free memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
